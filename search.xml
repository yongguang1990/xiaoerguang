<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[nginx]]></title>
    <url>%2Fp%2Fe30a.html</url>
    <content type="text"><![CDATA[什么是 Nginx由 小路依依 创建， 最后一次修改 2016-08-12 什么是 NginxNginx 是俄罗斯人编写的十分轻量级的 HTTP 服务器,Nginx，它的发音为“engine X”，是一个高性能的HTTP和反向代理服务器，同时也是一个 IMAP/POP3/SMTP 代理服务器。Nginx 是由俄罗斯人 Igor Sysoev 为俄罗斯访问量第二的 Rambler.ru 站点开发的，它已经在该站点运行超过两年半了。Igor Sysoev 在建立的项目时,使用基于 BSD 许可。 英文主页：http://nginx.net 。 到 2013 年，目前有很多国内网站采用 Nginx 作为 Web 服务器，如国内知名的新浪、163、腾讯、Discuz、豆瓣等。据 netcraft 统计，Nginx 排名第 3，约占 15% 的份额(参见：http://news.netcraft.com/archives/category/web-server-survey/ ) Nginx 以事件驱动的方式编写，所以有非常好的性能，同时也是一个非常高效的反向代理、负载平衡。其拥有匹配 Lighttpd 的性能，同时还没有 Lighttpd 的内存泄漏问题，而且 Lighttpd 的 mod_proxy 也有一些问题并且很久没有更新。 现在，Igor 将源代码以类 BSD 许可证的形式发布。Nginx 因为它的稳定性、丰富的模块库、灵活的配置和低系统资源的消耗而闻名．业界一致认为它是 Apache2.2＋mod_proxy_balancer 的轻量级代替者，不仅是因为响应静态页面的速度非常快，而且它的模块数量达到 Apache 的近 2/3。对 proxy 和 rewrite 模块的支持很彻底，还支持 mod_fcgi、ssl、vhosts ，适合用来做 mongrel clusters 的前端 HTTP 响应。 Nginx 的特点由 小路依依 创建， 最后一次修改 2016-08-12 Nginx 特点Nginx 做为 HTTP 服务器，有以下几项基本特性： 处理静态文件，索引文件以及自动索引；打开文件描述符缓冲． 无缓存的反向代理加速，简单的负载均衡和容错． FastCGI，简单的负载均衡和容错． 模块化的结构。包括 gzipping, byte ranges, chunked responses,以及 SSI-filter 等 filter。如果由 FastCGI 或其它代理服务器处理单页中存在的多个 SSI，则这项处理可以并行运行，而不需要相互等待。 支持 SSL 和 TLSSNI． Nginx 专为性能优化而开发，性能是其最重要的考量,实现上非常注重效率 。它支持内核 Poll 模型，能经受高负载的考验,有报告表明能支持高达 50,000 个并发连接数。 Nginx 具有很高的稳定性。其它 HTTP 服务器，当遇到访问的峰值，或者有人恶意发起慢速连接时，也很可能会导致服务器物理内存耗尽频繁交换，失去响应，只能重启服务器。例如当前 apache 一旦上到 200 个以上进程，web响应速度就明显非常缓慢了。而 Nginx 采取了分阶段资源分配技术，使得它的 CPU 与内存占用率非常低。Nginx 官方表示保持 10,000 个没有活动的连接，它只占 2.5M 内存，所以类似 DOS 这样的攻击对 Nginx 来说基本上是毫无用处的。就稳定性而言,Nginx 比 lighthttpd 更胜一筹。 Nginx 支持热部署。它的启动特别容易, 并且几乎可以做到 7*24 不间断运行，即使运行数个月也不需要重新启动。你还能够在不间断服务的情况下，对软件版本进行进行升级。 Nginx 采用 master-slave 模型,能够充分利用 SMP 的优势，且能够减少工作进程在磁盘 I/O 的阻塞延迟。当采用 select()/poll() 调用时，还可以限制每个进程的连接数。 Nginx 代码质量非常高，代码很规范，手法成熟，模块扩展也很容易。特别值得一提的是强大的 Upstream 与 Filter 链。Upstream 为诸如 reverse proxy,与其他服务器通信模块的编写奠定了很好的基础。而 Filter 链最酷的部分就是各个 filter 不必等待前一个 filter 执行完毕。它可以把前一个 filter 的输出做为当前 filter 的输入，这有点像 Unix 的管线。这意味着，一个模块可以开始压缩从后端服务器发送过来的请求，且可以在模块接收完后端服务器的整个请求之前把压缩流转向客户端。 Nginx 采用了一些 os 提供的最新特性如对 sendfile (Linux2.2+)，accept-filter (FreeBSD4.1+)，TCP_DEFER_ACCEPT (Linux 2.4+)的支持，从而大大提高了性能。 当然，Nginx 还很年轻，多多少少存在一些问题，比如：Nginx 是俄罗斯人创建，虽然前几年文档比较少，但是目前文档方面比较全面，英文资料居多，中文的资料也比较多，而且有专门的书籍和资料可供查找。 Nginx 的作者和社区都在不断的努力完善，我们有理由相信 Nginx 将继续以高速的增长率来分享轻量级 HTTP 服务器市场，会有一个更美好的未来。 初探 Nginx 架构由 小路依依 创建， 最后一次修改 2016-08-12 初探 Nginx 架构众所周知，Nginx 性能高，而 Nginx 的高性能与其架构是分不开的。那么 Nginx 究竟是怎么样的呢？这一节我们先来初识一下 Nginx 框架吧。 Nginx 在启动后，在 unix 系统中会以 daemon 的方式在后台运行，后台进程包含一个 master 进程和多个 worker 进程。我们也可以手动地关掉后台模式，让 Nginx 在前台运行，并且通过配置让 Nginx 取消 master 进程，从而可以使 Nginx 以单进程方式运行。很显然，生产环境下我们肯定不会这么做，所以关闭后台模式，一般是用来调试用的，在后面的章节里面，我们会详细地讲解如何调试 Nginx。所以，我们可以看到，Nginx 是以多进程的方式来工作的，当然 Nginx 也是支持多线程的方式的，只是我们主流的方式还是多进程的方式，也是 Nginx 的默认方式。Nginx 采用多进程的方式有诸多好处，所以我就主要讲解 Nginx 的多进程模式吧。 刚才讲到，Nginx 在启动后，会有一个 master 进程和多个 worker 进程。master 进程主要用来管理 worker 进程，包含：接收来自外界的信号，向各 worker 进程发送信号，监控 worker 进程的运行状态，当 worker 进程退出后(异常情况下)，会自动重新启动新的 worker 进程。而基本的网络事件，则是放在 worker 进程中来处理了。多个 worker 进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。一个请求，只可能在一个 worker 进程中处理，一个 worker 进程，不可能处理其它进程的请求。worker 进程的个数是可以设置的，一般我们会设置与机器cpu核数一致，这里面的原因与 Nginx 的进程模型以及事件处理模型是分不开的。Nginx 的进程模型，可以由下图来表示： 在 Nginx 启动后，如果我们要操作 Nginx，要怎么做呢？从上文中我们可以看到，master 来管理 worker 进程，所以我们只需要与 master 进程通信就行了。master 进程会接收来自外界发来的信号，再根据信号做不同的事情。所以我们要控制 Nginx，只需要通过 kill 向 master 进程发送信号就行了。比如kill -HUP pid，则是告诉 Nginx，从容地重启 Nginx，我们一般用这个信号来重启 Nginx，或重新加载配置，因为是从容地重启，因此服务是不中断的。master 进程在接收到 HUP 信号后是怎么做的呢？首先 master 进程在接到信号后，会先重新加载配置文件，然后再启动新的 worker 进程，并向所有老的 worker 进程发送信号，告诉他们可以光荣退休了。新的 worker 在启动后，就开始接收新的请求，而老的 worker 在收到来自 master 的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后，再退出。当然，直接给 master 进程发送信号，这是比较老的操作方式，Nginx 在 0.8 版本之后，引入了一系列命令行参数，来方便我们管理。比如，./nginx -s reload，就是来重启 Nginx，./nginx -s stop，就是来停止 Nginx 的运行。如何做到的呢？我们还是拿 reload 来说，我们看到，执行命令时，我们是启动一个新的 Nginx 进程，而新的 Nginx 进程在解析到 reload 参数后，就知道我们的目的是控制 Nginx 来重新加载配置文件了，它会向 master 进程发送信号，然后接下来的动作，就和我们直接向 master 进程发送信号一样了。 现在，我们知道了当我们在操作 Nginx 的时候，Nginx 内部做了些什么事情，那么，worker 进程又是如何处理请求的呢？我们前面有提到，worker 进程之间是平等的，每个进程，处理请求的机会也是一样的。当我们提供 80 端口的 http 服务时，一个连接请求过来，每个进程都有可能处理这个连接，怎么做到的呢？首先，每个 worker 进程都是从 master 进程 fork 过来，在 master 进程里面，先建立好需要 listen 的 socket（listenfd）之后，然后再 fork 出多个 worker 进程。所有 worker 进程的 listenfd 会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有 worker 进程在注册 listenfd 读事件前抢 accept_mutex，抢到互斥锁的那个进程注册 listenfd 读事件，在读事件里调用 accept 接受该连接。当一个 worker 进程在 accept 这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由 worker 进程来处理，而且只在一个 worker 进程中处理。 那么，Nginx 采用这种进程模型有什么好处呢？当然，好处肯定会很多了。首先，对于每个 worker 进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。其次，采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master 进程则很快启动新的 worker 进程。当然，worker 进程的异常退出，肯定是程序有 bug 了，异常退出，会导致当前 worker 上的所有请求失败，不过不会影响到所有请求，所以降低了风险。当然，好处还有很多，大家可以慢慢体会。 上面讲了很多关于 Nginx 的进程模型，接下来，我们来看看 Nginx 是如何处理事件的。 有人可能要问了，Nginx 采用多 worker 的方式来处理请求，每个 worker 里面只有一个主线程，那能够处理的并发数很有限啊，多少个 worker 就能处理多少个并发，何来高并发呢？非也，这就是 Nginx 的高明之处，Nginx 采用了异步非阻塞的方式来处理请求，也就是说，Nginx 是可以同时处理成千上万个请求的。想想 apache 的常用工作方式（apache 也有异步非阻塞版本，但因其与自带某些模块冲突，所以不常用），每个请求会独占一个工作线程，当并发数上到几千时，就同时有几千的线程在处理请求了。这对操作系统来说，是个不小的挑战，线程带来的内存占用非常大，线程的上下文切换带来的 cpu 开销很大，自然性能就上不去了，而这些开销完全是没有意义的。 为什么 Nginx 可以采用异步非阻塞的方式来处理呢，或者异步非阻塞到底是怎么回事呢？我们先回到原点，看看一个请求的完整过程。首先，请求过来，要建立连接，然后再接收数据，接收数据后，再发送数据。具体到系统底层，就是读写事件，而当读写事件没有准备好时，必然不可操作，如果不用非阻塞的方式来调用，那就得阻塞调用了，事件没有准备好，那就只能等了，等事件准备好了，你再继续吧。阻塞调用会进入内核等待，cpu 就会让出去给别人用了，对单线程的 worker 来说，显然不合适，当网络事件越多时，大家都在等待呢，cpu 空闲下来没人用，cpu利用率自然上不去了，更别谈高并发了。好吧，你说加进程数，这跟apache的线程模型有什么区别，注意，别增加无谓的上下文切换。所以，在 Nginx 里面，最忌讳阻塞的系统调用了。不要阻塞，那就非阻塞喽。非阻塞就是，事件没有准备好，马上返回 EAGAIN，告诉你，事件还没准备好呢，你慌什么，过会再来吧。好吧，你过一会，再来检查一下事件，直到事件准备好了为止，在这期间，你就可以先去做其它事情，然后再来看看事件好了没。虽然不阻塞了，但你得不时地过来检查一下事件的状态，你可以做更多的事情了，但带来的开销也是不小的。所以，才会有了异步非阻塞的事件处理机制，具体到系统调用就是像 select/poll/epoll/kqueue 这样的系统调用。它们提供了一种机制，让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。这种机制正好解决了我们上面的两个问题，拿 epoll 为例(在后面的例子中，我们多以 epoll 为例子，以代表这一类函数)，当事件没准备好时，放到 epoll 里面，事件准备好了，我们就去读写，当读写返回 EAGAIN 时，我们将它再次加入到 epoll 里面。这样，只要有事件准备好了，我们就去处理它，只有当所有事件都没准备好时，才在 epoll 里面等着。这样，我们就可以并发处理大量的并发了，当然，这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的事件，事实上就是这样的。与多线程相比，这种事件处理方式是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。并发数再多也不会导致无谓的资源浪费（上下文切换）。更多的并发数，只是会占用更多的内存而已。 我之前有对连接数进行过测试，在 24G 内存的机器上，处理的并发请求数达到过 200 万。现在的网络服务器基本都采用这种方式，这也是nginx性能高效的主要原因。 我们之前说过，推荐设置 worker 的个数为 cpu 的核数，在这里就很容易理解了，更多的 worker 数，只会导致进程来竞争 cpu 资源了，从而带来不必要的上下文切换。而且，nginx为了更好的利用多核特性，提供了 cpu 亲缘性的绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来 cache 的失效。像这种小的优化在 Nginx 中非常常见，同时也说明了 Nginx 作者的苦心孤诣。比如，Nginx 在做 4 个字节的字符串比较时，会将 4 个字符转换成一个 int 型，再作比较，以减少 cpu 的指令数等等。 现在，知道了 Nginx 为什么会选择这样的进程模型与事件模型了。对于一个基本的 Web 服务器来说，事件通常有三种类型，网络事件、信号、定时器。从上面的讲解中知道，网络事件通过异步非阻塞可以很好的解决掉。如何处理信号与定时器？ 首先，信号的处理。对 Nginx 来说，有一些特定的信号，代表着特定的意义。信号会中断掉程序当前的运行，在改变状态后，继续执行。如果是系统调用，则可能会导致系统调用的失败，需要重入。关于信号的处理，大家可以学习一些专业书籍，这里不多说。对于 Nginx 来说，如果nginx正在等待事件（epoll_wait 时），如果程序收到信号，在信号处理函数处理完后，epoll_wait 会返回错误，然后程序可再次进入 epoll_wait 调用。 另外，再来看看定时器。由于 epoll_wait 等函数在调用的时候是可以设置一个超时时间的，所以 Nginx 借助这个超时时间来实现定时器。nginx里面的定时器事件是放在一颗维护定时器的红黑树里面，每次在进入 epoll_wait前，先从该红黑树里面拿到所有定时器事件的最小时间，在计算出 epoll_wait 的超时时间后进入 epoll_wait。所以，当没有事件产生，也没有中断信号时，epoll_wait 会超时，也就是说，定时器事件到了。这时，nginx会检查所有的超时事件，将他们的状态设置为超时，然后再去处理网络事件。由此可以看出，当我们写 Nginx 代码时，在处理网络事件的回调函数时，通常做的第一个事情就是判断超时，然后再去处理网络事件。 我们可以用一段伪代码来总结一下 Nginx 的事件处理模型： 12345678910111213141516171819202122while (true) &#123; for t in run_tasks: t.handler(); update_time(&amp;now); timeout = ETERNITY; for t in wait_tasks: /* sorted already */ if (t.time &lt;= now) &#123; t.timeout_handler(); &#125; else &#123; timeout = t.time - now; break; &#125; nevents = poll_function(events, timeout); for i in nevents: task t; if (events[i].type == READ) &#123; t.handler = read_handler; &#125; else &#123; /* events[i].type == WRITE */ t.handler = write_handler; &#125; run_tasks_add(t);&#125; 好，本节我们讲了进程模型，事件模型，包括网络事件，信号，定时器事件。 Nginx 基础概念由 小路依依 创建， 最后一次修改 2016-08-12 Nginx 基础概念connection在 Nginx 中 connection 就是对 tcp 连接的封装，其中包括连接的 socket，读事件，写事件。利用 Nginx 封装的 connection，我们可以很方便的使用 Nginx 来处理与连接相关的事情，比如，建立连接，发送与接受数据等。而 Nginx 中的 http 请求的处理就是建立在 connection之上的，所以 Nginx 不仅可以作为一个web服务器，也可以作为邮件服务器。当然，利用 Nginx 提供的 connection，我们可以与任何后端服务打交道。 结合一个 tcp 连接的生命周期，我们看看 Nginx 是如何处理一个连接的。首先，Nginx 在启动时，会解析配置文件，得到需要监听的端口与 ip 地址，然后在 Nginx 的 master 进程里面，先初始化好这个监控的 socket(创建 socket，设置 addrreuse 等选项，绑定到指定的 ip 地址端口，再 listen)，然后再 fork 出多个子进程出来，然后子进程会竞争 accept 新的连接。此时，客户端就可以向 Nginx 发起连接了。当客户端与服务端通过三次握手建立好一个连接后，Nginx 的某一个子进程会 accept 成功，得到这个建立好的连接的 socket，然后创建 Nginx 对连接的封装，即 ngx_connection_t 结构体。接着，设置读写事件处理函数并添加读写事件来与客户端进行数据的交换。最后，Nginx 或客户端来主动关掉连接，到此，一个连接就寿终正寝了。 当然，Nginx 也是可以作为客户端来请求其它 server 的数据的（如 upstream 模块），此时，与其它 server 创建的连接，也封装在 ngx_connection_t 中。作为客户端，Nginx 先获取一个 ngx_connection_t 结构体，然后创建 socket，并设置 socket 的属性（ 比如非阻塞）。然后再通过添加读写事件，调用 connect/read/write 来调用连接，最后关掉连接，并释放 ngx_connection_t。 在 Nginx 中，每个进程会有一个连接数的最大上限，这个上限与系统对 fd 的限制不一样。在操作系统中，通过 ulimit -n，我们可以得到一个进程所能够打开的 fd 的最大数，即 nofile，因为每个 socket 连接会占用掉一个 fd，所以这也会限制我们进程的最大连接数，当然也会直接影响到我们程序所能支持的最大并发数，当 fd 用完后，再创建 socket 时，就会失败。Nginx 通过设置 worker_connectons 来设置每个进程支持的最大连接数。如果该值大于 nofile，那么实际的最大连接数是 nofile，Nginx 会有警告。Nginx 在实现时，是通过一个连接池来管理的，每个 worker 进程都有一个独立的连接池，连接池的大小是 worker_connections。这里的连接池里面保存的其实不是真实的连接，它只是一个 worker_connections 大小的一个 ngx_connection_t 结构的数组。并且，Nginx 会通过一个链表 free_connections 来保存所有的空闲 ngx_connection_t，每次获取一个连接时，就从空闲连接链表中获取一个，用完后，再放回空闲连接链表里面。 在这里，很多人会误解 worker_connections 这个参数的意思，认为这个值就是 Nginx 所能建立连接的最大值。其实不然，这个值是表示每个 worker 进程所能建立连接的最大值，所以，一个 Nginx 能建立的最大连接数，应该是worker_connections * worker_processes。当然，这里说的是最大连接数，对于 HTTP 请求本地资源来说，能够支持的最大并发数量是worker_connections * worker_processes，而如果是 HTTP 作为反向代理来说，最大并发数量应该是worker_connections * worker_processes/2。因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。 那么，我们前面有说过一个客户端连接过来后，多个空闲的进程，会竞争这个连接，很容易看到，这种竞争会导致不公平，如果某个进程得到 accept 的机会比较多，它的空闲连接很快就用完了，如果不提前做一些控制，当 accept 到一个新的 tcp 连接后，因为无法得到空闲连接，而且无法将此连接转交给其它进程，最终会导致此 tcp 连接得不到处理，就中止掉了。很显然，这是不公平的，有的进程有空余连接，却没有处理机会，有的进程因为没有空余连接，却人为地丢弃连接。那么，如何解决这个问题呢？首先，Nginx 的处理得先打开 accept_mutex 选项，此时，只有获得了 accept_mutex 的进程才会去添加accept事件，也就是说，Nginx会控制进程是否添加 accept 事件。Nginx 使用一个叫 ngx_accept_disabled 的变量来控制是否去竞争 accept_mutex 锁。在第一段代码中，计算 ngx_accept_disabled 的值，这个值是 Nginx 单进程的所有连接总数的八分之一，减去剩下的空闲连接数量，得到的这个 ngx_accept_disabled 有一个规律，当剩余连接数小于总连接数的八分之一时，其值才大于 0，而且剩余的连接数越小，这个值越大。再看第二段代码，当 ngx_accept_disabled 大于 0 时，不会去尝试获取 accept_mutex 锁，并且将 ngx_accept_disabled 减 1，于是，每次执行到此处时，都会去减 1，直到小于 0。不去获取 accept_mutex 锁，就是等于让出获取连接的机会，很显然可以看出，当空余连接越少时，ngx_accept_disable 越大，于是让出的机会就越多，这样其它进程获取锁的机会也就越大。不去 accept，自己的连接就控制下来了，其它进程的连接池就会得到利用，这样，Nginx 就控制了多进程间连接的平衡了。 12345678910111213141516171819202122ngx_accept_disabled = ngx_cycle-&gt;connection_n / 8 - ngx_cycle-&gt;free_connection_n;if (ngx_accept_disabled &gt; 0) &#123; ngx_accept_disabled--;&#125; else &#123; if (ngx_trylock_accept_mutex(cycle) == NGX_ERROR) &#123; return; &#125; if (ngx_accept_mutex_held) &#123; flags |= NGX_POST_EVENTS; &#125; else &#123; if (timer == NGX_TIMER_INFINITE || timer &gt; ngx_accept_mutex_delay) &#123; timer = ngx_accept_mutex_delay; &#125; &#125;&#125; 好了，连接就先介绍到这，本章的目的是介绍基本概念，知道在 Nginx 中连接是个什么东西就行了，而且连接是属于比较高级的用法，在后面的模块开发高级篇会有专门的章节来讲解连接与事件的实现及使用。 request这节我们讲 request，在 Nginx 中我们指的是 http 请求，具体到 Nginx 中的数据结构是ngx_http_request_t。ngx_http_request_t 是对一个 http 请求的封装。 我们知道，一个 http 请求，包含请求行、请求头、请求体、响应行、响应头、响应体。 http 请求是典型的请求-响应类型的的网络协议，而 http 是文本协议，所以我们在分析请求行与请求头，以及输出响应行与响应头，往往是一行一行的进行处理。如果我们自己来写一个 http 服务器，通常在一个连接建立好后，客户端会发送请求过来。然后我们读取一行数据，分析出请求行中包含的 method、uri、http_version 信息。然后再一行一行处理请求头，并根据请求 method 与请求头的信息来决定是否有请求体以及请求体的长度，然后再去读取请求体。得到请求后，我们处理请求产生需要输出的数据，然后再生成响应行，响应头以及响应体。在将响应发送给客户端之后，一个完整的请求就处理完了。当然这是最简单的 webserver 的处理方式，其实 Nginx 也是这样做的，只是有一些小小的区别，比如，当请求头读取完成后，就开始进行请求的处理了。Nginx 通过 ngx_http_request_t 来保存解析请求与输出响应相关的数据。 那接下来，简要讲讲 Nginx 是如何处理一个完整的请求的。对于 Nginx 来说，一个请求是从ngx_http_init_request 开始的，在这个函数中，会设置读事件为 ngx_http_process_request_line，也就是说，接下来的网络事件，会由 ngx_http_process_request_line 来执行。从ngx_http_process_request_line 的函数名，我们可以看到，这就是来处理请求行的，正好与之前讲的，处理请求的第一件事就是处理请求行是一致的。通过 ngx_http_read_request_header 来读取请求数据。然后调用 ngx_http_parse_request_line 函数来解析请求行。Nginx 为提高效率，采用状态机来解析请求行，而且在进行 method 的比较时，没有直接使用字符串比较，而是将四个字符转换成一个整型，然后一次比较以减少 cpu 的指令数，这个前面有说过。很多人可能很清楚一个请求行包含请求的方法，uri，版本，却不知道其实在请求行中，也是可以包含有 host 的。比如一个请求 GET http://www.taobao.com/uri HTTP/1.0 这样一个请求行也是合法的，而且 host 是 www.taobao.com，这个时候，Nginx 会忽略请求头中的 host 域，而以请求行中的这个为准来查找虚拟主机。另外，对于对于 http0.9 版来说，是不支持请求头的，所以这里也是要特别的处理。所以，在后面解析请求头时，协议版本都是 1.0 或 1.1。整个请求行解析到的参数，会保存到 ngx_http_request_t 结构当中。 在解析完请求行后，Nginx 会设置读事件的 handler 为 ngx_http_process_request_headers，然后后续的请求就在 ngx_http_process_request_headers 中进行读取与解析。ngx_http_process_request_headers 函数用来读取请求头，跟请求行一样，还是调用 ngx_http_read_request_header 来读取请求头，调用 ngx_http_parse_header_line 来解析一行请求头，解析到的请求头会保存到 ngx_http_request_t 的域 headers_in 中，headers_in 是一个链表结构，保存所有的请求头。而 HTTP 中有些请求是需要特别处理的，这些请求头与请求处理函数存放在一个映射表里面，即 ngx_http_headers_in，在初始化时，会生成一个 hash 表，当每解析到一个请求头后，就会先在这个 hash 表中查找，如果有找到，则调用相应的处理函数来处理这个请求头。比如:Host 头的处理函数是 ngx_http_process_host。 当 Nginx 解析到两个回车换行符时，就表示请求头的结束，此时就会调用 ngx_http_process_request 来处理请求了。ngx_http_process_request 会设置当前的连接的读写事件处理函数为 ngx_http_request_handler，然后再调用 ngx_http_handler 来真正开始处理一个完整的http请求。这里可能比较奇怪，读写事件处理函数都是ngx_http_request_handler，其实在这个函数中，会根据当前事件是读事件还是写事件，分别调用 ngx_http_request_t 中的 read_event_handler 或者是 write_event_handler。由于此时，我们的请求头已经读取完成了，之前有说过，Nginx 的做法是先不读取请求 body，所以这里面我们设置 read_event_handler 为 ngx_http_block_reading，即不读取数据了。刚才说到，真正开始处理数据，是在 ngx_http_handler 这个函数里面，这个函数会设置 write_event_handler 为 ngx_http_core_run_phases，并执行 ngx_http_core_run_phases 函数。ngx_http_core_run_phases 这个函数将执行多阶段请求处理，Nginx 将一个 http 请求的处理分为多个阶段，那么这个函数就是执行这些阶段来产生数据。因为 ngx_http_core_run_phases 最后会产生数据，所以我们就很容易理解，为什么设置写事件的处理函数为 ngx_http_core_run_phases 了。在这里，我简要说明了一下函数的调用逻辑，我们需要明白最终是调用 ngx_http_core_run_phases 来处理请求，产生的响应头会放在 ngx_http_request_t 的 headers_out 中，这一部分内容，我会放在请求处理流程里面去讲。Nginx 的各种阶段会对请求进行处理，最后会调用 filter 来过滤数据，对数据进行加工，如 truncked 传输、gzip 压缩等。这里的 filter 包括 header filter 与 body filter，即对响应头或响应体进行处理。filter 是一个链表结构，分别有 header filter 与 body filter，先执行 header filter 中的所有 filter，然后再执行 body filter 中的所有 filter。在 header filter 中的最后一个 filter，即 ngx_http_header_filter，这个 filter 将会遍历所有的响应头，最后需要输出的响应头在一个连续的内存，然后调用 ngx_http_write_filter 进行输出。ngx_http_write_filter 是 body filter 中的最后一个，所以 Nginx 首先的 body 信息，在经过一系列的 body filter 之后，最后也会调用 ngx_http_write_filter 来进行输出(有图来说明)。 这里要注意的是，Nginx 会将整个请求头都放在一个 buffer 里面，这个 buffer 的大小通过配置项 client_header_buffer_size 来设置，如果用户的请求头太大，这个 buffer 装不下，那 Nginx 就会重新分配一个新的更大的 buffer 来装请求头，这个大 buffer 可以通过 large_client_header_buffers 来设置，这个 large_buffer 这一组 buffer，比如配置 48k，就是表示有四个 8k 大小的 buffer 可以用。注意，为了保存请求行或请求头的完整性，一个完整的请求行或请求头，需要放在一个连续的内存里面，所以，一个完整的请求行或请求头，只会保存在一个 buffer 里面。这样，如果请求行大于一个 buffer 的大小，就会返回 414 错误，如果一个请求头大小大于一个 buffer 大小，就会返回 400 错误。在了解了这些参数的值，以及 Nginx 实际的做法之后，在应用场景，我们就需要根据实际的需求来调整这些参数，来优化我们的程序了。 处理流程图： 以上这些，就是 Nginx 中一个 http 请求的生命周期了。我们再看看与请求相关的一些概念吧。 keepalive当然，在 Nginx 中，对于 http1.0 与 http1.1 也是支持长连接的。什么是长连接呢？我们知道，http 请求是基于 TCP 协议之上的，那么，当客户端在发起请求前，需要先与服务端建立 TCP 连接，而每一次的 TCP 连接是需要三次握手来确定的，如果客户端与服务端之间网络差一点，这三次交互消费的时间会比较多，而且三次交互也会带来网络流量。当然，当连接断开后，也会有四次的交互，当然对用户体验来说就不重要了。而 http 请求是请求应答式的，如果我们能知道每个请求头与响应体的长度，那么我们是可以在一个连接上面执行多个请求的，这就是所谓的长连接，但前提条件是我们先得确定请求头与响应体的长度。对于请求来说，如果当前请求需要有body，如 POST 请求，那么 Nginx 就需要客户端在请求头中指定 content-length 来表明 body 的大小，否则返回 400 错误。也就是说，请求体的长度是确定的，那么响应体的长度呢？先来看看 http 协议中关于响应 body 长度的确定： 对于 http1.0 协议来说，如果响应头中有 content-length 头，则以 content-length 的长度就可以知道 body 的长度了，客户端在接收 body 时，就可以依照这个长度来接收数据，接收完后，就表示这个请求完成了。而如果没有 content-length 头，则客户端会一直接收数据，直到服务端主动断开连接，才表示 body 接收完了。 而对于 http1.1 协议来说，如果响应头中的 Transfer-encoding 为 chunked 传输，则表示 body 是流式输出，body 会被分成多个块，每块的开始会标识出当前块的长度，此时，body 不需要通过长度来指定。如果是非 chunked 传输，而且有 content-length，则按照 content-length 来接收数据。否则，如果是非 chunked，并且没有 content-length，则客户端接收数据，直到服务端主动断开连接。 从上面，我们可以看到，除了 http1.0 不带 content-length 以及 http1.1 非 chunked 不带 content-length 外，body 的长度是可知的。此时，当服务端在输出完 body 之后，会可以考虑使用长连接。能否使用长连接，也是有条件限制的。如果客户端的请求头中的 connection为close，则表示客户端需要关掉长连接，如果为 keep-alive，则客户端需要打开长连接，如果客户端的请求中没有 connection 这个头，那么根据协议，如果是 http1.0，则默认为 close，如果是 http1.1，则默认为 keep-alive。如果结果为 keepalive，那么，Nginx 在输出完响应体后，会设置当前连接的 keepalive 属性，然后等待客户端下一次请求。当然，Nginx 不可能一直等待下去，如果客户端一直不发数据过来，岂不是一直占用这个连接？所以当 Nginx 设置了 keepalive 等待下一次的请求时，同时也会设置一个最大等待时间，这个时间是通过选项 keepalive_timeout 来配置的，如果配置为 0，则表示关掉 keepalive，此时，http 版本无论是 1.1 还是 1.0，客户端的 connection 不管是 close 还是 keepalive，都会强制为 close。 如果服务端最后的决定是 keepalive 打开，那么在响应的 http 头里面，也会包含有 connection 头域，其值是”Keep-Alive”，否则就是”Close”。如果 connection 值为 close，那么在 Nginx 响应完数据后，会主动关掉连接。所以，对于请求量比较大的 Nginx 来说，关掉 keepalive 最后会产生比较多的 time-wait 状态的 socket。一般来说，当客户端的一次访问，需要多次访问同一个 server 时，打开 keepalive 的优势非常大，比如图片服务器，通常一个网页会包含很多个图片。打开 keepalive 也会大量减少 time-wait 的数量。 pipe在 http1.1 中，引入了一种新的特性，即 pipeline。那么什么是 pipeline 呢？pipeline 其实就是流水线作业，它可以看作为 keepalive 的一种升华，因为 pipeline 也是基于长连接的，目的就是利用一个连接做多次请求。如果客户端要提交多个请求，对于keepalive来说，那么第二个请求，必须要等到第一个请求的响应接收完全后，才能发起，这和 TCP 的停止等待协议是一样的，得到两个响应的时间至少为2*RTT。而对 pipeline 来说，客户端不必等到第一个请求处理完后，就可以马上发起第二个请求。得到两个响应的时间可能能够达到1*RTT。Nginx 是直接支持 pipeline 的，但是，Nginx 对 pipeline 中的多个请求的处理却不是并行的，依然是一个请求接一个请求的处理，只是在处理第一个请求的时候，客户端就可以发起第二个请求。这样，Nginx 利用 pipeline 减少了处理完一个请求后，等待第二个请求的请求头数据的时间。其实 Nginx 的做法很简单，前面说到，Nginx 在读取数据时，会将读取的数据放到一个 buffer 里面，所以，如果 Nginx 在处理完前一个请求后，如果发现 buffer 里面还有数据，就认为剩下的数据是下一个请求的开始，然后就接下来处理下一个请求，否则就设置 keepalive。 lingering_closelingering_close，字面意思就是延迟关闭，也就是说，当 Nginx 要关闭连接时，并非立即关闭连接，而是先关闭 tcp 连接的写，再等待一段时间后再关掉连接的读。为什么要这样呢？我们先来看看这样一个场景。Nginx 在接收客户端的请求时，可能由于客户端或服务端出错了，要立即响应错误信息给客户端，而 Nginx 在响应错误信息后，大分部情况下是需要关闭当前连接。Nginx 执行完 write()系统调用把错误信息发送给客户端，write()系统调用返回成功并不表示数据已经发送到客户端，有可能还在 tcp 连接的 write buffer 里。接着如果直接执行 close()系统调用关闭 tcp 连接，内核会首先检查 tcp 的 read buffer 里有没有客户端发送过来的数据留在内核态没有被用户态进程读取，如果有则发送给客户端 RST 报文来关闭 tcp 连接丢弃 write buffer 里的数据，如果没有则等待 write buffer 里的数据发送完毕，然后再经过正常的 4 次分手报文断开连接。所以,当在某些场景下出现 tcp write buffer 里的数据在 write()系统调用之后到 close()系统调用执行之前没有发送完毕，且 tcp read buffer 里面还有数据没有读，close()系统调用会导致客户端收到 RST 报文且不会拿到服务端发送过来的错误信息数据。那客户端肯定会想，这服务器好霸道，动不动就 reset 我的连接，连个错误信息都没有。 在上面这个场景中，我们可以看到，关键点是服务端给客户端发送了 RST 包，导致自己发送的数据在客户端忽略掉了。所以，解决问题的重点是，让服务端别发 RST 包。再想想，我们发送 RST 是因为我们关掉了连接，关掉连接是因为我们不想再处理此连接了，也不会有任何数据产生了。对于全双工的 TCP 连接来说，我们只需要关掉写就行了，读可以继续进行，我们只需要丢掉读到的任何数据就行了，这样的话，当我们关掉连接后，客户端再发过来的数据，就不会再收到 RST 了。当然最终我们还是需要关掉这个读端的，所以我们会设置一个超时时间，在这个时间过后，就关掉读，客户端再发送数据来就不管了，作为服务端我会认为，都这么长时间了，发给你的错误信息也应该读到了，再慢就不关我事了，要怪就怪你 RP 不好了。当然，正常的客户端，在读取到数据后，会关掉连接，此时服务端就会在超时时间内关掉读端。这些正是 lingering_close 所做的事情。协议栈提供 SO_LINGER 这个选项，它的一种配置情况就是来处理 lingering_close 的情况的，不过 Nginx 是自己实现的 lingering_close。lingering_close 存在的意义就是来读取剩下的客户端发来的数据，所以 Nginx 会有一个读超时时间，通过 lingering_timeout 选项来设置，如果在 lingering_timeout 时间内还没有收到数据，则直接关掉连接。Nginx 还支持设置一个总的读取时间，通过 lingering_time 来设置，这个时间也就是 Nginx 在关闭写之后，保留 socket 的时间，客户端需要在这个时间内发送完所有的数据，否则 Nginx 在这个时间过后，会直接关掉连接。当然，Nginx 是支持配置是否打开 lingering_close 选项的，通过 lingering_close 选项来配置。 那么，我们在实际应用中，是否应该打开 lingering_close 呢？这个就没有固定的推荐值了，如 Maxim Dounin所说，lingering_close 的主要作用是保持更好的客户端兼容性，但是却需要消耗更多的额外资源（比如连接会一直占着）。 这节，我们介绍了 Nginx 中，连接与请求的基本概念，下节，我们讲基本的数据结构。 Nginx 基本数据结构由 小路依依 创建， 最后一次修改 2016-08-12 基本数据结构Nginx 的作者为追求极致的高效，自己实现了很多颇具特色的 Nginx 风格的数据结构以及公共函数。比如，Nginx 提供了带长度的字符串，根据编译器选项优化过的字符串拷贝函数 ngx_copy 等。所以，在我们写 Nginx 模块时，应该尽量调用 Nginx 提供的 api，尽管有些 api 只是对 glibc 的宏定义。本节，我们介绍 string、list、buffer、chain 等一系列最基本的数据结构及相关api的使用技巧以及注意事项。 ngx_str_t在 Nginx 源码目录的 src/core 下面的 ngx_string.h|c 里面，包含了字符串的封装以及字符串相关操作的 api。Nginx 提供了一个带长度的字符串结构 ngx_str_t，它的原型如下： 1234typedef struct &#123; size_t len; u_char *data;&#125; ngx_str_t; 在结构体当中，data 指向字符串数据的第一个字符，字符串的结束用长度来表示，而不是由&#39;\\0&#39;来表示结束。所以，在写 Nginx 代码时，处理字符串的方法跟我们平时使用有很大的不一样，但要时刻记住，字符串不以&#39;\\0&#39;结束，尽量使用 Nginx 提供的字符串操作的 api 来操作字符串。 那么，Nginx 这样做有什么好处呢？首先，通过长度来表示字符串长度，减少计算字符串长度的次数。其次，Nginx 可以重复引用一段字符串内存，data 可以指向任意内存，长度表示结束，而不用去 copy 一份自己的字符串(因为如果要以&#39;\\0&#39;结束，而不能更改原字符串，所以势必要 copy 一段字符串)。我们在 ngx_http_request_t 结构体的成员中，可以找到很多字符串引用一段内存的例子，比如 request_line、uri、args 等等，这些字符串的 data 部分，都是指向在接收数据时创建 buffer 所指向的内存中，uri，args 就没有必要 copy 一份出来。这样的话，减少了很多不必要的内存分配与拷贝。 正是基于此特性，在 Nginx 中，必须谨慎的去修改一个字符串。在修改字符串时需要认真的去考虑：是否可以修改该字符串；字符串修改后，是否会对其它的引用造成影响。在后面介绍 ngx_unescape_uri 函数的时候，就会看到这一点。但是，使用 Nginx 的字符串会产生一些问题，glibc 提供的很多系统 api 函数大多是通过&#39;\\0&#39;来表示字符串的结束，所以我们在调用系统 api 时，就不能直接传入 str-&gt;data 了。此时，通常的做法是创建一段 str-&gt;len + 1 大小的内存，然后 copy 字符串，最后一个字节置为&#39;\\0&#39;。比较 hack 的做法是，将字符串最后一个字符的后一个字符 backup 一个，然后设置为&#39;\\0&#39;，在做完调用后，再由 backup 改回来，但前提条件是，你得确定这个字符是可以修改的，而且是有内存分配，不会越界，但一般不建议这么做。接下来，看看 Nginx 提供的操作字符串相关的 api。 1#define ngx_string(str) &#123; sizeof(str) - 1, (u_char *) str &#125; ngx_string(str) 是一个宏，它通过一个以&#39;\\0&#39;结尾的普通字符串 str 构造一个 Nginx 的字符串，鉴于其中采用 sizeof 操作符计算字符串长度，因此参数必须是一个常量字符串。 1#define ngx_null_string &#123; 0, NULL &#125; 定义变量时，使用 ngx_null_string 初始化字符串为空字符串，符串的长度为 0，data 为 NULL。 12#define ngx_str_set(str, text) \ (str)-&gt;len = sizeof(text) - 1; (str)-&gt;data = (u_char *) text ngx_str_set 用于设置字符串 str 为 text，由于使用 sizeof 计算长度，故 text 必须为常量字符串。 1#define ngx_str_null(str) (str)-&gt;len = 0; (str)-&gt;data = NULL ngx_str_null 用于设置字符串 str 为空串，长度为 0，data 为 NULL。 上面这四个函数，使用时一定要小心，ngx_string 与 ngx_null_string 是“{，}”格式的，故只能用于赋值时初始化，如： 12ngx_str_t str = ngx_string(&quot;hello world&quot;);ngx_str_t str1 = ngx_null_string; 如果向下面这样使用，就会有问题，这里涉及到c语言中对结构体变量赋值操作的语法规则，在此不做介绍。 123ngx_str_t str, str1;str = ngx_string(&quot;hello world&quot;); // 编译出错str1 = ngx_null_string; // 编译出错 这种情况，可以调用 ngx_str_set 与 ngx_str_null 这两个函数来做: 123ngx_str_t str, str1;ngx_str_set(&amp;str, &quot;hello world&quot;); ngx_str_null(&amp;str1); 按照 C99 标准，您也可以这么做： 123ngx_str_t str, str1;str = (ngx_str_t) ngx_string(&quot;hello world&quot;);str1 = (ngx_str_t) ngx_null_string; 另外要注意的是，ngx_string 与 ngx_str_set 在调用时，传进去的字符串一定是常量字符串，否则会得到意想不到的错误(因为 ngx_str_set 内部使用了 sizeof()，如果传入的是 u_char*，那么计算的是这个指针的长度，而不是字符串的长度)。如： 123ngx_str_t str;u_char *a = &quot;hello world&quot;;ngx_str_set(&amp;str, a); // 问题产生 此外，值得注意的是，由于 ngx_str_set 与 ngx_str_null 实际上是两行语句，故在 if/for/while 等语句中单独使用需要用花括号括起来，例如： 123456ngx_str_t str;if (cond) ngx_str_set(&amp;str, &quot;true&quot;); // 问题产生else ngx_str_set(&amp;str, &quot;false&quot;); // 问题产生void ngx_strlow(u_char *dst, u_char *src, size_t n); 将 src 的前 n 个字符转换成小写存放在 dst 字符串当中，调用者需要保证 dst 指向的空间大于等于n，且指向的空间必须可写。操作不会对原字符串产生变动。如要更改原字符串，可以： 12ngx_strlow(str-&gt;data, str-&gt;data, str-&gt;len);ngx_strncmp(s1, s2, n) 区分大小写的字符串比较，只比较前n个字符。 1ngx_strcmp(s1, s2) 区分大小写的不带长度的字符串比较。 1ngx_int_t ngx_strcasecmp(u_char *s1, u_char *s2); 不区分大小写的不带长度的字符串比较。 1ngx_int_t ngx_strncasecmp(u_char *s1, u_char *s2, size_t n); 不区分大小写的带长度的字符串比较，只比较前 n 个字符。 123u_char * ngx_cdecl ngx_sprintf(u_char *buf, const char *fmt, ...);u_char * ngx_cdecl ngx_snprintf(u_char *buf, size_t max, const char *fmt, ...);u_char * ngx_cdecl ngx_slprintf(u_char *buf, u_char *last, const char *fmt, ...); 上面这三个函数用于字符串格式化，ngx_snprintf 的第二个参数 max 指明 buf 的空间大小，ngx_slprintf 则通过 last 来指明 buf 空间的大小。推荐使用第二个或第三个函数来格式化字符串，ngx_sprintf 函数还是比较危险的，容易产生缓冲区溢出漏洞。在这一系列函数中，Nginx 在兼容 glibc 中格式化字符串的形式之外，还添加了一些方便格式化 Nginx 类型的一些转义字符，比如%V用于格式化 ngx_str_t 结构。在 Nginx 源文件的 ngx_string.c 中有说明： 123456789101112131415161718192021222324252627282930/* * supported formats: * %[0][width][x][X]O off_t * %[0][width]T time_t * %[0][width][u][x|X]z ssize_t/size_t * %[0][width][u][x|X]d int/u_int * %[0][width][u][x|X]l long * %[0][width|m][u][x|X]i ngx_int_t/ngx_uint_t * %[0][width][u][x|X]D int32_t/uint32_t * %[0][width][u][x|X]L int64_t/uint64_t * %[0][width|m][u][x|X]A ngx_atomic_int_t/ngx_atomic_uint_t * %[0][width][.width]f double, max valid number fits to %18.15f * %P ngx_pid_t * %M ngx_msec_t * %r rlim_t * %p void * * %V ngx_str_t * * %v ngx_variable_value_t * * %s null-terminated string * %*s length and string * %Z &apos;\0&apos; * %N &apos;\n&apos; * %c char * %% % * * reserved: * %t ptrdiff_t * %S null-terminated wchar string * %C wchar */ 这里特别要提醒的是，我们最常用于格式化 ngx_str_t 结构，其对应的转义符是%V，传给函数的一定要是指针类型，否则程序就会 coredump 掉。这也是我们最容易犯的错。比如： 12345ngx_str_t str = ngx_string(&quot;hello world&quot;);u_char buffer[1024];ngx_snprintf(buffer, 1024, &quot;%V&quot;, &amp;str); // 注意，str取地址void ngx_encode_base64(ngx_str_t *dst, ngx_str_t *src);ngx_int_t ngx_decode_base64(ngx_str_t *dst, ngx_str_t *src); 这两个函数用于对 str 进行 base64 编码与解码，调用前，需要保证 dst 中有足够的空间来存放结果，如果不知道具体大小，可先调用 ngx_base64_encoded_length 与 ngx_base64_decoded_length 来预估最大占用空间。 12uintptr_t ngx_escape_uri(u_char *dst, u_char *src, size_t size, ngx_uint_t type); 对 src 进行编码，根据 type 来按不同的方式进行编码，如果 dst 为 NULL，则返回需要转义的字符的数量，由此可得到需要的空间大小。type 的类型可以是： 1234567#define NGX_ESCAPE_URI 0#define NGX_ESCAPE_ARGS 1#define NGX_ESCAPE_HTML 2#define NGX_ESCAPE_REFRESH 3#define NGX_ESCAPE_MEMCACHED 4#define NGX_ESCAPE_MAIL_AUTH 5void ngx_unescape_uri(u_char **dst, u_char **src, size_t size, ngx_uint_t type); 对 src 进行反编码，type 可以是 0、NGX_UNESCAPE_URI、NGX_UNESCAPE_REDIRECT 这三个值。如果是 0，则表示 src 中的所有字符都要进行转码。如果是 NGX_UNESCAPE_URI 与 NGX_UNESCAPE_REDIRECT，则遇到&#39;?&#39;后就结束了，后面的字符就不管了。而 NGX_UNESCAPE_URI 与 NGX_UNESCAPE_REDIRECT 之间的区别是 NGX_UNESCAPE_URI 对于遇到的需要转码的字符，都会转码，而 NGX_UNESCAPE_REDIRECT 则只会对非可见字符进行转码。 1uintptr_t ngx_escape_html(u_char *dst, u_char *src, size_t size); 对 html 标签进行编码。 当然，我这里只介绍了一些常用的 api 的使用，大家可以先熟悉一下，在实际使用过程中，遇到不明白的，最快最直接的方法就是去看源码，看 api 的实现或看 Nginx 自身调用 api 的地方是怎么做的，代码就是最好的文档。 ngx_pool_tngx_pool_t是一个非常重要的数据结构，在很多重要的场合都有使用，很多重要的数据结构也都在使用它。那么它究竟是一个什么东西呢？简单的说，它提供了一种机制，帮助管理一系列的资源（如内存，文件等），使得对这些资源的使用和释放统一进行，免除了使用过程中考虑到对各种各样资源的什么时候释放，是否遗漏了释放的担心。 例如对于内存的管理，如果我们需要使用内存，那么总是从一个 ngx_pool_t 的对象中获取内存，在最终的某个时刻，我们销毁这个 ngx_pool_t 对象，所有这些内存都被释放了。这样我们就不必要对对这些内存进行 malloc 和 free 的操作，不用担心是否某块被malloc出来的内存没有被释放。因为当 ngx_pool_t 对象被销毁的时候，所有从这个对象中分配出来的内存都会被统一释放掉。 再比如我们要使用一系列的文件，但是我们打开以后，最终需要都关闭，那么我们就把这些文件统一登记到一个 ngx_pool_t 对象中，当这个 ngx_pool_t 对象被销毁的时候，所有这些文件都将会被关闭。 从上面举的两个例子中我们可以看出，使用 ngx_pool_t 这个数据结构的时候，所有的资源的释放都在这个对象被销毁的时刻，统一进行了释放，那么就会带来一个问题，就是这些资源的生存周期（或者说被占用的时间）是跟 ngx_pool_t 的生存周期基本一致（ngx_pool_t 也提供了少量操作可以提前释放资源）。从最高效的角度来说，这并不是最好的。比如，我们需要依次使用 A，B，C 三个资源，且使用完 B 的时候，A 就不会再被使用了，使用C的时候 A 和 B 都不会被使用到。如果不使用 ngx_pool_t 来管理这三个资源，那我们可能从系统里面申请 A，使用 A，然后在释放 A。接着申请 B，使用 B，再释放 B。最后申请 C，使用 C，然后释放 C。但是当我们使用一个 ngx_pool_t 对象来管理这三个资源的时候，A，B 和 C 的释放是在最后一起发生的，也就是在使用完 C 以后。诚然，这在客观上增加了程序在一段时间的资源使用量。但是这也减轻了程序员分别管理三个资源的生命周期的工作。这也就是有所得，必有所失的道理。实际上是一个取舍的问题，要看在具体的情况下，你更在乎的是哪个。 可以看一下在 Nginx 里面一个典型的使用 ngx_pool_t 的场景，对于 Nginx 处理的每个 http request, Nginx 会生成一个 ngx_pool_t 对象与这个 http request 关联，所有处理过程中需要申请的资源都从这个 ngx_pool_t 对象中获取，当这个 http request 处理完成以后，所有在处理过程中申请的资源，都将随着这个关联的 ngx_pool_t 对象的销毁而释放。 ngx_pool_t 相关结构及操作被定义在文件src/core/ngx_palloc.h|c中。 1234567891011typedef struct ngx_pool_s ngx_pool_t; struct ngx_pool_s &#123; ngx_pool_data_t d; size_t max; ngx_pool_t *current; ngx_chain_t *chain; ngx_pool_large_t *large; ngx_pool_cleanup_t *cleanup; ngx_log_t *log;&#125;; 从 ngx_pool_t 的一般使用者的角度来说，可不用关注 ngx_pool_t 结构中各字段作用。所以这里也不会进行详细的解释，当然在说明某些操作函数的使用的时候，如有必要，会进行说明。 下面我们来分别解释下 ngx_pool_t 的相关操作。 1ngx_pool_t *ngx_create_pool(size_t size, ngx_log_t *log); 创建一个初始节点大小为 size 的 pool，log 为后续在该 pool 上进行操作时输出日志的对象。 需要说明的是 size 的选择，size 的大小必须小于等于 NGX_MAX_ALLOC_FROM_POOL，且必须大于 sizeof(ngx_pool_t)。 选择大于 NGX_MAX_ALLOC_FROM_POOL 的值会造成浪费，因为大于该限制的空间不会被用到（只是说在第一个由 ngx_pool_t 对象管理的内存块上的内存，后续的分配如果第一个内存块上的空闲部分已用完，会再分配的）。 选择小于 sizeof(ngx_pool_t)的值会造成程序崩溃。由于初始大小的内存块中要用一部分来存储 ngx_pool_t 这个信息本身。 当一个 ngx_pool_t 对象被创建以后，该对象的 max 字段被赋值为 size-sizeof(ngx_pool_t)和 NGX_MAX_ALLOC_FROM_POOL 这两者中比较小的。后续的从这个 pool 中分配的内存块，在第一块内存使用完成以后，如果要继续分配的话，就需要继续从操作系统申请内存。当内存的大小小于等于 max 字段的时候，则分配新的内存块，链接在 d 这个字段（实际上是 d.next 字段）管理的一条链表上。当要分配的内存块是比 max 大的，那么从系统中申请的内存是被挂接在 large 字段管理的一条链表上。我们暂且把这个称之为大块内存链和小块内存链。 1void *ngx_palloc(ngx_pool_t *pool, size_t size); 从这个 pool 中分配一块为 size 大小的内存。注意，此函数分配的内存的起始地址按照 NGX_ALIGNMENT 进行了对齐。对齐操作会提高系统处理的速度，但会造成少量内存的浪费。 1void *ngx_pnalloc(ngx_pool_t *pool, size_t size); 从这个 pool 中分配一块为 size 大小的内存。但是此函数分配的内存并没有像上面的函数那样进行过对齐。 .. code:: c 1void *ngx_pcalloc(ngx_pool_t *pool, size_t size); 该函数也是分配size大小的内存，并且对分配的内存块进行了清零。内部实际上是转调用ngx_palloc实现的。 1void *ngx_pmemalign(ngx_pool_t *pool, size_t size, size_t alignment); 按照指定对齐大小 alignment 来申请一块大小为 size 的内存。此处获取的内存不管大小都将被置于大内存块链中管理。 1ngx_int_t ngx_pfree(ngx_pool_t *pool, void *p); 对于被置于大块内存链，也就是被 large 字段管理的一列内存中的某块进行释放。该函数的实现是顺序遍历 large 管理的大块内存链表。所以效率比较低下。如果在这个链表中找到了这块内存，则释放，并返回 NGX_OK。否则返回 NGX_DECLINED。 由于这个操作效率比较低下，除非必要，也就是说这块内存非常大，确应及时释放，否则一般不需要调用。反正内存在这个 pool 被销毁的时候，总归会都释放掉的嘛！ 1ngx_pool_cleanup_t *ngx_pool_cleanup_add(ngx_pool_t *p, size_t size); ngx_pool_t 中的 cleanup 字段管理着一个特殊的链表，该链表的每一项都记录着一个特殊的需要释放的资源。对于这个链表中每个节点所包含的资源如何去释放，是自说明的。这也就提供了非常大的灵活性。意味着，ngx_pool_t 不仅仅可以管理内存，通过这个机制，也可以管理任何需要释放的资源，例如，关闭文件，或者删除文件等等。下面我们看一下这个链表每个节点的类型: 12345678typedef struct ngx_pool_cleanup_s ngx_pool_cleanup_t;typedef void (*ngx_pool_cleanup_pt)(void *data);struct ngx_pool_cleanup_s &#123; ngx_pool_cleanup_pt handler; void *data; ngx_pool_cleanup_t *next;&#125;; data: 指明了该节点所对应的资源。 handler: 是一个函数指针，指向一个可以释放 data 所对应资源的函数。该函数只有一个参数，就是 data。 next: 指向该链表中下一个元素。 看到这里，ngx_pool_cleanup_add 这个函数的用法，我相信大家都应该有一些明白了。但是这个参数 size 是起什么作用的呢？这个 size 就是要存储这个 data 字段所指向的资源的大小，该函数会为 data 分配 size 大小的空间。 比如我们需要最后删除一个文件。那我们在调用这个函数的时候，把 size 指定为存储文件名的字符串的大小，然后调用这个函数给 cleanup 链表中增加一项。该函数会返回新添加的这个节点。我们然后把这个节点中的 data 字段拷贝为文件名。把 hander 字段赋值为一个删除文件的函数（当然该函数的原型要按照 void (\*ngx_pool_cleanup_pt)(void \*data)）。 1void ngx_destroy_pool(ngx_pool_t *pool); 该函数就是释放 pool 中持有的所有内存，以及依次调用 cleanup 字段所管理的链表中每个元素的 handler 字段所指向的函数，来释放掉所有该 pool 管理的资源。并且把 pool 指向的 ngx_pool_t 也释放掉了，完全不可用了。 1void ngx_reset_pool(ngx_pool_t *pool); 该函数释放 pool 中所有大块内存链表上的内存，小块内存链上的内存块都修改为可用。但是不会去处理 cleanup链表上的项目。 ngx_array_tngx_array_t 是 Nginx 内部使用的数组结构。Nginx 的数组结构在存储上与大家认知的 C 语言内置的数组有相似性，比如实际上存储数据的区域也是一大块连续的内存。但是数组除了存储数据的内存以外还包含一些元信息来描述相关的一些信息。下面我们从数组的定义上来详细的了解一下。ngx_array_t 的定义位于src/core/ngx_array.c|h里面。 12345678typedef struct ngx_array_s ngx_array_t;struct ngx_array_s &#123; void *elts; ngx_uint_t nelts; size_t size; ngx_uint_t nalloc; ngx_pool_t *pool;&#125;; elts: 指向实际的数据存储区域。 nelts: 数组实际元素个数。 size: 数组单个元素的大小，单位是字节。 nalloc: 数组的容量。表示该数组在不引发扩容的前提下，可以最多存储的元素的个数。当 nelts 增长到达 nalloc 时，如果再往此数组中存储元素，则会引发数组的扩容。数组的容量将会扩展到原有容量的 2 倍大小。实际上是分配新的一块内存，新的一块内存的大小是原有内存大小的 2 倍。原有的数据会被拷贝到新的一块内存中。 pool: 该数组用来分配内存的内存池。 下面介绍 ngx_array_t 相关操作函数。 1ngx_array_t *ngx_array_create(ngx_pool_t *p, ngx_uint_t n, size_t size); 创建一个新的数组对象，并返回这个对象。 p: 数组分配内存使用的内存池； n: 数组的初始容量大小，即在不扩容的情况下最多可以容纳的元素个数。 size: 单个元素的大小，单位是字节。 1void ngx_array_destroy(ngx_array_t *a); 销毁该数组对象，并释放其分配的内存回内存池。 1void *ngx_array_push(ngx_array_t *a); 在数组 a 上新追加一个元素，并返回指向新元素的指针。需要把返回的指针使用类型转换，转换为具体的类型，然后再给新元素本身或者是各字段（如果数组的元素是复杂类型）赋值。 1void *ngx_array_push_n(ngx_array_t *a, ngx_uint_t n); 在数组 a 上追加 n 个元素，并返回指向这些追加元素的首个元素的位置的指针。 1static ngx_inline ngx_int_t ngx_array_init(ngx_array_t *array, ngx_pool_t *pool, ngx_uint_t n, size_t size); 如果一个数组对象是被分配在堆上的，那么当调用 ngx_array_destroy 销毁以后，如果想再次使用，就可以调用此函数。 如果一个数组对象是被分配在栈上的，那么就需要调用此函数，进行初始化的工作以后，才可以使用。 注意事项由于使用 ngx_palloc 分配内存，数组在扩容时，旧的内存不会被释放，会造成内存的浪费。因此，最好能提前规划好数组的容量，在创建或者初始化的时候一次搞定，避免多次扩容，造成内存浪费。 ngx_hash_tngx_hash_t 是 Nginx 自己的 hash 表的实现。定义和实现位于src/core/ngx_hash.h|c中。ngx_hash_t 的实现也与数据结构教科书上所描述的 hash 表的实现是大同小异。对于常用的解决冲突的方法有线性探测，二次探测和开链法等。ngx_hash_t 使用的是最常用的一种，也就是开链法，这也是 STL 中的 hash 表使用的方法。 但是 ngx_hash_t 的实现又有其几个显著的特点: ngx_hash_t 不像其他的 hash 表的实现，可以插入删除元素，它只能一次初始化，就构建起整个 hash 表以后，既不能再删除，也不能在插入元素了。 ngx_hash_t 的开链并不是真的开了一个链表，实际上是开了一段连续的存储空间，几乎可以看做是一个数组。这是因为 ngx_hash_t 在初始化的时候，会经历一次预计算的过程，提前把每个桶里面会有多少元素放进去给计算出来，这样就提前知道每个桶的大小了。那么就不需要使用链表，一段连续的存储空间就足够了。这也从一定程度上节省了内存的使用。 从上面的描述，我们可以看出来，这个值越大，越造成内存的浪费。就两步，首先是初始化，然后就可以在里面进行查找了。下面我们详细来看一下。 ngx_hash_t 的初始化。 12ngx_int_t ngx_hash_init(ngx_hash_init_t *hinit, ngx_hash_key_t *names,ngx_uint_t nelts); 首先我们来看一下初始化函数。该函数的第一个参数 hinit 是初始化的一些参数的一个集合。 names 是初始化一个 ngx_hash_t 所需要的所有 key 的一个数组。而 nelts 就是 key 的个数。下面先看一下 ngx_hash_init_t 类型，该类型提供了初始化一个 hash 表所需要的一些基本信息。 1234567891011typedef struct &#123; ngx_hash_t *hash; ngx_hash_key_pt key; ngx_uint_t max_size; ngx_uint_t bucket_size; char *name; ngx_pool_t *pool; ngx_pool_t *temp_pool;&#125; ngx_hash_init_t; hash: 该字段如果为 NULL，那么调用完初始化函数后，该字段指向新创建出来的 hash 表。如果该字段不为 NULL，那么在初始的时候，所有的数据被插入了这个字段所指的 hash 表中。 key: 指向从字符串生成 hash 值的 hash 函数。Nginx 的源代码中提供了默认的实现函数 ngx_hash_key_lc。 max_size: hash 表中的桶的个数。该字段越大，元素存储时冲突的可能性越小，每个桶中存储的元素会更少，则查询起来的速度更快。当然，这个值越大，越造成内存的浪费也越大，(实际上也浪费不了多少)。 :bucket_size: 每个桶的最大限制大小，单位是字节。如果在初始化一个 hash 表的时候，发现某个桶里面无法存的下所有属于该桶的元素，则 hash 表初始化失败。 name: 该 hash 表的名字。 pool: 该 hash 表分配内存使用的 pool。 temp_pool: 该 hash 表使用的临时 pool，在初始化完成以后，该 pool 可以被释放和销毁掉。 下面来看一下存储 hash 表 key 的数组的结构。 12345typedef struct &#123; ngx_str_t key; ngx_uint_t key_hash; void *value;&#125; ngx_hash_key_t; key 和 value 的含义显而易见，就不用解释了。key_hash 是对 key 使用 hash 函数计算出来的值。 对这两个结构分析完成以后，我想大家应该都已经明白这个函数应该是如何使用了吧。该函数成功初始化一个 hash 表以后，返回 NGX_OK，否则返回 NGX_ERROR。 1void *ngx_hash_find(ngx_hash_t *hash, ngx_uint_t key, u_char *name, size_t len); 在 hash 里面查找 key 对应的 value。实际上这里的 key 是对真正的 key（也就是 name）计算出的 hash 值。len 是 name 的长度。 如果查找成功，则返回指向 value 的指针，否则返回 NULL。 ngx_hash_wildcard_tNginx 为了处理带有通配符的域名的匹配问题，实现了 ngx_hash_wildcard_t 这样的 hash 表。他可以支持两种类型的带有通配符的域名。一种是通配符在前的，例如：\*.abc.com，也可以省略掉星号，直接写成.abc.com。这样的 key，可以匹配 www.abc.com，qqq.www.abc.com 之类的。另外一种是通配符在末尾的，例如：mail.xxx.\*，请特别注意通配符在末尾的不像位于开始的通配符可以被省略掉。这样的通配符，可以匹配 mail.xxx.com、mail.xxx.com.cn、mail.xxx.net 之类的域名。 有一点必须说明，就是一个 ngx_hash_wildcard_t 类型的 hash 表只能包含通配符在前的key或者是通配符在后的key。不能同时包含两种类型的通配符的 key。ngx_hash_wildcard_t 类型变量的构建是通过函数 ngx_hash_wildcard_init 完成的，而查询是通过函数 ngx_hash_find_wc_head 或者 ngx_hash_find_wc_tail 来做的。ngx_hash_find_wc_head 查询包含通配符在前的 key 的 hash 表的，而 ngx_hash_find_wc_tail 是查询包含通配符在后的 key 的 hash 表的。 下面详细说明这几个函数的用法。 12ngx_int_t ngx_hash_wildcard_init(ngx_hash_init_t *hinit, ngx_hash_key_t *names, ngx_uint_t nelts); 该函数用来构建一个可以包含通配符 key 的 hash 表。 hinit: 构造一个通配符 hash 表的一些参数的一个集合。关于该参数对应的类型的说明，请参见 ngx_hash_t 类型中 ngx_hash_init 函数的说明。 names: 构造此 hash 表的所有的通配符 key 的数组。特别要注意的是这里的 key 已经都是被预处理过的。例如：\*.abc.com或者.abc.com被预处理完成以后，变成了com.abc.。而mail.xxx.\*则被预处理为mail.xxx.。为什么会被处理这样？这里不得不简单地描述一下通配符 hash 表的实现原理。当构造此类型的 hash 表的时候，实际上是构造了一个 hash 表的一个“链表”，是通过 hash 表中的 key “链接”起来的。比如：对于\*.abc.com将会构造出 2 个 hash 表，第一个 hash 表中有一个 key 为 com 的表项，该表项的 value 包含有指向第二个 hash 表的指针，而第二个 hash 表中有一个表项 abc，该表项的 value 包含有指向\*.abc.com对应的 value 的指针。那么查询的时候，比如查询 www.abc.com 的时候，先查 com，通过查 com 可以找到第二级的 hash 表，在第二级 hash 表中，再查找 abc，依次类推，直到在某一级的 hash 表中查到的表项对应的 value 对应一个真正的值而非一个指向下一级 hash 表的指针的时候，查询过程结束。这里有一点需要特别注意的，就是 names 数组中元素的 value 值低两位 bit 必须为 0（有特殊用途）。如果不满足这个条件，这个 hash 表查询不出正确结果。 nelts: names 数组元素的个数。 该函数执行成功返回 NGX_OK，否则 NGX_ERROR。 1void *ngx_hash_find_wc_head(ngx_hash_wildcard_t *hwc, u_char *name, size_t len); 该函数查询包含通配符在前的 key 的 hash 表的。 hwc: hash 表对象的指针。 name: 需要查询的域名，例如: www.abc.com。 len: name 的长度。 该函数返回匹配的通配符对应 value。如果没有查到，返回 NULL。 1void *ngx_hash_find_wc_tail(ngx_hash_wildcard_t *hwc, u_char *name, size_t len); 该函数查询包含通配符在末尾的 key 的 hash 表的。 参数及返回值请参加上个函数的说明。 ngx_hash_combined_t组合类型 hash 表，该 hash 表的定义如下： 12345typedef struct &#123; ngx_hash_t hash; ngx_hash_wildcard_t *wc_head; ngx_hash_wildcard_t *wc_tail;&#125; ngx_hash_combined_t; 从其定义显见，该类型实际上包含了三个 hash 表，一个普通 hash 表，一个包含前向通配符的 hash 表和一个包含后向通配符的 hash 表。 Nginx 提供该类型的作用，在于提供一个方便的容器包含三个类型的 hash 表，当有包含通配符的和不包含通配符的一组 key 构建 hash 表以后，以一种方便的方式来查询，你不需要再考虑一个 key 到底是应该到哪个类型的 hash 表里去查了。 构造这样一组合 hash 表的时候，首先定义一个该类型的变量，再分别构造其包含的三个子 hash 表即可。 对于该类型 hash 表的查询，Nginx 提供了一个方便的函数 ngx_hash_find_combined。 12void *ngx_hash_find_combined(ngx_hash_combined_t *hash, ngx_uint_t key,u_char *name, size_t len); 该函数在此组合 hash 表中，依次查询其三个子 hash 表，看是否匹配，一旦找到，立即返回查找结果，也就是说如果有多个可能匹配，则只返回第一个匹配的结果。 hash: 此组合 hash 表对象。 key: 根据 name 计算出的 hash 值。 name: key 的具体内容。 len: name 的长度。 返回查询的结果，未查到则返回 NULL。 ngx_hash_keys_arrays_t大家看到在构建一个 ngx_hash_wildcard_t 的时候，需要对通配符的哪些 key 进行预处理。这个处理起来比较麻烦。而当有一组 key，这些里面既有无通配符的 key，也有包含通配符的 key 的时候。我们就需要构建三个 hash 表，一个包含普通的 key 的 hash 表，一个包含前向通配符的 hash 表，一个包含后向通配符的 hash 表（或者也可以把这三个 hash 表组合成一个 ngx_hash_combined_t）。在这种情况下，为了让大家方便的构造这些 hash 表，Nginx 提供给了此辅助类型。 该类型以及相关的操作函数也定义在src/core/ngx_hash.h|c里。我们先来看一下该类型的定义。 123456789101112131415typedef struct &#123; ngx_uint_t hsize; ngx_pool_t *pool; ngx_pool_t *temp_pool; ngx_array_t keys; ngx_array_t *keys_hash; ngx_array_t dns_wc_head; ngx_array_t *dns_wc_head_hash; ngx_array_t dns_wc_tail; ngx_array_t *dns_wc_tail_hash;&#125; ngx_hash_keys_arrays_t; hsize: 将要构建的 hash 表的桶的个数。对于使用这个结构中包含的信息构建的三种类型的 hash 表都会使用此参数。 pool: 构建这些 hash 表使用的 pool。 temp_pool: 在构建这个类型以及最终的三个 hash 表过程中可能用到临时 pool。该 temp_pool 可以在构建完成以后，被销毁掉。这里只是存放临时的一些内存消耗。 keys: 存放所有非通配符 key 的数组。 keys_hash: 这是个二维数组，第一个维度代表的是 bucket 的编号，那么 keys_hash[i] 中存放的是所有的 key 算出来的 hash 值对 hsize 取模以后的值为 i 的 key。假设有 3 个 key,分别是 key1,key2 和 key3 假设 hash 值算出来以后对 hsize 取模的值都是 i，那么这三个 key 的值就顺序存放在keys_hash[i][0],keys_hash[i][1], keys_hash[i][2]。该值在调用的过程中用来保存和检测是否有冲突的 key 值，也就是是否有重复。 dns_wc_head: 放前向通配符 key 被处理完成以后的值。比如：\*.abc.com 被处理完成以后，变成 “com.abc.” 被存放在此数组中。 dns_wc_tail: 存放后向通配符 key 被处理完成以后的值。比如：mail.xxx.\* 被处理完成以后，变成 “mail.xxx.” 被存放在此数组中。 dns_wc_head_hash: 该值在调用的过程中用来保存和检测是否有冲突的前向通配符的 key 值，也就是是否有重复。 dns_wc_tail_hash: 该值在调用的过程中用来保存和检测是否有冲突的后向通配符的 key 值，也就是是否有重复。 在定义一个这个类型的变量，并对字段 pool 和 temp_pool 赋值以后，就可以调用函数 ngx_hash_add_key 把所有的 key 加入到这个结构中了，该函数会自动实现普通 key，带前向通配符的 key 和带后向通配符的 key 的分类和检查，并将这个些值存放到对应的字段中去，然后就可以通过检查这个结构体中的 keys、dns_wc_head、dns_wc_tail 三个数组是否为空，来决定是否构建普通 hash 表，前向通配符 hash 表和后向通配符 hash 表了（在构建这三个类型的 hash 表的时候，可以分别使用 keys、dns_wc_head、dns_wc_tail三个数组）。 构建出这三个 hash 表以后，可以组合在一个 ngx_hash_combined_t 对象中，使用 ngx_hash_find_combined 进行查找。或者是仍然保持三个独立的变量对应这三个 hash 表，自己决定何时以及在哪个 hash 表中进行查询。 1ngx_int_t ngx_hash_keys_array_init(ngx_hash_keys_arrays_t *ha, ngx_uint_t type); 初始化这个结构，主要是对这个结构中的 ngx_array_t 类型的字段进行初始化，成功返回 NGX_OK。 ha: 该结构的对象指针。 type: 该字段有 2 个值可选择，即 NGX_HASH_SMALL 和 NGX_HASH_LARGE。用来指明将要建立的 hash 表的类型，如果是 NGX_HASH_SMALL，则有比较小的桶的个数和数组元素大小。NGX_HASH_LARGE 则相反。 12ngx_int_t ngx_hash_add_key(ngx_hash_keys_arrays_t *ha, ngx_str_t *key,void *value, ngx_uint_t flags); 一般是循环调用这个函数，把一组键值对加入到这个结构体中。返回 NGX_OK 是加入成功。返回 NGX_BUSY 意味着key值重复。 ha: 该结构的对象指针。 key: 参数名自解释了。 value: 参数名自解释了。 flags: 有两个标志位可以设置，NGX_HASH_WILDCARD_KEY 和 NGX_HASH_READONLY_KEY。同时要设置的使用逻辑与操作符就可以了。NGX_HASH_READONLY_KEY 被设置的时候，在计算 hash 值的时候，key 的值不会被转成小写字符，否则会。NGX_HASH_WILDCARD_KEY 被设置的时候，说明 key 里面可能含有通配符，会进行相应的处理。如果两个标志位都不设置，传 0。 有关于这个数据结构的使用，可以参考src/http/ngx_http.c中的 ngx_http_server_names 函数。 ngx_chain_tNginx 的 filter 模块在处理从别的 filter 模块或者是 handler 模块传递过来的数据（实际上就是需要发送给客户端的 http response）。这个传递过来的数据是以一个链表的形式(ngx_chain_t)。而且数据可能被分多次传递过来。也就是多次调用 filter 的处理函数，以不同的 ngx_chain_t。 该结构被定义在src/core/ngx_buf.h|c。下面我们来看一下 ngx_chain_t 的定义。 123456typedef struct ngx_chain_s ngx_chain_t;struct ngx_chain_s &#123; ngx_buf_t *buf; ngx_chain_t *next;&#125;; 就 2 个字段，next 指向这个链表的下个节点。buf 指向实际的数据。所以在这个链表上追加节点也是非常容易，只要把末尾元素的 next 指针指向新的节点，把新节点的 next 赋值为 NULL 即可。 1ngx_chain_t *ngx_alloc_chain_link(ngx_pool_t *pool); 该函数创建一个 ngx_chain_t 的对象，并返回指向对象的指针，失败返回 NULL。 123#define ngx_free_chain(pool, cl) \ cl-&gt;next = pool-&gt;chain; \pool-&gt;chain = cl 该宏释放一个 ngx_chain_t 类型的对象。如果要释放整个 chain，则迭代此链表，对每个节点使用此宏即可。 注意: 对 ngx_chaint_t 类型的释放，并不是真的释放了内存，而仅仅是把这个对象挂在了这个 pool 对象的一个叫做 chain 的字段对应的 chain 上，以供下次从这个 pool 上分配 ngx_chain_t 类型对象的时候，快速的从这个 pool-&gt;chain上 取下链首元素就返回了，当然，如果这个链是空的，才会真的在这个 pool 上使用 ngx_palloc 函数进行分配。 ngx_buf_t这个 ngx_buf_t 就是这个 ngx_chain_t 链表的每个节点的实际数据。该结构实际上是一种抽象的数据结构，它代表某种具体的数据。这个数据可能是指向内存中的某个缓冲区，也可能指向一个文件的某一部分，也可能是一些纯元数据（元数据的作用在于指示这个链表的读取者对读取的数据进行不同的处理）。 该数据结构位于src/core/ngx_buf.h|c文件中。我们来看一下它的定义。 123456789101112131415161718192021222324252627282930313233343536struct ngx_buf_s &#123; u_char *pos; u_char *last; off_t file_pos; off_t file_last; u_char *start; /* start of buffer */ u_char *end; /* end of buffer */ ngx_buf_tag_t tag; ngx_file_t *file; ngx_buf_t *shadow; /* the buf's content could be changed */ unsigned temporary:1; /* * the buf's content is in a memory cache or in a read only memory * and must not be changed */ unsigned memory:1; /* the buf's content is mmap()ed and must not be changed */ unsigned mmap:1; unsigned recycled:1; unsigned in_file:1; unsigned flush:1; unsigned sync:1; unsigned last_buf:1; unsigned last_in_chain:1; unsigned last_shadow:1; unsigned temp_file:1; /* STUB */ int num;&#125;; pos：当 buf 所指向的数据在内存里的时候，pos 指向的是这段数据开始的位置。 last：当 buf 所指向的数据在内存里的时候，last 指向的是这段数据结束的位置。 file_pos：当 buf 所指向的数据是在文件里的时候，file_pos 指向的是这段数据的开始位置在文件中的偏移量。 file_last：当 buf 所指向的数据是在文件里的时候，file_last 指向的是这段数据的结束位置在文件中的偏移量。 start：当 buf 所指向的数据在内存里的时候，这一整块内存包含的内容可能被包含在多个 buf 中(比如在某段数据中间插入了其他的数据，这一块数据就需要被拆分开)。那么这些 buf 中的 start 和 end 都指向这一块内存的开始地址和结束地址。而 pos 和 last 指向本 buf 所实际包含的数据的开始和结尾。 end：解释参见 start。 tag：实际上是一个void *类型的指针，使用者可以关联任意的对象上去，只要对使用者有意义。 file：当 buf 所包含的内容在文件中时，file字段指向对应的文件对象。 shadow：当这个 buf 完整 copy 了另外一个 buf 的所有字段的时候，那么这两个 buf 指向的实际上是同一块内存，或者是同一个文件的同一部分，此时这两个 buf 的 shadow 字段都是指向对方的。那么对于这样的两个 buf，在释放的时候，就需要使用者特别小心，具体是由哪里释放，要提前考虑好，如果造成资源的多次释放，可能会造成程序崩溃！ temporary：为 1 时表示该 buf 所包含的内容是在一个用户创建的内存块中，并且可以被在 filter 处理的过程中进行变更，而不会造成问题。 memory：为 1 时表示该 buf 所包含的内容是在内存中，但是这些内容却不能被进行处理的 filter 进行变更。 mmap：为 1 时表示该 buf 所包含的内容是在内存中, 是通过 mmap 使用内存映射从文件中映射到内存中的，这些内容却不能被进行处理的 filter 进行变更。 recycled：可以回收的。也就是这个 buf 是可以被释放的。这个字段通常是配合 shadow 字段一起使用的，对于使用 ngx_create_temp_buf 函数创建的 buf，并且是另外一个 buf 的 shadow，那么可以使用这个字段来标示这个buf是可以被释放的。 in_file：为 1 时表示该 buf 所包含的内容是在文件中。 flush：遇到有 flush 字段被设置为 1 的 buf 的 chain，则该 chain 的数据即便不是最后结束的数据（last_buf被设置，标志所有要输出的内容都完了），也会进行输出，不会受 postpone_output 配置的限制，但是会受到发送速率等其他条件的限制。 last_buf：数据被以多个 chain 传递给了过滤器，此字段为 1 表明这是最后一个 buf。 last_in_chain：在当前的 chain 里面，此 buf 是最后一个。特别要注意的是 last_in_chain 的 buf 不一定是last_buf，但是 last_buf 的 buf 一定是 last_in_chain 的。这是因为数据会被以多个 chain 传递给某 个filter 模块。 last_shadow：在创建一个 buf 的 shadow 的时候，通常将新创建的一个 buf 的 last_shadow 置为 1。 temp_file:由于受到内存使用的限制，有时候一些 buf 的内容需要被写到磁盘上的临时文件中去，那么这时，就设置此标志。 对于此对象的创建，可以直接在某个 ngx_pool_t 上分配，然后根据需要，给对应的字段赋值。也可以使用定义好的 2 个宏： 12#define ngx_alloc_buf(pool) ngx_palloc(pool, sizeof(ngx_buf_t))#define ngx_calloc_buf(pool) ngx_pcalloc(pool, sizeof(ngx_buf_t)) 这两个宏使用类似函数，也是不说自明的。 对于创建 temporary 字段为 1 的 buf（就是其内容可以被后续的 filter 模块进行修改），可以直接使用函数 ngx_create_temp_buf 进行创建。 1ngx_buf_t *ngx_create_temp_buf(ngx_pool_t *pool, size_t size); 该函数创建一个 ngx_buf_t 类型的对象，并返回指向这个对象的指针，创建失败返回 NULL。 对于创建的这个对象，它的 start 和 end 指向新分配内存开始和结束的地方。pos 和 last 都指向这块新分配内存的开始处，这样，后续的操作可以在这块新分配的内存上存入数据。 pool: 分配该 buf 和 buf 使用的内存所使用的 pool。 size: 该 buf 使用的内存的大小。 为了配合对 ngx_buf_t 的使用，Nginx 定义了以下的宏方便操作。 1#define ngx_buf_in_memory(b) (b-&gt;temporary || b-&gt;memory || b-&gt;mmap) 返回这个 buf 里面的内容是否在内存里。 1#define ngx_buf_in_memory_only(b) (ngx_buf_in_memory(b) &amp;&amp; !b-&gt;in_file) 返回这个 buf 里面的内容是否仅仅在内存里，并且没有在文件里。 123#define ngx_buf_special(b) \ ((b-&gt;flush || b-&gt;last_buf || b-&gt;sync) \ &amp;&amp; !ngx_buf_in_memory(b) &amp;&amp; !b-&gt;in_file) 返回该 buf 是否是一个特殊的 buf，只含有特殊的标志和没有包含真正的数据。 123#define ngx_buf_sync_only(b) \ (b-&gt;sync \ &amp;&amp; !ngx_buf_in_memory(b) &amp;&amp; !b-&gt;in_file &amp;&amp; !b-&gt;flush &amp;&amp; !b-&gt;last_buf) 返回该 buf 是否是一个只包含 sync 标志而不包含真正数据的特殊 buf。 123#define ngx_buf_size(b) \ (ngx_buf_in_memory(b) ? (off_t) (b-&gt;last - b-&gt;pos): \ (b-&gt;file_last - b-&gt;file_pos)) 返回该 buf 所含数据的大小，不管这个数据是在文件里还是在内存里。 ngx_list_tngx_list_t 顾名思义，看起来好像是一个 list 的数据结构。这样的说法，算对也不算对。因为它符合 list 类型数据结构的一些特点，比如可以添加元素，实现自增长，不会像数组类型的数据结构，受到初始设定的数组容量的限制，并且它跟我们常见的 list 型数据结构也是一样的，内部实现使用了一个链表。 那么它跟我们常见的链表实现的 list 有什么不同呢？不同点就在于它的节点，它的节点不像我们常见的 list 的节点，只能存放一个元素，ngx_list_t 的节点实际上是一个固定大小的数组。 在初始化的时候，我们需要设定元素需要占用的空间大小，每个节点数组的容量大小。在添加元素到这个 list 里面的时候，会在最尾部的节点里的数组上添加元素，如果这个节点的数组存满了，就再增加一个新的节点到这个 list 里面去。 好了，看到这里，大家应该基本上明白这个 list 结构了吧？还不明白也没有关系，下面我们来具体看一下它的定义，这些定义和相关的操作函数定义在src/core/ngx_list.h|c文件中。 1234567typedef struct &#123; ngx_list_part_t *last; ngx_list_part_t part; size_t size; ngx_uint_t nalloc; ngx_pool_t *pool;&#125; ngx_list_t; last: 指向该链表的最后一个节点。 part: 该链表的首个存放具体元素的节点。 size: 链表中存放的具体元素所需内存大小。 nalloc: 每个节点所含的固定大小的数组的容量。 pool: 该 list 使用的分配内存的 pool。 好，我们在看一下每个节点的定义。 123456typedef struct ngx_list_part_s ngx_list_part_t;struct ngx_list_part_s &#123; void *elts; ngx_uint_t nelts; ngx_list_part_t *next;&#125;; elts: 节点中存放具体元素的内存的开始地址。 nelts: 节点中已有元素个数。这个值是不能大于链表头节点 ngx_list_t 类型中的 nalloc 字段的。 next: 指向下一个节点。 我们来看一下提供的一个操作的函数。 1ngx_list_t *ngx_list_create(ngx_pool_t *pool, ngx_uint_t n, size_t size); 该函数创建一个 ngx_list_t 类型的对象，并对该 list 的第一个节点分配存放元素的内存空间。 pool: 分配内存使用的 pool。 n: 每个节点（ngx_list_part_t）固定长度的数组的长度，即最多可以存放的元素个数。 size: 每个元素所占用的内存大小。 返回值: 成功返回指向创建的 ngx_list_t 对象的指针，失败返回 NULL。 1void *ngx_list_push(ngx_list_t *list); 该函数在给定的 list 的尾部追加一个元素，并返回指向新元素存放空间的指针。如果追加失败，则返回 NULL。 12static ngx_inline ngx_int_tngx_list_init(ngx_list_t *list, ngx_pool_t *pool, ngx_uint_t n, size_t size); 该函数是用于 ngx_list_t 类型的对象已经存在，但是其第一个节点存放元素的内存空间还未分配的情况下，可以调用此函数来给这个 list 的首节点来分配存放元素的内存空间。 那么什么时候会出现已经有了 ngx_list_t 类型的对象，而其首节点存放元素的内存尚未分配的情况呢？那就是这个 ngx_list_t 类型的变量并不是通过调用 ngx_list_create 函数创建的。例如：如果某个结构体的一个成员变量是 ngx_list_t 类型的，那么当这个结构体类型的对象被创建出来的时候，这个成员变量也被创建出来了，但是它的首节点的存放元素的内存并未被分配。 总之，如果这个 ngx_list_t 类型的变量，如果不是你通过调用函数 ngx_list_create 创建的，那么就必须调用此函数去初始化，否则，你往这个 list 里追加元素就可能引发不可预知的行为，亦或程序会崩溃! ngx_queue_tngx_queue_t 是 Nginx 中的双向链表，在 Nginx 源码目录src/core下面的ngx_queue.h|c里面。它的原型如下： 123456typedef struct ngx_queue_s ngx_queue_t;struct ngx_queue_s &#123; ngx_queue_t *prev; ngx_queue_t *next;&#125;; 不同于教科书中将链表节点的数据成员声明在链表节点的结构体中，ngx_queue_t 只是声明了前向和后向指针。在使用的时候，我们首先需要定义一个哨兵节点(对于后续具体存放数据的节点，我们称之为数据节点)，比如： 1ngx_queue_t free; 接下来需要进行初始化，通过宏 ngx_queue_init()来实现： 1ngx_queue_init(&amp;free); ngx_queue_init()的宏定义如下： 123#define ngx_queue_init(q) \ (q)-&gt;prev = q; \ (q)-&gt;next = q 可见初始的时候哨兵节点的 prev 和 next 都指向自己，因此其实是一个空链表。ngx_queue_empty()可以用来判断一个链表是否为空，其实现也很简单，就是： 12#define ngx_queue_empty(h) \ (h == (h)-&gt;prev) 那么如何声明一个具有数据元素的链表节点呢？只要在相应的结构体中加上一个 ngx_queue_t 的成员就行了。比如 ngx_http_upstream_keepalive_module 中的 ngx_http_upstream_keepalive_cache_t： 123456789typedef struct &#123; ngx_http_upstream_keepalive_srv_conf_t *conf; ngx_queue_t queue; ngx_connection_t *connection; socklen_t socklen; u_char sockaddr[NGX_SOCKADDRLEN];&#125; ngx_http_upstream_keepalive_cache_t; 对于每一个这样的数据节点，可以通过 ngx_queue_insert_head()来添加到链表中，第一个参数是哨兵节点，第二个参数是数据节点，比如： 12ngx_http_upstream_keepalive_cache_t cache;ngx_queue_insert_head(&amp;free, &amp;cache.queue); 相应的几个宏定义如下： 12345678910111213#define ngx_queue_insert_head(h, x) \ (x)-&gt;next = (h)-&gt;next; \ (x)-&gt;next-&gt;prev = x; \ (x)-&gt;prev = h; \ (h)-&gt;next = x#define ngx_queue_insert_after ngx_queue_insert_head#define ngx_queue_insert_tail(h, x) \ (x)-&gt;prev = (h)-&gt;prev; \ (x)-&gt;prev-&gt;next = x; \ (x)-&gt;next = h; \ (h)-&gt;prev = x ngx_queue_insert_head() 和 ngx_queue_insert_after() 都是往头部添加节点，ngx_queue_insert_tail() 是往尾部添加节点。从代码可以看出哨兵节点的 prev 指向链表的尾数据节点，next 指向链表的头数据节点。另外 ngx_queue_head() 和 ngx_queue_last() 这两个宏分别可以得到头节点和尾节点。 那假如现在有一个 ngx_queue_t *q 指向的是链表中的数据节点的 queue 成员，如何得到ngx_http_upstream_keepalive_cache_t 的数据呢？ Nginx 提供了 ngx_queue_data() 宏来得到ngx_http_upstream_keepalive_cache_t 的指针，例如： 123ngx_http_upstream_keepalive_cache_t *cache = ngx_queue_data(q, ngx_http_upstream_keepalive_cache_t, queue); 也许您已经可以猜到 ngx_queue_data 是通过地址相减来得到的： 12#define ngx_queue_data(q, type, link) \ (type *) ((u_char *) q - offsetof(type, link)) 另外 Nginx 也提供了 ngx_queue_remove()宏来从链表中删除一个数据节点，以及 ngx_queue_add() 用来将一个链表添加到另一个链表。 Nginx 的配置系统由 小路依依 创建， 最后一次修改 2016-08-12 Nginx 的配置系统Nginx 的配置系统由一个主配置文件和其他一些辅助的配置文件构成。这些配置文件均是纯文本文件，全部位于Nginx 安装目录下的 conf 目录下。 配置文件中以#开始的行，或者是前面有若干空格或者 TAB，然后再跟#的行，都被认为是注释，也就是只对编辑查看文件的用户有意义，程序在读取这些注释行的时候，其实际的内容是被忽略的。 由于除主配置文件 nginx.conf 以外的文件都是在某些情况下才使用的，而只有主配置文件是在任何情况下都被使用的。所以在这里我们就以主配置文件为例，来解释 Nginx 的配置系统。 在 nginx.conf 中，包含若干配置项。每个配置项由配置指令和指令参数 2 个部分构成。指令参数也就是配置指令对应的配置值。 指令概述配置指令是一个字符串，可以用单引号或者双引号括起来，也可以不括。但是如果配置指令包含空格，一定要引起来。 指令参数指令的参数使用一个或者多个空格或者 TAB 字符与指令分开。指令的参数有一个或者多个 TOKEN 串组成。TOKEN 串之间由空格或者 TAB 键分隔。 TOKEN 串分为简单字符串或者是复合配置块。复合配置块即是由大括号括起来的一堆内容。一个复合配置块中可能包含若干其他的配置指令。 如果一个配置指令的参数全部由简单字符串构成，也就是不包含复合配置块，那么我们就说这个配置指令是一个简单配置项，否则称之为复杂配置项。例如下面这个是一个简单配置项： 1error_page 500 502 503 504 /50x.html; 对于简单配置，配置项的结尾使用分号结束。对于复杂配置项，包含多个 TOKEN 串的，一般都是简单 TOKEN 串放在前面，复合配置块一般位于最后，而且其结尾，并不需要再添加分号。例如下面这个复杂配置项： 1234location / &#123; root /home/jizhao/nginx-book/build/html; index index.html index.htm;&#125; 指令上下文nginx.conf 中的配置信息，根据其逻辑上的意义，对它们进行了分类，也就是分成了多个作用域，或者称之为配置指令上下文。不同的作用域含有一个或者多个配置项。 当前 Nginx 支持的几个指令上下文： main: Nginx 在运行时与具体业务功能（比如http服务或者email服务代理）无关的一些参数，比如工作进程数，运行的身份等。 http: 与提供 http 服务相关的一些配置参数。例如：是否使用 keepalive 啊，是否使用gzip进行压缩等。 server: http 服务上支持若干虚拟主机。每个虚拟主机一个对应的 server 配置项，配置项里面包含该虚拟主机相关的配置。在提供 mail 服务的代理时，也可以建立若干 server，每个 server 通过监听的地址来区分。 location: http 服务中，某些特定的URL对应的一系列配置项。 mail: 实现 email 相关的 SMTP/IMAP/POP3 代理时，共享的一些配置项（因为可能实现多个代理，工作在多个监听地址上）。 指令上下文，可能有包含的情况出现。例如：通常 http 上下文和 mail 上下文一定是出现在 main 上下文里的。在一个上下文里，可能包含另外一种类型的上下文多次。例如：如果 http 服务，支持了多个虚拟主机，那么在 http 上下文里，就会出现多个 server 上下文。 我们来看一个示例配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748user nobody;worker_processes 1;error_log logs/error.log info;events &#123; worker_connections 1024;&#125;http &#123; server &#123; listen 80; server_name www.linuxidc.com; access_log logs/linuxidc.access.log main; location / &#123; index index.html; root /var/www/linuxidc.com/htdocs; &#125; &#125; server &#123; listen 80; server_name www.Androidj.com; access_log logs/androidj.access.log main; location / &#123; index index.html; root /var/www/androidj.com/htdocs; &#125; &#125; &#125;mail &#123; auth_http 127.0.0.1:80/auth.php; pop3_capabilities "TOP" "USER"; imap_capabilities "IMAP4rev1" "UIDPLUS"; server &#123; listen 110; protocol pop3; proxy on; &#125; server &#123; listen 25; protocol smtp; proxy on; smtp_auth login plain; xclient off; &#125;&#125; 在这个配置中，上面提到个五种配置指令上下文都存在。 存在于 main 上下文中的配置指令如下: user worker_processes error_log events http mail 存在于 http 上下文中的指令如下: server 存在于 mail 上下文中的指令如下： server auth_http imap_capabilities 存在于 server 上下文中的配置指令如下： listen server_name access_log location protocol proxy smtp_auth xclient 存在于 location 上下文中的指令如下： index root 当然，这里只是一些示例。具体有哪些配置指令，以及这些配置指令可以出现在什么样的上下文中，需要参考 Nginx 的使用文档 Nginx 的模块化体系结构由 小路依依 创建， 最后一次修改 2016-08-12 Nginx 的模块化体系结构Nginx 的内部结构是由核心部分和一系列的功能模块所组成。这样划分是为了使得每个模块的功能相对简单，便于开发，同时也便于对系统进行功能扩展。为了便于描述，下文中我们将使用 Nginx core 来称呼 Nginx 的核心功能部分。 Nginx 提供了 Web 服务器的基础功能，同时提供了 Web 服务反向代理，Email 服务反向代理功能。Nginx core实现了底层的通讯协议，为其他模块和 Nginx 进程构建了基本的运行时环境，并且构建了其他各模块的协作基础。除此之外，或者说大部分与协议相关的，或者应用相关的功能都是在这些模块中所实现的。 模块概述Nginx 将各功能模块组织成一条链，当有请求到达的时候，请求依次经过这条链上的部分或者全部模块，进行处理。每个模块实现特定的功能。例如，实现对请求解压缩的模块，实现 SSI 的模块，实现与上游服务器进行通讯的模块，实现与 FastCGI 服务进行通讯的模块。 有两个模块比较特殊，他们居于 Nginx core 和各功能模块的中间。这两个模块就是 http 模块和 mail 模块。这 2 个模块在 Nginx core 之上实现了另外一层抽象，处理与 HTTP 协议和 Email 相关协议（SMTP/POP3/IMAP）有关的事件，并且确保这些事件能被以正确的顺序调用其他的一些功能模块。 目前 HTTP 协议是被实现在 http 模块中的，但是有可能将来被剥离到一个单独的模块中，以扩展 Nginx 支持 SPDY 协议。 模块的分类Nginx 的模块根据其功能基本上可以分为以下几种类型： event module: 搭建了独立于操作系统的事件处理机制的框架，及提供了各具体事件的处理。包括 ngx_events_module， ngx_event_core_module和ngx_epoll_module 等。Nginx 具体使用何种事件处理模块，这依赖于具体的操作系统和编译选项。 phase handler: 此类型的模块也被直接称为 handler 模块。主要负责处理客户端请求并产生待响应内容，比如 ngx_http_static_module 模块，负责客户端的静态页面请求处理并将对应的磁盘文件准备为响应内容输出。 output filter: 也称为 filter 模块，主要是负责对输出的内容进行处理，可以对输出进行修改。例如，可以实现对输出的所有 html 页面增加预定义的 footbar 一类的工作，或者对输出的图片的 URL 进行替换之类的工作。 upstream: upstream 模块实现反向代理的功能，将真正的请求转发到后端服务器上，并从后端服务器上读取响应，发回客户端。upstream 模块是一种特殊的 handler，只不过响应内容不是真正由自己产生的，而是从后端服务器上读取的。 load-balancer: 负载均衡模块，实现特定的算法，在众多的后端服务器中，选择一个服务器出来作为某个请求的转发服务器。 Nginx 的请求处理由 小路依依 创建， 最后一次修改 2016-08-12 Nginx 的请求处理Nginx 使用一个多进程模型来对外提供服务，其中一个 master 进程，多个 worker 进程。master 进程负责管理 Nginx 本身和其他 worker 进程。 所有实际上的业务处理逻辑都在 worker 进程。worker 进程中有一个函数，执行无限循环，不断处理收到的来自客户端的请求，并进行处理，直到整个 Nginx 服务被停止。 worker 进程中，ngx_worker_process_cycle()函数就是这个无限循环的处理函数。在这个函数中，一个请求的简单处理流程如下： 操作系统提供的机制（例如 epoll, kqueue 等）产生相关的事件。 接收和处理这些事件，如是接受到数据，则产生更高层的 request 对象。 处理 request 的 header 和 body。 产生响应，并发送回客户端。 完成 request 的处理。 重新初始化定时器及其他事件。 请求的处理流程为了让大家更好的了解 Nginx 中请求处理过程，我们以 HTTP Request 为例，来做一下详细地说明。 从 Nginx 的内部来看，一个 HTTP Request 的处理过程涉及到以下几个阶段。 初始化 HTTP Request（读取来自客户端的数据，生成 HTTP Request 对象，该对象含有该请求所有的信息）。 处理请求头。 处理请求体。 如果有的话，调用与此请求（URL 或者 Location）关联的 handler。 依次调用各 phase handler 进行处理。 在这里，我们需要了解一下 phase handler 这个概念。phase 字面的意思，就是阶段。所以 phase handlers 也就好理解了，就是包含若干个处理阶段的一些 handler。 在每一个阶段，包含有若干个 handler，再处理到某个阶段的时候，依次调用该阶段的 handler 对 HTTP Request 进行处理。 通常情况下，一个 phase handler 对这个 request 进行处理，并产生一些输出。通常 phase handler 是与定义在配置文件中的某个 location 相关联的。 一个 phase handler 通常执行以下几项任务： 获取 location 配置。 产生适当的响应。 发送 response header。 发送 response body。 当 Nginx 读取到一个 HTTP Request 的 header 的时候，Nginx 首先查找与这个请求关联的虚拟主机的配置。如果找到了这个虚拟主机的配置，那么通常情况下，这个 HTTP Request 将会经过以下几个阶段的处理（phase handlers）： NGX_HTTP_POST_READ_PHASE: 读取请求内容阶段 NGX_HTTP_SERVER_REWRITE_PHASE: Server 请求地址重写阶段 NGX_HTTP_FIND_CONFIG_PHASE: 配置查找阶段: NGX_HTTP_REWRITE_PHASE: Location请求地址重写阶段 NGX_HTTP_POST_REWRITE_PHASE: 请求地址重写提交阶段 NGX_HTTP_PREACCESS_PHASE: 访问权限检查准备阶段 NGX_HTTP_ACCESS_PHASE: 访问权限检查阶段 NGX_HTTP_POST_ACCESS_PHASE: 访问权限检查提交阶段 NGX_HTTP_TRY_FILES_PHASE: 配置项 try_files 处理阶段 NGX_HTTP_CONTENT_PHASE: 内容产生阶段 NGX_HTTP_LOG_PHASE: 日志模块处理阶段 在内容产生阶段，为了给一个 request 产生正确的响应，Nginx 必须把这个 request 交给一个合适的 content handler 去处理。如果这个 request 对应的 location 在配置文件中被明确指定了一个 content handler，那么Nginx 就可以通过对 location 的匹配，直接找到这个对应的 handler，并把这个 request 交给这个 content handler 去处理。这样的配置指令包括像，perl，flv，proxy_pass，mp4等。 如果一个 request 对应的 location 并没有直接有配置的 content handler，那么 Nginx 依次尝试: 如果一个 location 里面有配置 random_index on，那么随机选择一个文件，发送给客户端。 如果一个 location 里面有配置 index 指令，那么发送 index 指令指明的文件，给客户端。 如果一个 location 里面有配置 autoindex on，那么就发送请求地址对应的服务端路径下的文件列表给客户端。 如果这个 request 对应的 location 上有设置 gzip_static on，那么就查找是否有对应的.gz文件存在，有的话，就发送这个给客户端（客户端支持 gzip 的情况下）。 请求的 URI 如果对应一个静态文件，static module 就发送静态文件的内容到客户端。 内容产生阶段完成以后，生成的输出会被传递到 filter 模块去进行处理。filter 模块也是与 location 相关的。所有的 fiter 模块都被组织成一条链。输出会依次穿越所有的 filter，直到有一个 filter 模块的返回值表明已经处理完成。 这里列举几个常见的 filter 模块，例如： server-side includes。 XSLT filtering。 图像缩放之类的。 gzip 压缩。 在所有的 filter 中，有几个 filter 模块需要关注一下。按照调用的顺序依次说明如下： write: 写输出到客户端，实际上是写到连接对应的 socket 上。 postpone: 这个 filter 是负责 subrequest 的，也就是子请求的。 copy: 将一些需要复制的 buf(文件或者内存)重新复制一份然后交给剩余的 body filter 处理。 Nginx handler 模块简介由 小路依依 创建， 最后一次修改 2016-08-12 handler 模块简介相信大家在看了前一章的模块概述以后，都对 Nginx 的模块有了一个基本的认识。基本上作为第三方开发者最可能开发的就是三种类型的模块，即 handler，filter 和 load-balancer。Handler 模块就是接受来自客户端的请求并产生输出的模块。有些地方说 upstream 模块实际上也是一种 handler 模块，只不过它产生的内容来自于从后端服务器获取的，而非在本机产生的。 在上一章提到，配置文件中使用 location 指令可以配置 content handler 模块，当 Nginx 系统启动的时候，每个 handler 模块都有一次机会把自己关联到对应的 location上。如果有多个 handler 模块都关联了同一个 location，那么实际上只有一个 handler 模块真正会起作用。当然大多数情况下，模块开发人员都会避免出现这种情况。 handler 模块处理的结果通常有三种情况: 处理成功，处理失败（处理的时候发生了错误）或者是拒绝去处理。在拒绝处理的情况下，这个 location 的处理就会由默认的 handler 模块来进行处理。例如，当请求一个静态文件的时候，如果关联到这个 location 上的一个 handler 模块拒绝处理，就会由默认的 ngx_http_static_module 模块进行处理，该模块是一个典型的 handler 模块。 本章主要讲述的是如何编写 handler 模块，在研究 handler 模块编写之前先来了解一下模块的一些基本数据结构。 Nginx 模块的基本结构由 小路依依 创建， 最后一次修改 2016-08-12 模块的基本结构在这一节我们将会对通常的模块开发过程中，每个模块所包含的一些常用的部分进行说明。这些部分有些是必须的，有些不是必须的。同时这里所列出的这些东西对于其他类型的模块，例如 filter 模块等也都是相同的。 模块配置结构基本上每个模块都会提供一些配置指令，以便于用户可以通过配置来控制该模块的行为。那么这些配置信息怎么存储呢？那就需要定义该模块的配置结构来进行存储。 大家都知道 Nginx 的配置信息分成了几个作用域(scope,有时也称作上下文)，这就是 main，server 以及 location。同样的每个模块提供的配置指令也可以出现在这几个作用域里。那对于这三个作用域的配置信息，每个模块就需要定义三个不同的数据结构去进行存储。当然，不是每个模块都会在这三个作用域都提供配置指令的。那么也就不一定每个模块都需要定义三个数据结构去存储这些配置信息了。视模块的实现而言，需要几个就定义几个。 有一点需要特别注意的就是，在模块的开发过程中，我们最好使用 Nginx 原有的命名习惯。这样跟原代码的契合度更高，看起来也更舒服。 对于模块配置信息的定义，命名习惯是ngx_http_&lt;module name&gt;_(main|srv|loc)_conf_t。这里有个例子，就是从我们后面将要展示给大家的 hello module 中截取的。 12345typedef struct&#123; ngx_str_t hello_string; ngx_int_t hello_counter;&#125;ngx_http_hello_loc_conf_t; 模块配置指令一个模块的配置指令是定义在一个静态数组中的。同样地，我们来看一下从 hello module 中截取的模块配置指令的定义。 12345678910111213141516171819static ngx_command_t ngx_http_hello_commands[] = &#123; &#123; ngx_string("hello_string"), NGX_HTTP_LOC_CONF|NGX_CONF_NOARGS|NGX_CONF_TAKE1, ngx_http_hello_string, NGX_HTTP_LOC_CONF_OFFSET, offsetof(ngx_http_hello_loc_conf_t, hello_string), NULL &#125;, &#123; ngx_string("hello_counter"), NGX_HTTP_LOC_CONF|NGX_CONF_FLAG, ngx_http_hello_counter, NGX_HTTP_LOC_CONF_OFFSET, offsetof(ngx_http_hello_loc_conf_t, hello_counter), NULL &#125;, ngx_null_command&#125;; 其实看这个定义，就基本能看出来一些信息。例如，我们是定义了两个配置指令，一个是叫 hello_string，可以接受一个参数，或者是没有参数。另外一个命令是 hello_counter，接受一个 NGX_CONF_FLAG 类型的参数。除此之外，似乎看起来有点迷惑。没有关系，我们来详细看一下 ngx_command_t，一旦我们了解这个结构的详细信息，那么我相信上述这个定义所表达的所有信息就不言自明了。 ngx_command_t 的定义，位于src/core/ngx_conf_file.h中。 12345678struct ngx_command_s &#123; ngx_str_t name; ngx_uint_t type; char *(*set)(ngx_conf_t *cf, ngx_command_t *cmd, void *conf); ngx_uint_t conf; ngx_uint_t offset; void *post;&#125;; name: 配置指令的名称。 type: 该配置的类型，其实更准确一点说，是该配置指令属性的集合。Nginx 提供了很多预定义的属性值（一些宏定义），通过逻辑或运算符可组合在一起，形成对这个配置指令的详细的说明。下面列出可在这里使用的预定义属性值及说明。 NGX_CONF_NOARGS：配置指令不接受任何参数。 NGX_CONF_TAKE1：配置指令接受 1 个参数。 NGX_CONF_TAKE2：配置指令接受 2 个参数。 NGX_CONF_TAKE3：配置指令接受 3 个参数。 NGX_CONF_TAKE4：配置指令接受 4 个参数。 NGX_CONF_TAKE5：配置指令接受 5 个参数。 NGX_CONF_TAKE6：配置指令接受 6 个参数。 NGX_CONF_TAKE7：配置指令接受 7 个参数。 可以组合多个属性，比如一个指令即可以不填参数，也可以接受1个或者2个参数。那么就是NGX_CONF_NOARGS|NGX_CONF_TAKE1|NGX_CONF_TAKE2。如果写上面三个属性在一起，你觉得麻烦，那么没有关系，Nginx 提供了一些定义，使用起来更简洁。 NGX_CONF_TAKE12：配置指令接受 1 个或者 2 个参数。 NGX_CONF_TAKE13：配置指令接受 1 个或者 3 个参数。 NGX_CONF_TAKE23：配置指令接受 2 个或者 3 个参数。 NGX_CONF_TAKE123：配置指令接受 1 个或者 2 个或者 3 参数。 NGX_CONF_TAKE1234：配置指令接受 1 个或者 2 个或者 3 个或者 4 个参数。 NGX_CONF_1MORE：配置指令接受至少一个参数。 NGX_CONF_2MORE：配置指令接受至少两个参数。 NGX_CONF_MULTI: 配置指令可以接受多个参数，即个数不定。 NGX_CONF_BLOCK：配置指令可以接受的值是一个配置信息块。也就是一对大括号括起来的内容。里面可以再包括很多的配置指令。比如常见的 server 指令就是这个属性的。 NGX_CONF_FLAG：配置指令可以接受的值是”on”或者”off”，最终会被转成 bool 值。 NGX_CONF_ANY：配置指令可以接受的任意的参数值。一个或者多个，或者”on”或者”off”，或者是配置块。 最后要说明的是，无论如何，Nginx 的配置指令的参数个数不可以超过 NGX_CONF_MAX_ARGS 个。目前这个值被定义为 8，也就是不能超过 8 个参数值。 下面介绍一组说明配置指令可以出现的位置的属性。 NGX_DIRECT_CONF：可以出现在配置文件中最外层。例如已经提供的配置指令 daemon，master_process 等。 NGX_MAIN_CONF: http、mail、events、error_log 等。 NGX_ANY_CONF: 该配置指令可以出现在任意配置级别上。 对于我们编写的大多数模块而言，都是在处理http相关的事情，也就是所谓的都是NGX_HTTP_MODULE，对于这样类型的模块，其配置可能出现的位置也是分为直接出现在http里面，以及其他位置。 NGX_HTTP_MAIN_CONF: 可以直接出现在 http 配置指令里。 NGX_HTTP_SRV_CONF: 可以出现在 http 里面的 server 配置指令里。 NGX_HTTP_LOC_CONF: 可以出现在 http server 块里面的 location 配置指令里。 NGX_HTTP_UPS_CONF: 可以出现在 http 里面的 upstream 配置指令里。 NGX_HTTP_SIF_CONF: 可以出现在 http 里面的 server 配置指令里的 if 语句所在的 block 中。 NGX_HTTP_LMT_CONF: 可以出现在 http 里面的 limit_except 指令的 block 中。 NGX_HTTP_LIF_CONF: 可以出现在 http server 块里面的 location 配置指令里的 if 语句所在的 block 中。 set: 这是一个函数指针，当 Nginx 在解析配置的时候，如果遇到这个配置指令，将会把读取到的值传递给这个函数进行分解处理。因为具体每个配置指令的值如何处理，只有定义这个配置指令的人是最清楚的。来看一下这个函数指针要求的函数原型。 1char *(*set)(ngx_conf_t *cf, ngx_command_t *cmd, void *conf); 先看该函数的返回值，处理成功时，返回 NGX_OK，否则返回 NGX_CONF_ERROR 或者是一个自定义的错误信息的字符串。 再看一下这个函数被调用的时候，传入的三个参数。 cf: 该参数里面保存从配置文件读取到的原始字符串以及相关的一些信息。特别注意的是这个参数的args字段是一个 ngx_str_t类型的数组，该数组的首个元素是这个配置指令本身，第二个元素是指令的第一个参数，第三个元素是第二个参数，依次类推。 cmd: 这个配置指令对应的 ngx_command_t 结构。 conf: 就是定义的存储这个配置值的结构体，比如在上面展示的那个 ngx_http_hello_loc_conf_t。当解析这个 hello_string 变量的时候，传入的 conf 就指向一个 ngx_http_hello_loc_conf_t 类型的变量。用户在处理的时候可以使用类型转换，转换成自己知道的类型，再进行字段的赋值。 为了更加方便的实现对配置指令参数的读取，Nginx 已经默认提供了对一些标准类型的参数进行读取的函数，可以直接赋值给 set 字段使用。下面来看一下这些已经实现的 set 类型函数。 ngx_conf_set_flag_slot： 读取 NGX_CONF_FLAG 类型的参数。 ngx_conf_set_str_slot:读取字符串类型的参数。 ngx_conf_set_str_array_slot: 读取字符串数组类型的参数。 ngx_conf_set_keyval_slot： 读取键值对类型的参数。 ngx_conf_set_num_slot: 读取整数类型(有符号整数 ngx_int_t)的参数。 ngx_conf_set_size_slot:读取 size_t 类型的参数，也就是无符号数。 ngx_conf_set_off_slot: 读取 off_t 类型的参数。 ngx_conf_set_msec_slot: 读取毫秒值类型的参数。 ngx_conf_set_sec_slot: 读取秒值类型的参数。 ngx_conf_set_bufs_slot： 读取的参数值是 2 个，一个是 buf 的个数，一个是 buf 的大小。例如： output_buffers 1 128k; ngx_conf_set_enum_slot: 读取枚举类型的参数，将其转换成整数 ngx_uint_t 类型。 ngx_conf_set_bitmask_slot: 读取参数的值，并将这些参数的值以 bit 位的形式存储。例如：HttpDavModule 模块的 dav_methods 指令。 conf: 该字段被 NGX_HTTP_MODULE 类型模块所用 (我们编写的基本上都是 NGX_HTTP_MOUDLE，只有一些 Nginx 核心模块是非 NGX_HTTP_MODULE)，该字段指定当前配置项存储的内存位置。实际上是使用哪个内存池的问题。因为 http 模块对所有 http 模块所要保存的配置信息，划分了 main, server 和 location 三个地方进行存储，每个地方都有一个内存池用来分配存储这些信息的内存。这里可能的值为 NGX_HTTP_MAIN_CONF_OFFSET、NGX_HTTP_SRV_CONF_OFFSET 或 NGX_HTTP_LOC_CONF_OFFSET。当然也可以直接置为 0，就是 NGX_HTTP_MAIN_CONF_OFFSET。 offset: 指定该配置项值的精确存放位置，一般指定为某一个结构体变量的字段偏移。因为对于配置信息的存储，一般我们都是定义个结构体来存储的。那么比如我们定义了一个结构体 A，该项配置的值需要存储到该结构体的 b 字段。那么在这里就可以填写为 offsetof(A, b)。对于有些配置项，它的值不需要保存或者是需要保存到更为复杂的结构中时，这里可以设置为 0。 post: 该字段存储一个指针。可以指向任何一个在读取配置过程中需要的数据，以便于进行配置读取的处理。大多数时候，都不需要，所以简单地设为 0 即可。 看到这里，应该就比较清楚了。ngx_http_hello_commands 这个数组每 5 个元素为一组，用来描述一个配置项的所有情况。那么如果有多个配置项，只要按照需要再增加 5 个对应的元素对新的配置项进行说明。 需要注意的是，就是在ngx_http_hello_commands这个数组定义的最后，都要加一个ngx_null_command作为结尾。 模块上下文结构这是一个 ngx_http_module_t 类型的静态变量。这个变量实际上是提供一组回调函数指针，这些函数有在创建存储配置信息的对象的函数，也有在创建前和创建后会调用的函数。这些函数都将被 Nginx 在合适的时间进行调用。 12345678910111213typedef struct &#123; ngx_int_t (*preconfiguration)(ngx_conf_t *cf); ngx_int_t (*postconfiguration)(ngx_conf_t *cf); void *(*create_main_conf)(ngx_conf_t *cf); char *(*init_main_conf)(ngx_conf_t *cf, void *conf); void *(*create_srv_conf)(ngx_conf_t *cf); char *(*merge_srv_conf)(ngx_conf_t *cf, void *prev, void *conf); void *(*create_loc_conf)(ngx_conf_t *cf); char *(*merge_loc_conf)(ngx_conf_t *cf, void *prev, void *conf);&#125; ngx_http_module_t; preconfiguration: 在创建和读取该模块的配置信息之前被调用。 postconfiguration: 在创建和读取该模块的配置信息之后被调用。 create_main_conf: 调用该函数创建本模块位于 http block 的配置信息存储结构。该函数成功的时候，返回创建的配置对象。失败的话，返回 NULL。 init_main_conf: 调用该函数初始化本模块位于 http block 的配置信息存储结构。该函数成功的时候，返回 NGX_CONF_OK。失败的话，返回 NGX_CONF_ERROR 或错误字符串。 create_srv_conf: 调用该函数创建本模块位于 http server block 的配置信息存储结构，每个 server block 会创建一个。该函数成功的时候，返回创建的配置对象。失败的话，返回 NULL。 merge_srv_conf: 因为有些配置指令既可以出现在 http block，也可以出现在 http server block 中。那么遇到这种情况，每个 server 都会有自己存储结构来存储该 server 的配置，但是在这种情况下 http block 中的配置与 server block 中的配置信息发生冲突的时候，就需要调用此函数进行合并，该函数并非必须提供，当预计到绝对不会发生需要合并的情况的时候，就无需提供。当然为了安全起见还是建议提供。该函数执行成功的时候，返回 NGX_CONF_OK。失败的话，返回 NGX_CONF_ERROR 或错误字符串。 create_loc_conf: 调用该函数创建本模块位于 location block 的配置信息存储结构。每个在配置中指明的 location 创建一个。该函数执行成功，返回创建的配置对象。失败的话，返回 NULL。 merge_loc_conf: 与 merge_srv_conf 类似，这个也是进行配置值合并的地方。该函数成功的时候，返回 NGX_CONF_OK。失败的话，返回 NGX_CONF_ERROR 或错误字符串。 Nginx 里面的配置信息都是上下一层层的嵌套的，对于具体某个 location 的话，对于同一个配置，如果当前层次没有定义，那么就使用上层的配置，否则使用当前层次的配置。 这些配置信息一般默认都应该设为一个未初始化的值，针对这个需求，Nginx 定义了一系列的宏定义来代表各种配置所对应数据类型的未初始化值，如下： 12345#define NGX_CONF_UNSET -1#define NGX_CONF_UNSET_UINT (ngx_uint_t) -1#define NGX_CONF_UNSET_PTR (void *) -1#define NGX_CONF_UNSET_SIZE (size_t) -1#define NGX_CONF_UNSET_MSEC (ngx_msec_t) -1 又因为对于配置项的合并，逻辑都类似，也就是前面已经说过的，如果在本层次已经配置了，也就是配置项的值已经被读取进来了（那么这些配置项的值就不会等于上面已经定义的那些 UNSET 的值），就使用本层次的值作为定义合并的结果，否则，使用上层的值，如果上层的值也是这些UNSET类的值，那就赋值为默认值，否则就使用上层的值作为合并的结果。对于这样类似的操作，Nginx 定义了一些宏操作来做这些事情，我们来看其中一个的定义。 1234#define ngx_conf_merge_uint_value(conf, prev, default) \ if (conf == NGX_CONF_UNSET_UINT) &#123; \ conf = (prev == NGX_CONF_UNSET_UINT) ? default : prev; \ &#125; 显而易见，这个逻辑确实比较简单，所以其它的宏定义也类似，我们就列具其中的一部分吧。 12345ngx_conf_merge_valuengx_conf_merge_ptr_valuengx_conf_merge_uint_valuengx_conf_merge_msec_valuengx_conf_merge_sec_value 等等。 下面来看一下 hello 模块的模块上下文的定义，加深一下印象。 12345678910111213static ngx_http_module_t ngx_http_hello_module_ctx = &#123; NULL, /* preconfiguration */ ngx_http_hello_init, /* postconfiguration */ NULL, /* create main configuration */ NULL, /* init main configuration */ NULL, /* create server configuration */ NULL, /* merge server configuration */ ngx_http_hello_create_loc_conf, /* create location configuration */ NULL /* merge location configuration */&#125;; 注意：这里并没有提供 merge_loc_conf 函数，因为我们这个模块的配置指令已经确定只出现在 NGX_HTTP_LOC_CONF 中这一个层次上，不会发生需要合并的情况。 模块的定义对于开发一个模块来说，我们都需要定义一个 ngx_module_t 类型的变量来说明这个模块本身的信息，从某种意义上来说，这是这个模块最重要的一个信息，它告诉了 Nginx 这个模块的一些信息，上面定义的配置信息，还有模块上下文信息，都是通过这个结构来告诉 Nginx 系统的，也就是加载模块的上层代码，都需要通过定义的这个结构，来获取这些信息。 我们先来看下 ngx_module_t 的定义 12345678910111213141516171819202122232425262728293031323334typedef struct ngx_module_s ngx_module_t;struct ngx_module_s &#123; ngx_uint_t ctx_index; ngx_uint_t index; ngx_uint_t spare0; ngx_uint_t spare1; ngx_uint_t abi_compatibility; ngx_uint_t major_version; ngx_uint_t minor_version; void *ctx; ngx_command_t *commands; ngx_uint_t type; ngx_int_t (*init_master)(ngx_log_t *log); ngx_int_t (*init_module)(ngx_cycle_t *cycle); ngx_int_t (*init_process)(ngx_cycle_t *cycle); ngx_int_t (*init_thread)(ngx_cycle_t *cycle); void (*exit_thread)(ngx_cycle_t *cycle); void (*exit_process)(ngx_cycle_t *cycle); void (*exit_master)(ngx_cycle_t *cycle); uintptr_t spare_hook0; uintptr_t spare_hook1; uintptr_t spare_hook2; uintptr_t spare_hook3; uintptr_t spare_hook4; uintptr_t spare_hook5; uintptr_t spare_hook6; uintptr_t spare_hook7;&#125;;#define NGX_NUMBER_MAJOR 3#define NGX_NUMBER_MINOR 1#define NGX_MODULE_V1 0, 0, 0, 0, \ NGX_DSO_ABI_COMPATIBILITY, NGX_NUMBER_MAJOR, NGX_NUMBER_MINOR#define NGX_MODULE_V1_PADDING 0, 0, 0, 0, 0, 0, 0, 0 再看一下 hello 模块的模块定义。 1234567891011121314ngx_module_t ngx_http_hello_module = &#123; NGX_MODULE_V1, &amp;ngx_http_hello_module_ctx, /* module context */ ngx_http_hello_commands, /* module directives */ NGX_HTTP_MODULE, /* module type */ NULL, /* init master */ NULL, /* init module */ NULL, /* init process */ NULL, /* init thread */ NULL, /* exit thread */ NULL, /* exit process */ NULL, /* exit master */ NGX_MODULE_V1_PADDING&#125;; 模块可以提供一些回调函数给 Nginx，当 Nginx 在创建进程线程或者结束进程线程时进行调用。但大多数模块在这些时刻并不需要做什么，所以都简单赋值为 NULL。 Nginx handler 模块的基本结构由 小路依依 创建， 最后一次修改 2016-08-12 handler 模块的基本结构除了上一节介绍的模块的基本结构以外，handler 模块必须提供一个真正的处理函数，这个函数负责对来自客户端请求的真正处理。这个函数的处理，既可以选择自己直接生成内容，也可以选择拒绝处理，由后续的 handler 去进行处理，或者是选择丢给后续的 filter 进行处理。来看一下这个函数的原型申明。 1typedef ngx_int_t (*ngx_http_handler_pt)(ngx_http_request_t *r); r 是 http 请求。里面包含请求所有的信息，这里不详细说明了，可以参考别的章节的介绍。 该函数处理成功返回 NGX_OK，处理发生错误返回 NGX_ERROR，拒绝处理（留给后续的 handler 进行处理）返回 NGX_DECLINE。 返回 NGX_OK 也就代表给客户端的响应已经生成好了，否则返回 NGX_ERROR 就发生错误了。 Nginx handler 模块的挂载由 小路依依 创建， 最后一次修改 2016-08-12 handler 模块的挂载handler 模块真正的处理函数通过两种方式挂载到处理过程中，一种方式就是按处理阶段挂载;另外一种挂载方式就是按需挂载。 按处理阶段挂载为了更精细地控制对于客户端请求的处理过程，Nginx 把这个处理过程划分成了 11 个阶段。他们从前到后，依次列举如下： NGX_HTTP_POST_READ_PHASE: 读取请求内容阶段 NGX_HTTP_SERVER_REWRITE_PHASE: Server 请求地址重写阶段 NGX_HTTP_FIND_CONFIG_PHASE: 配置查找阶段: NGX_HTTP_REWRITE_PHASE: Location 请求地址重写阶段 NGX_HTTP_POST_REWRITE_PHASE: 请求地址重写提交阶段 NGX_HTTP_PREACCESS_PHASE: 访问权限检查准备阶段 NGX_HTTP_ACCESS_PHASE: 访问权限检查阶段 NGX_HTTP_POST_ACCESS_PHASE: 访问权限检查提交阶段 NGX_HTTP_TRY_FILES_PHASE: 配置项 try_files 处理阶段 NGX_HTTP_CONTENT_PHASE: 内容产生阶段 NGX_HTTP_LOG_PHASE: 日志模块处理阶段 一般情况下，我们自定义的模块，大多数是挂载在 NGX_HTTP_CONTENT_PHASE 阶段的。挂载的动作一般是在模块上下文调用的 postconfiguration 函数中。 注意：有几个阶段是特例，它不调用挂载地任何的handler，也就是你就不用挂载到这几个阶段了： NGX_HTTP_FIND_CONFIG_PHASE NGX_HTTP_POST_ACCESS_PHASE NGX_HTTP_POST_REWRITE_PHASE NGX_HTTP_TRY_FILES_PHASE 所以其实真正是有 7 个 phase 你可以去挂载 handler。 挂载的代码如下（摘自 hello module）: 1234567891011121314151617static ngx_int_tngx_http_hello_init(ngx_conf_t *cf)&#123; ngx_http_handler_pt *h; ngx_http_core_main_conf_t *cmcf; cmcf = ngx_http_conf_get_module_main_conf(cf, ngx_http_core_module); h = ngx_array_push(&amp;cmcf-&gt;phases[NGX_HTTP_CONTENT_PHASE].handlers); if (h == NULL) &#123; return NGX_ERROR; &#125; *h = ngx_http_hello_handler; return NGX_OK;&#125; 使用这种方式挂载的 handler 也被称为 content phase handlers。 按需挂载以这种方式挂载的 handler 也被称为 content handler。 当一个请求进来以后，Nginx 从 NGX_HTTP_POST_READ_PHASE 阶段开始依次执行每个阶段中所有 handler。执行到 NGX_HTTP_CONTENT_PHASE 阶段的时候，如果这个 location 有一个对应的 content handler 模块，那么就去执行这个 content handler 模块真正的处理函数。否则继续依次执行 NGX_HTTP_CONTENT_PHASE 阶段中所有 content phase handlers，直到某个函数处理返回 NGX_OK 或者 NGX_ERROR。 换句话说，当某个 location 处理到 NGX_HTTP_CONTENT_PHASE 阶段时，如果有 content handler 模块，那么 NGX_HTTP_CONTENT_PHASE 挂载的所有 content phase handlers 都不会被执行了。 但是使用这个方法挂载上去的 handler 有一个特点是必须在 NGX_HTTP_CONTENT_PHASE 阶段才能执行到。如果你想自己的 handler 在更早的阶段执行，那就不要使用这种挂载方式。 那么在什么情况会使用这种方式来挂载呢？一般情况下，某个模块对某个 location 进行了处理以后，发现符合自己处理的逻辑，而且也没有必要再调用 NGX_HTTP_CONTENT_PHASE 阶段的其它 handler 进行处理的时候，就动态挂载上这个 handler。 下面来看一下使用这种挂载方式的具体例子（摘自 Emiller’s Guide To Nginx Module Development）。 12345678910static char *ngx_http_circle_gif(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)&#123; ngx_http_core_loc_conf_t *clcf; clcf = ngx_http_conf_get_module_loc_conf(cf, ngx_http_core_module); clcf-&gt;handler = ngx_http_circle_gif_handler; return NGX_CONF_OK;&#125; Nginx handler 的编写步骤由 小路依依 创建， 最后一次修改 2016-08-12 handler 的编写步骤好，到了这里，让我们稍微整理一下思路，回顾一下实现一个 handler 的步骤: 编写模块基本结构。包括模块的定义，模块上下文结构，模块的配置结构等。 实现 handler 的挂载函数。根据模块的需求选择正确的挂载方式。 编写 handler 处理函数。模块的功能主要通过这个函数来完成。 看起来不是那么难，对吧？还是那句老话，世上无难事，只怕有心人! 现在我们来完整的分析前面提到的 hello handler module 示例的功能和代码。 Nginx 示例: hello handler 模块由 小路依依 创建， 最后一次修改 2016-08-12 示例: hello handler 模块在前面已经看到了这个 hello handler module 的部分重要的结构。该模块提供了 2 个配置指令，仅可以出现在 location 指令的作用域中。这两个指令是 hello_string, 该指令接受一个参数来设置显示的字符串。如果没有跟参数，那么就使用默认的字符串作为响应字符串。 另一个指令是 hello_counter，如果设置为 on，则会在响应的字符串后面追加 Visited Times:的字样，以统计请求的次数。 这里有两点注意一下： 对于 flag 类型的配置指令，当值为 off 的时候，使用 ngx_conf_set_flag_slot 函数，会转化为 0，为on，则转化为非 0。 另外一个是，我提供了 merge_loc_conf 函数，但是却没有设置到模块的上下文定义中。这样有一个缺点，就是如果一个指令没有出现在配置文件中的时候，配置信息中的值，将永远会保持在 create_loc_conf 中的初始化的值。那如果，在类似 create_loc_conf 这样的函数中，对创建出来的配置信息的值，没有设置为合理的值的话，后面用户又没有配置，就会出现问题。 下面来完整的给出 ngx_http_hello_module 模块的完整代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236#include &lt;ngx_config.h&gt;#include &lt;ngx_core.h&gt;#include &lt;ngx_http.h&gt;typedef struct&#123; ngx_str_t hello_string; ngx_int_t hello_counter;&#125;ngx_http_hello_loc_conf_t;static ngx_int_t ngx_http_hello_init(ngx_conf_t *cf);static void *ngx_http_hello_create_loc_conf(ngx_conf_t *cf);static char *ngx_http_hello_string(ngx_conf_t *cf, ngx_command_t *cmd, void *conf);static char *ngx_http_hello_counter(ngx_conf_t *cf, ngx_command_t *cmd, void *conf);static ngx_command_t ngx_http_hello_commands[] = &#123; &#123; ngx_string("hello_string"), NGX_HTTP_LOC_CONF|NGX_CONF_NOARGS|NGX_CONF_TAKE1, ngx_http_hello_string, NGX_HTTP_LOC_CONF_OFFSET, offsetof(ngx_http_hello_loc_conf_t, hello_string), NULL &#125;, &#123; ngx_string("hello_counter"), NGX_HTTP_LOC_CONF|NGX_CONF_FLAG, ngx_http_hello_counter, NGX_HTTP_LOC_CONF_OFFSET, offsetof(ngx_http_hello_loc_conf_t, hello_counter), NULL &#125;, ngx_null_command&#125;;/* static u_char ngx_hello_default_string[] = "Default String: Hello, world!";*/static int ngx_hello_visited_times = 0; static ngx_http_module_t ngx_http_hello_module_ctx = &#123; NULL, /* preconfiguration */ ngx_http_hello_init, /* postconfiguration */ NULL, /* create main configuration */ NULL, /* init main configuration */ NULL, /* create server configuration */ NULL, /* merge server configuration */ ngx_http_hello_create_loc_conf, /* create location configuration */ NULL /* merge location configuration */&#125;;ngx_module_t ngx_http_hello_module = &#123; NGX_MODULE_V1, &amp;ngx_http_hello_module_ctx, /* module context */ ngx_http_hello_commands, /* module directives */ NGX_HTTP_MODULE, /* module type */ NULL, /* init master */ NULL, /* init module */ NULL, /* init process */ NULL, /* init thread */ NULL, /* exit thread */ NULL, /* exit process */ NULL, /* exit master */ NGX_MODULE_V1_PADDING&#125;;static ngx_int_tngx_http_hello_handler(ngx_http_request_t *r)&#123; ngx_int_t rc; ngx_buf_t *b; ngx_chain_t out; ngx_http_hello_loc_conf_t* my_conf; u_char ngx_hello_string[1024] = &#123;0&#125;; ngx_uint_t content_length = 0; ngx_log_error(NGX_LOG_EMERG, r-&gt;connection-&gt;log, 0, "ngx_http_hello_handler is called!"); my_conf = ngx_http_get_module_loc_conf(r, ngx_http_hello_module); if (my_conf-&gt;hello_string.len == 0 ) &#123; ngx_log_error(NGX_LOG_EMERG, r-&gt;connection-&gt;log, 0, "hello_string is empty!"); return NGX_DECLINED; &#125; if (my_conf-&gt;hello_counter == NGX_CONF_UNSET || my_conf-&gt;hello_counter == 0) &#123; ngx_sprintf(ngx_hello_string, "%s", my_conf-&gt;hello_string.data); &#125; else &#123; ngx_sprintf(ngx_hello_string, "%s Visited Times:%d", my_conf-&gt;hello_string.data, ++ngx_hello_visited_times); &#125; ngx_log_error(NGX_LOG_EMERG, r-&gt;connection-&gt;log, 0, "hello_string:%s", ngx_hello_string); content_length = ngx_strlen(ngx_hello_string); /* we response to 'GET' and 'HEAD' requests only */ if (!(r-&gt;method &amp; (NGX_HTTP_GET|NGX_HTTP_HEAD))) &#123; return NGX_HTTP_NOT_ALLOWED; &#125; /* discard request body, since we don't need it here */ rc = ngx_http_discard_request_body(r); if (rc != NGX_OK) &#123; return rc; &#125; /* set the 'Content-type' header */ /* *r-&gt;headers_out.content_type.len = sizeof("text/html") - 1; *r-&gt;headers_out.content_type.data = (u_char *)"text/html"; */ ngx_str_set(&amp;r-&gt;headers_out.content_type, "text/html"); /* send the header only, if the request type is http 'HEAD' */ if (r-&gt;method == NGX_HTTP_HEAD) &#123; r-&gt;headers_out.status = NGX_HTTP_OK; r-&gt;headers_out.content_length_n = content_length; return ngx_http_send_header(r); &#125; /* allocate a buffer for your response body */ b = ngx_pcalloc(r-&gt;pool, sizeof(ngx_buf_t)); if (b == NULL) &#123; return NGX_HTTP_INTERNAL_SERVER_ERROR; &#125; /* attach this buffer to the buffer chain */ out.buf = b; out.next = NULL; /* adjust the pointers of the buffer */ b-&gt;pos = ngx_hello_string; b-&gt;last = ngx_hello_string + content_length; b-&gt;memory = 1; /* this buffer is in memory */ b-&gt;last_buf = 1; /* this is the last buffer in the buffer chain */ /* set the status line */ r-&gt;headers_out.status = NGX_HTTP_OK; r-&gt;headers_out.content_length_n = content_length; /* send the headers of your response */ rc = ngx_http_send_header(r); if (rc == NGX_ERROR || rc &gt; NGX_OK || r-&gt;header_only) &#123; return rc; &#125; /* send the buffer chain of your response */ return ngx_http_output_filter(r, &amp;out);&#125;static void *ngx_http_hello_create_loc_conf(ngx_conf_t *cf)&#123; ngx_http_hello_loc_conf_t* local_conf = NULL; local_conf = ngx_pcalloc(cf-&gt;pool, sizeof(ngx_http_hello_loc_conf_t)); if (local_conf == NULL) &#123; return NULL; &#125; ngx_str_null(&amp;local_conf-&gt;hello_string); local_conf-&gt;hello_counter = NGX_CONF_UNSET; return local_conf;&#125; /*static char *ngx_http_hello_merge_loc_conf(ngx_conf_t *cf, void *parent, void *child)&#123; ngx_http_hello_loc_conf_t* prev = parent; ngx_http_hello_loc_conf_t* conf = child; ngx_conf_merge_str_value(conf-&gt;hello_string, prev-&gt;hello_string, ngx_hello_default_string); ngx_conf_merge_value(conf-&gt;hello_counter, prev-&gt;hello_counter, 0); return NGX_CONF_OK;&#125;*/static char *ngx_http_hello_string(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)&#123; ngx_http_hello_loc_conf_t* local_conf; local_conf = conf; char* rv = ngx_conf_set_str_slot(cf, cmd, conf); ngx_conf_log_error(NGX_LOG_EMERG, cf, 0, "hello_string:%s", local_conf-&gt;hello_string.data); return rv;&#125;static char *ngx_http_hello_counter(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)&#123; ngx_http_hello_loc_conf_t* local_conf; local_conf = conf; char* rv = NULL; rv = ngx_conf_set_flag_slot(cf, cmd, conf); ngx_conf_log_error(NGX_LOG_EMERG, cf, 0, "hello_counter:%d", local_conf-&gt;hello_counter); return rv; &#125;static ngx_int_tngx_http_hello_init(ngx_conf_t *cf)&#123; ngx_http_handler_pt *h; ngx_http_core_main_conf_t *cmcf; cmcf = ngx_http_conf_get_module_main_conf(cf, ngx_http_core_module); h = ngx_array_push(&amp;cmcf-&gt;phases[NGX_HTTP_CONTENT_PHASE].handlers); if (h == NULL) &#123; return NGX_ERROR; &#125; *h = ngx_http_hello_handler; return NGX_OK;&#125; 通过上面一些介绍，我相信大家都能对整个示例模块有一个比较好的理解。唯一可能感觉有些理解困难的地方在于ngx_http_hello_handler 函数里面产生和设置输出。但其实大家在本书的前面的相关章节都可以看到对 ngx_buf_t 和 request 等相关数据结构的说明。如果仔细看了这些地方的说明的话，应该对这里代码的实现就比较容易理解了。因此，这里不再赘述解释。 Nginx handler 模块的编译和使用由 小路依依 创建， 最后一次修改 2016-08-12 handler 模块的编译和使用模块的功能开发完了之后，模块的使用还需要编译才能够执行，下面我们来看下模块的编译和使用。 config 文件的编写对于开发一个模块，我们是需要把这个模块的 C 代码组织到一个目录里，同时需要编写一个 config 文件。这个 config 文件的内容就是告诉 Nginx 的编译脚本，该如何进行编译。我们来看一下 hello handler module 的 config 文件的内容，然后再做解释。 123ngx_addon_name=ngx_http_hello_moduleHTTP_MODULES=&quot;$HTTP_MODULES ngx_http_hello_module&quot;NGX_ADDON_SRCS=&quot;$NGX_ADDON_SRCS $ngx_addon_dir/ngx_http_hello_module.c&quot; 其实文件很简单，几乎不需要做什么解释。大家一看都懂了。唯一需要说明的是，如果这个模块的实现有多个源文件，那么都在 NGX_ADDON_SRCS 这个变量里，依次写进去就可以。 编译对于模块的编译，Nginx 并不像 apache 一样，提供了单独的编译工具，可以在没有 apache 源代码的情况下来单独编译一个模块的代码。Nginx 必须去到 Nginx 的源代码目录里，通过 configure 指令的参数，来进行编译。下面看一下 hello module 的 configure 指令： 1./configure --prefix=/usr/local/nginx-1.3.1 --add-module=/home/jizhao/open_source/book_module 我写的这个示例模块的代码和 config 文件都放在/home/jizhao/open_source/book_module这个目录下。所以一切都很明了，也没什么好说的了。 使用使用一个模块需要根据这个模块定义的配置指令来做。比如我们这个简单的 hello handler module 的使用就很简单。在我的测试服务器的配置文件里，就是在 http 里面的默认的 server 里面加入如下的配置： 1234location /test &#123; hello_string jizhao; hello_counter on;&#125; 当我们访问这个地址的时候, lynx http://127.0.0.1/test 的时候，就可以看到返回的结果。 1jizhao Visited Times:1 当然你访问多次，这个次数是会增加的。 Nginx 更多 handler 模块示例分析由 小路依依 创建， 最后一次修改 2016-08-12 更多 handler 模块示例分析http access module该模块的代码位于src/http/modules/ngx_http_access_module.c中。该模块的作用是提供对于特定 host 的客户端的访问控制。可以限定特定 host 的客户端对于服务端全部，或者某个 server，或者是某个 location 的访问。 该模块的实现非常简单，总共也就只有几个函数。 1234567891011121314static ngx_int_t ngx_http_access_handler(ngx_http_request_t *r);static ngx_int_t ngx_http_access_inet(ngx_http_request_t *r, ngx_http_access_loc_conf_t *alcf, in_addr_t addr);#if (NGX_HAVE_INET6)static ngx_int_t ngx_http_access_inet6(ngx_http_request_t *r, ngx_http_access_loc_conf_t *alcf, u_char *p);#endifstatic ngx_int_t ngx_http_access_found(ngx_http_request_t *r, ngx_uint_t deny);static char *ngx_http_access_rule(ngx_conf_t *cf, ngx_command_t *cmd, void *conf);static void *ngx_http_access_create_loc_conf(ngx_conf_t *cf);static char *ngx_http_access_merge_loc_conf(ngx_conf_t *cf, void *parent, void *child);static ngx_int_t ngx_http_access_init(ngx_conf_t *cf); 对于与配置相关的几个函数都不需要做解释了，需要提一下的是函数 ngx_http_access_init，该函数在实现上把本模块挂载到了 NGX_HTTP_ACCESS_PHASE 阶段的 handler 上，从而使自己的被调用时机发生在了 NGX_HTTP_CONTENT_PHASE 等阶段前。因为进行客户端地址的限制检查，根本不需要等到这么后面。 另外看一下这个模块的主处理函数 ngx_http_access_handler。这个函数的逻辑也非常简单，主要是根据客户端地址的类型，来分别选择 ipv4 类型的处理函数 ngx_http_access_inet 还是 ipv6 类型的处理函数 ngx_http_access_inet6。 而这个两个处理函数内部也非常简单，就是循环检查每个规则，检查是否有匹配的规则，如果有就返回匹配的结果，如果都没有匹配，就默认拒绝。 http static module从某种程度上来说，此模块可以算的上是“最正宗的”，“最古老”的 content handler。因为本模块的作用就是读取磁盘上的静态文件，并把文件内容作为产生的输出。在Web技术发展的早期，只有静态页面，没有服务端脚本来动态生成 HTML 的时候。恐怕开发个 Web 服务器的时候，第一个要开发就是这样一个 content handler。 http static module 的代码位于src/http/modules/ngx_http_static_module.c中，总共只有两百多行近三百行。可以说是非常短小。 我们首先来看一下该模块的模块上下文的定义。 12345678910111213ngx_http_module_t ngx_http_static_module_ctx = &#123; NULL, /* preconfiguration */ ngx_http_static_init, /* postconfiguration */ NULL, /* create main configuration */ NULL, /* init main configuration */ NULL, /* create server configuration */ NULL, /* merge server configuration */ NULL, /* create location configuration */ NULL /* merge location configuration */&#125;; 是非常的简洁吧，连任何与配置相关的函数都没有。对了，因为该模块没有提供任何配置指令。大家想想也就知道了，这个模块做的事情实在是太简单了，也确实没什么好配置的。唯一需要调用的函数是一个 ngx_http_static_init 函数。好了，来看一下这个函数都干了写什么。 1234567891011121314151617static ngx_int_tngx_http_static_init(ngx_conf_t *cf)&#123; ngx_http_handler_pt *h; ngx_http_core_main_conf_t *cmcf; cmcf = ngx_http_conf_get_module_main_conf(cf, ngx_http_core_module); h = ngx_array_push(&amp;cmcf-&gt;phases[NGX_HTTP_CONTENT_PHASE].handlers); if (h == NULL) &#123; return NGX_ERROR; &#125; *h = ngx_http_static_handler; return NGX_OK;&#125; 仅仅是挂载这个 handler 到 NGX_HTTP_CONTENT_PHASE 处理阶段。简单吧？ 下面我们就看一下这个模块最核心的处理逻辑所在的 ngx_http_static_handler 函数。该函数大概占了这个模块代码量的百分之八九十。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220static ngx_int_tngx_http_static_handler(ngx_http_request_t *r)&#123; u_char *last, *location; size_t root, len; ngx_str_t path; ngx_int_t rc; ngx_uint_t level; ngx_log_t *log; ngx_buf_t *b; ngx_chain_t out; ngx_open_file_info_t of; ngx_http_core_loc_conf_t *clcf; if (!(r-&gt;method &amp; (NGX_HTTP_GET|NGX_HTTP_HEAD|NGX_HTTP_POST))) &#123; return NGX_HTTP_NOT_ALLOWED; &#125; if (r-&gt;uri.data[r-&gt;uri.len - 1] == &apos;/&apos;) &#123; return NGX_DECLINED; &#125; log = r-&gt;connection-&gt;log; /* * ngx_http_map_uri_to_path() allocates memory for terminating &apos;\0&apos; * so we do not need to reserve memory for &apos;/&apos; for possible redirect */ last = ngx_http_map_uri_to_path(r, &amp;path, &amp;root, 0); if (last == NULL) &#123; return NGX_HTTP_INTERNAL_SERVER_ERROR; &#125; path.len = last - path.data; ngx_log_debug1(NGX_LOG_DEBUG_HTTP, log, 0, &quot;http filename: \&quot;%s\&quot;&quot;, path.data); clcf = ngx_http_get_module_loc_conf(r, ngx_http_core_module); ngx_memzero(&amp;of, sizeof(ngx_open_file_info_t)); of.read_ahead = clcf-&gt;read_ahead; of.directio = clcf-&gt;directio; of.valid = clcf-&gt;open_file_cache_valid; of.min_uses = clcf-&gt;open_file_cache_min_uses; of.errors = clcf-&gt;open_file_cache_errors; of.events = clcf-&gt;open_file_cache_events; if (ngx_http_set_disable_symlinks(r, clcf, &amp;path, &amp;of) != NGX_OK) &#123; return NGX_HTTP_INTERNAL_SERVER_ERROR; &#125; if (ngx_open_cached_file(clcf-&gt;open_file_cache, &amp;path, &amp;of, r-&gt;pool) != NGX_OK) &#123; switch (of.err) &#123; case 0: return NGX_HTTP_INTERNAL_SERVER_ERROR; case NGX_ENOENT: case NGX_ENOTDIR: case NGX_ENAMETOOLONG: level = NGX_LOG_ERR; rc = NGX_HTTP_NOT_FOUND; break; case NGX_EACCES:#if (NGX_HAVE_OPENAT) case NGX_EMLINK: case NGX_ELOOP:#endif level = NGX_LOG_ERR; rc = NGX_HTTP_FORBIDDEN; break; default: level = NGX_LOG_CRIT; rc = NGX_HTTP_INTERNAL_SERVER_ERROR; break; &#125; if (rc != NGX_HTTP_NOT_FOUND || clcf-&gt;log_not_found) &#123; ngx_log_error(level, log, of.err, &quot;%s \&quot;%s\&quot; failed&quot;, of.failed, path.data); &#125; return rc; &#125; r-&gt;root_tested = !r-&gt;error_page; ngx_log_debug1(NGX_LOG_DEBUG_HTTP, log, 0, &quot;http static fd: %d&quot;, of.fd); if (of.is_dir) &#123; ngx_log_debug0(NGX_LOG_DEBUG_HTTP, log, 0, &quot;http dir&quot;); ngx_http_clear_location(r); r-&gt;headers_out.location = ngx_palloc(r-&gt;pool, sizeof(ngx_table_elt_t)); if (r-&gt;headers_out.location == NULL) &#123; return NGX_HTTP_INTERNAL_SERVER_ERROR; &#125; len = r-&gt;uri.len + 1; if (!clcf-&gt;alias &amp;&amp; clcf-&gt;root_lengths == NULL &amp;&amp; r-&gt;args.len == 0) &#123; location = path.data + clcf-&gt;root.len; *last = &apos;/&apos;; &#125; else &#123; if (r-&gt;args.len) &#123; len += r-&gt;args.len + 1; &#125; location = ngx_pnalloc(r-&gt;pool, len); if (location == NULL) &#123; return NGX_HTTP_INTERNAL_SERVER_ERROR; &#125; last = ngx_copy(location, r-&gt;uri.data, r-&gt;uri.len); *last = &apos;/&apos;; if (r-&gt;args.len) &#123; *++last = &apos;?&apos;; ngx_memcpy(++last, r-&gt;args.data, r-&gt;args.len); &#125; &#125; /* * we do not need to set the r-&gt;headers_out.location-&gt;hash and * r-&gt;headers_out.location-&gt;key fields */ r-&gt;headers_out.location-&gt;value.len = len; r-&gt;headers_out.location-&gt;value.data = location; return NGX_HTTP_MOVED_PERMANENTLY; &#125;#if !(NGX_WIN32) /* the not regular files are probably Unix specific */ if (!of.is_file) &#123; ngx_log_error(NGX_LOG_CRIT, log, 0, &quot;\&quot;%s\&quot; is not a regular file&quot;, path.data); return NGX_HTTP_NOT_FOUND; &#125;#endif if (r-&gt;method &amp; NGX_HTTP_POST) &#123; return NGX_HTTP_NOT_ALLOWED; &#125; rc = ngx_http_discard_request_body(r); if (rc != NGX_OK) &#123; return rc; &#125; log-&gt;action = &quot;sending response to client&quot;; r-&gt;headers_out.status = NGX_HTTP_OK; r-&gt;headers_out.content_length_n = of.size; r-&gt;headers_out.last_modified_time = of.mtime; if (ngx_http_set_content_type(r) != NGX_OK) &#123; return NGX_HTTP_INTERNAL_SERVER_ERROR; &#125; if (r != r-&gt;main &amp;&amp; of.size == 0) &#123; return ngx_http_send_header(r); &#125; r-&gt;allow_ranges = 1; /* we need to allocate all before the header would be sent */ b = ngx_pcalloc(r-&gt;pool, sizeof(ngx_buf_t)); if (b == NULL) &#123; return NGX_HTTP_INTERNAL_SERVER_ERROR; &#125; b-&gt;file = ngx_pcalloc(r-&gt;pool, sizeof(ngx_file_t)); if (b-&gt;file == NULL) &#123; return NGX_HTTP_INTERNAL_SERVER_ERROR; &#125; rc = ngx_http_send_header(r); if (rc == NGX_ERROR || rc &gt; NGX_OK || r-&gt;header_only) &#123; return rc; &#125; b-&gt;file_pos = 0; b-&gt;file_last = of.size; b-&gt;in_file = b-&gt;file_last ? 1: 0; b-&gt;last_buf = (r == r-&gt;main) ? 1: 0; b-&gt;last_in_chain = 1; b-&gt;file-&gt;fd = of.fd; b-&gt;file-&gt;name = path; b-&gt;file-&gt;log = log; b-&gt;file-&gt;directio = of.is_directio; out.buf = b; out.next = NULL; return ngx_http_output_filter(r, &amp;out);&#125; 首先是检查客户端的 http 请求类型（r-&gt;method），如果请求类型为NGX_HTTP_GET|NGX_HTTP_HEAD|NGX_HTTP_POST，则继续进行处理，否则一律返回 NGX_HTTP_NOT_ALLOWED 从而拒绝客户端的发起的请求。 其次是检查请求的 url 的结尾字符是不是斜杠/，如果是说明请求的不是一个文件，给后续的 handler 去处理，比如后续的 ngx_http_autoindex_handler（如果是请求的是一个目录下面，可以列出这个目录的文件），或者是 ngx_http_index_handler（如果请求的路径下面有个默认的 index 文件，直接返回 index 文件的内容）。 然后接下来调用了一个 ngx_http_map_uri_to_path 函数，该函数的作用是把请求的 http 协议的路径转化成一个文件系统的路径。 然后根据转化出来的具体路径，去打开文件，打开文件的时候做了 2 种检查，一种是，如果请求的文件是个 symbol link，根据配置，是否允许符号链接，不允许返回错误。还有一个检查是，如果请求的是一个名称，是一个目录的名字，也返回错误。如果都没有错误，就读取文件，返回内容。其实说返回内容可能不是特别准确，比较准确的说法是，把产生的内容传递给后续的 filter 去处理。 http log module该模块提供了对于每一个 http 请求进行记录的功能，也就是我们见到的 access.log。当然这个模块对于 log 提供了一些配置指令，使得可以比较方便的定制 access.log。 这个模块的代码位于src/http/modules/ngx_http_log_module.c，虽然这个模块的代码有接近 1400 行，但是主要的逻辑在于对日志本身格式啊，等细节的处理。我们在这里进行分析主要是关注，如何编写一个 log handler 的问题。 由于 log handler 的时候，拿到的参数也是 request 这个东西，那么也就意味着我们如果需要，可以好好研究下这个结构，把我们需要的所有信息都记录下来。 对于 log handler，有一点特别需要注意的就是，log handler 是无论如何都会被调用的，就是只要服务端接受到了一个客户端的请求，也就是产生了一个 request 对象，那么这些个 log handler 的处理函数都会被调用的，就是在释放 request 的时候被调用的（ngx_http_free_request函数）。 那么当然绝对不能忘记的就是 log handler 最好，也是建议被挂载在 NGX_HTTP_LOG_PHASE 阶段。因为挂载在其他阶段，有可能在某些情况下被跳过，而没有执行到，导致你的 log 模块记录的信息不全。 还有一点要说明的是，由于 Nginx 是允许在某个阶段有多个 handler 模块存在的，根据其处理结果，确定是否要调用下一个 handler。但是对于挂载在 NGX_HTTP_LOG_PHASE 阶段的 handler，则根本不关注这里 handler 的具体处理函数的返回值，所有的都被调用。如下，位于src/http/ngx_http_request.c中的 ngx_http_log_request 函数。 12345678910111213141516static voidngx_http_log_request(ngx_http_request_t *r)&#123; ngx_uint_t i, n; ngx_http_handler_pt *log_handler; ngx_http_core_main_conf_t *cmcf; cmcf = ngx_http_get_module_main_conf(r, ngx_http_core_module); log_handler = cmcf-&gt;phases[NGX_HTTP_LOG_PHASE].handlers.elts; n = cmcf-&gt;phases[NGX_HTTP_LOG_PHASE].handlers.nelts; for (i = 0; i &lt; n; i++) &#123; log_handler[i](r); &#125;&#125; Nginx 过滤模块简介由 小路依依 创建， 最后一次修改 2016-08-12 过滤模块简介执行时间和内容过滤（filter）模块是过滤响应头和内容的模块，可以对回复的头和内容进行处理。它的处理时间在获取回复内容之后，向用户发送响应之前。它的处理过程分为两个阶段，过滤 HTTP 回复的头部和主体，在这两个阶段可以分别对头部和主体进行修改。 在代码中有类似的函数： 12ngx_http_top_header_filter(r);ngx_http_top_body_filter(r, in); 就是分别对头部和主体进行过滤的函数。所有模块的响应内容要返回给客户端，都必须调用这两个接口。 执行顺序过滤模块的调用是有顺序的，它的顺序在编译的时候就决定了。控制编译的脚本位于 auto/modules 中，当你编译完 Nginx 以后，可以在 objs 目录下面看到一个 ngx_modules.c 的文件。打开这个文件，有类似的代码： 1234567891011121314151617ngx_module_t *ngx_modules[] = &#123; ... &amp;ngx_http_write_filter_module, &amp;ngx_http_header_filter_module, &amp;ngx_http_chunked_filter_module, &amp;ngx_http_range_header_filter_module, &amp;ngx_http_gzip_filter_module, &amp;ngx_http_postpone_filter_module, &amp;ngx_http_ssi_filter_module, &amp;ngx_http_charset_filter_module, &amp;ngx_http_userid_filter_module, &amp;ngx_http_headers_filter_module, &amp;ngx_http_copy_filter_module, &amp;ngx_http_range_body_filter_module, &amp;ngx_http_not_modified_filter_module, NULL&#125;; 从 write_filter 到 not_modified_filter，模块的执行顺序是反向的。也就是说最早执行的是 not_modified_filter，然后各个模块依次执行。一般情况下，第三方过滤模块的 config 文件会将模块名追加到变量 HTTP_AUX_FILTER_MODULES 中，此时该模块只能加入到 copy_filter 和 headers_filter 模块之间执行。 Nginx 执行的时候是怎么按照次序依次来执行各个过滤模块呢？它采用了一种很隐晦的方法，即通过局部的全局变量。比如，在每个 filter 模块，很可能看到如下代码： 12345678910static ngx_http_output_header_filter_pt ngx_http_next_header_filter;static ngx_http_output_body_filter_pt ngx_http_next_body_filter;...ngx_http_next_header_filter = ngx_http_top_header_filter;ngx_http_top_header_filter = ngx_http_example_header_filter;ngx_http_next_body_filter = ngx_http_top_body_filter;ngx_http_top_body_filter = ngx_http_example_body_filter; ngx_http_top_header_filter 是一个全局变量。当编译进一个 filter 模块的时候，就被赋值为当前 filter 模块的处理函数。而 ngx_http_next_header_filter 是一个局部全局变量，它保存了编译前上一个 filter 模块的处理函数。所以整体看来，就像用全局变量组成的一条单向链表。 每个模块想执行下一个过滤函数，只要调用一下 ngx_http_next_header_filter 这个局部变量。而整个过滤模块链的入口，需要调用 ngx_http_top_header_filter 这个全局变量。ngx_http_top_body_filter 的行为与 header fitler 类似。 响应头和响应体过滤函数的执行顺序如下所示： 这图只表示了 head_filter 和 body_filter 之间的执行顺序，在 header_filter 和 body_filter 处理函数之间，在 body_filter 处理函数之间，可能还有其他执行代码。 模块编译Nginx 可以方便的加入第三方的过滤模块。在过滤模块的目录里，首先需要加入 config 文件，文件的内容如下： 123ngx_addon_name=ngx_http_example_filter_moduleHTTP_AUX_FILTER_MODULES=&quot;$HTTP_AUX_FILTER_MODULES ngx_http_example_filter_module&quot;NGX_ADDON_SRCS=&quot;$NGX_ADDON_SRCS $ngx_addon_dir/ngx_http_example_filter_module.c&quot; 说明把这个名为 ngx_http_example_filter_module 的过滤模块加入，ngx_http_example_filter_module.c 是该模块的源代码。 注意 HTTP_AUX_FILTER_MODULES 这个变量与一般的内容处理模块不同。 Nginx 过滤模块的分析由 小路依依 创建， 最后一次修改 2016-08-12 过滤模块的分析相关结构体ngx_chain_t 结构非常简单，是一个单向链表： 123456typedef struct ngx_chain_s ngx_chain_t;struct ngx_chain_s &#123; ngx_buf_t *buf; ngx_chain_t *next;&#125;; 在过滤模块中，所有输出的内容都是通过一条单向链表所组成。这种单向链表的设计，正好应和了 Nginx 流式的输出模式。每次 Nginx 都是读到一部分的内容，就放到链表，然后输出出去。这种设计的好处是简单，非阻塞，但是相应的问题就是跨链表的内容操作非常麻烦，如果需要跨链表，很多时候都只能缓存链表的内容。 单链表负载的就是 ngx_buf_t，这个结构体使用非常广泛，先让我们看下该结构体的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748struct ngx_buf_s &#123; u_char *pos; /* 当前buffer真实内容的起始位置 */ u_char *last; /* 当前buffer真实内容的结束位置 */ off_t file_pos; /* 在文件中真实内容的起始位置 */ off_t file_last; /* 在文件中真实内容的结束位置 */ u_char *start; /* buffer内存的开始分配的位置 */ u_char *end; /* buffer内存的结束分配的位置 */ ngx_buf_tag_t tag; /* buffer属于哪个模块的标志 */ ngx_file_t *file; /* buffer所引用的文件 */ /* 用来引用替换过后的buffer，以便当所有buffer输出以后， * 这个影子buffer可以被释放。 */ ngx_buf_t *shadow; /* the buf&apos;s content could be changed */ unsigned temporary:1; /* * the buf&apos;s content is in a memory cache or in a read only memory * and must not be changed */ unsigned memory:1; /* the buf&apos;s content is mmap()ed and must not be changed */ unsigned mmap:1; unsigned recycled:1; /* 内存可以被输出并回收 */ unsigned in_file:1; /* buffer的内容在文件中 */ /* 马上全部输出buffer的内容, gzip模块里面用得比较多 */ unsigned flush:1; /* 基本上是一段输出链的最后一个buffer带的标志，标示可以输出， * 有些零长度的buffer也可以置该标志 */ unsigned sync:1; /* 所有请求里面最后一块buffer，包含子请求 */ unsigned last_buf:1; /* 当前请求输出链的最后一块buffer */ unsigned last_in_chain:1; /* shadow链里面的最后buffer，可以释放buffer了 */ unsigned last_shadow:1; /* 是否是暂存文件 */ unsigned temp_file:1; /* 统计用，表示使用次数 */ /* STUB */ int num;&#125;; 一般 buffer 结构体可以表示一块内存，内存的起始和结束地址分别用 start 和 end 表示，pos 和 last 表示实际的内容。如果内容已经处理过了，pos 的位置就可以往后移动。如果读取到新的内容，last 的位置就会往后移动。所以 buffer 可以在多次调用过程中使用。如果 last 等于 end，就说明这块内存已经用完了。如果 pos 等于 last，说明内存已经处理完了。下面是一个简单的示意图，说明 buffer 中指针的用法： 响应头过滤函数响应头过滤函数主要的用处就是处理 HTTP 响应的头，可以根据实际情况对于响应头进行修改或者添加删除。响应头过滤函数先于响应体过滤函数，而且只调用一次，所以一般可作过滤模块的初始化工作。 响应头过滤函数的入口只有一个： 1234567ngx_int_tngx_http_send_header(ngx_http_request_t *r)&#123; ... return ngx_http_top_header_filter(r);&#125; 该函数向客户端发送回复的时候调用，然后按前一节所述的执行顺序。该函数的返回值一般是 NGX_OK，NGX_ERROR 和 NGX_AGAIN，分别表示处理成功，失败和未完成。 你可以把 HTTP 响应头的存储方式想象成一个 hash 表，在 Nginx 内部可以很方便地查找和修改各个响应头部，ngx_http_header_filter_module 过滤模块把所有的 HTTP 头组合成一个完整的 buffer，最终 ngx_http_write_filter_module 过滤模块把 buffer 输出。 按照前一节过滤模块的顺序，依次讲解如下： filter module description ngx_http_not_modified_filter_module 默认打开，如果请求的 if-modified-since 等于回复的 last-modified 间值，说明回复没有变化，清空所有回复的内容，返回 304。 ngx_http_range_body_filter_module 默认打开，只是响应体过滤函数，支持 range 功能，如果请求包含range请求，那就只发送range请求的一段内容。 ngx_http_copy_filter_module 始终打开，只是响应体过滤函数， 主要工作是把文件中内容读到内存中，以便进行处理。 ngx_http_headers_filter_module 始终打开，可以设置 expire 和 Cache-control 头，可以添加任意名称的头 ngx_http_userid_filter_module 默认关闭，可以添加统计用的识别用户的 cookie。 ngx_http_charset_filter_module 默认关闭，可以添加 charset，也可以将内容从一种字符集转换到另外一种字符集，不支持多字节字符集。 ngx_http_ssi_filter_module 默认关闭，过滤 SSI 请求，可以发起子请求，去获取include进来的文件 ngx_http_postpone_filter_module 始终打开，用来将子请求和主请求的输出链合并 ngx_http_gzip_filter_module 默认关闭，支持流式的压缩内容 ngx_http_range_header_filter_module 默认打开，只是响应头过滤函数，用来解析range头，并产生range响应的头。 ngx_http_chunked_filter_module 默认打开，对于 HTTP/1.1 和缺少 content-length 的回复自动打开。 ngx_http_header_filter_module 始终打开，用来将所有 header 组成一个完整的 HTTP 头。 ngx_http_write_filter_module 始终打开，将输出链拷贝到 r-&gt;out中，然后输出内容。 响应体过滤函数响应体过滤函数是过滤响应主体的函数。ngx_http_top_body_filter 这个函数每个请求可能会被执行多次，它的入口函数是 ngx_http_output_filter，比如： 1234567891011121314151617ngx_int_tngx_http_output_filter(ngx_http_request_t *r, ngx_chain_t *in)&#123; ngx_int_t rc; ngx_connection_t *c; c = r-&gt;connection; rc = ngx_http_top_body_filter(r, in); if (rc == NGX_ERROR) &#123; /* NGX_ERROR may be returned by any filter */ c-&gt;error = 1; &#125; return rc;&#125; ngx_http_output_filter 可以被一般的静态处理模块调用，也有可能是在 upstream 模块里面被调用，对于整个请求的处理阶段来说，他们处于的用处都是一样的，就是把响应内容过滤，然后发给客户端。 具体模块的响应体过滤函数的格式类似这样： 1234567static int ngx_http_example_body_filter(ngx_http_request_t *r, ngx_chain_t *in)&#123; ... return ngx_http_next_body_filter(r, in);&#125; 该函数的返回值一般是 NGX_OK，NGX_ERROR 和 NGX_AGAIN，分别表示处理成功，失败和未完成。 主要功能介绍响应的主体内容就存于单链表 in，链表一般不会太长，有时 in 参数可能为 NULL。in中存有buf结构体中，对于静态文件，这个buf大小默认是 32K；对于反向代理的应用，这个buf可能是4k或者8k。为了保持内存的低消耗，Nginx一般不会分配过大的内存，处理的原则是收到一定的数据，就发送出去。一个简单的例子，可以看看Nginx的chunked_filter模块，在没有 content-length 的情况下，chunk 模块可以流式（stream）的加上长度，方便浏览器接收和显示内容。 在响应体过滤模块中，尤其要注意的是 buf 的标志位，完整描述可以在“相关结构体”这个节中看到。如果 buf 中包含 last 标志，说明是最后一块 buf，可以直接输出并结束请求了。如果有 flush 标志，说明这块 buf 需要马上输出，不能缓存。如果整块 buffer 经过处理完以后，没有数据了，你可以把 buffer 的 sync 标志置上，表示只是同步的用处。 当所有的过滤模块都处理完毕时，在最后的 write_fitler 模块中，Nginx 会将 in 输出链拷贝到 r-&gt;out 输出链的末尾，然后调用 sendfile 或者 writev 接口输出。由于 Nginx 是非阻塞的 socket 接口，写操作并不一定会成功，可能会有部分数据还残存在 r-&gt;out。在下次的调用中，Nginx 会继续尝试发送，直至成功。 发出子请求Nginx 过滤模块一大特色就是可以发出子请求，也就是在过滤响应内容的时候，你可以发送新的请求，Nginx 会根据你调用的先后顺序，将多个回复的内容拼接成正常的响应主体。一个简单的例子可以参考 addition 模块。 Nginx 是如何保证父请求和子请求的顺序呢？当 Nginx 发出子请求时，就会调用 ngx_http_subrequest 函数，将子请求插入父请求的 r-&gt;postponed 链表中。子请求会在主请求执行完毕时获得依次调用。子请求同样会有一个请求所有的生存期和处理过程，也会进入过滤模块流程。 关键点是在 postpone_filter 模块中，它会拼接主请求和子请求的响应内容。r-&gt;postponed 按次序保存有父请求和子请求，它是一个链表，如果前面一个请求未完成，那后一个请求内容就不会输出。当前一个请求完成时并输出时，后一个请求才可输出，当所有的子请求都完成时，所有的响应内容也就输出完毕了。 一些优化措施Nginx 过滤模块涉及到的结构体，主要就是 chain 和 buf，非常简单。在日常的过滤模块中，这两类结构使用非常频繁，Nginx采用类似 freelist 重复利用的原则，将使用完毕的 chain 或者 buf 结构体，放置到一个固定的空闲链表里，以待下次使用。 比如，在通用内存池结构体中，pool-&gt;chain 变量里面就保存着释放的 chain。而一般的 buf 结构体，没有模块间公用的空闲链表池，都是保存在各模块的缓存空闲链表池里面。对于 buf 结构体，还有一种 busy 链表，表示该链表中的 buf 都处于输出状态，如果 buf 输出完毕，这些 buf 就可以释放并重复利用了。 功能 函数名 chain 分配 ngx_alloc_chain_link chain 释放 ngx_free_chain buf 分配 ngx_chain_get_free_buf buf 释放 ngx_chain_update_chains 过滤内容的缓存由于 Nginx 设计流式的输出结构，当我们需要对响应内容作全文过滤的时候，必须缓存部分的 buf 内容。该类过滤模块往往比较复杂，比如 sub，ssi，gzip 等模块。这类模块的设计非常灵活，我简单讲一下设计原则： 输入链 in 需要拷贝操作，经过缓存的过滤模块，输入输出链往往已经完全不一样了，所以需要拷贝，通过 ngx_chain_add_copy 函数完成。 一般有自己的 free 和 busy 缓存链表池，可以提高 buf 分配效率。 如果需要分配大块内容，一般分配固定大小的内存卡，并设置 recycled 标志，表示可以重复利用。 原有的输入 buf 被替换缓存时，必须将其 buf-&gt;pos 设为 buf-&gt;last，表明原有的 buf 已经被输出完毕。或者在新建立的 buf，将 buf-&gt;shadow 指向旧的 buf，以便输出完毕时及时释放旧的 buf。 Nginx upstream 模块简介由 小路依依 创建，Loen 最后一次修改 2016-08-12 upstream 模块简介Nginx 模块一般被分成三大类：handler、filter 和 upstream。前面的章节中，读者已经了解了 handler、filter。利用这两类模块，可以使 Nginx 轻松完成任何单机工作。而本章介绍的 upstream 模块，将使 Nginx 跨越单机的限制，完成网络数据的接收、处理和转发。 数据转发功能，为 Nginx 提供了跨越单机的横向处理能力，使 Nginx 摆脱只能为终端节点提供单一功能的限制，而使它具备了网路应用级别的拆分、封装和整合的战略功能。在云模型大行其道的今天，数据转发是 Nginx 有能力构建一个网络应用的关键组件。当然，鉴于开发成本的问题，一个网络应用的关键组件一开始往往会采用高级编程语言开发。但是当系统到达一定规模，并且需要更重视性能的时候，为了达到所要求的性能目标，高级语言开发出的组件必须进行结构化修改。此时，对于修改代价而言，Nginx 的 upstream 模块呈现出极大的吸引力，因为它天生就快。作为附带，Nginx 的配置系统提供的层次化和松耦合使得系统的扩展性也达到比较高的程度。 言归正传，下面介绍 upstream 的写法。 upstream 模块接口从本质上说，upstream 属于 handler，只是他不产生自己的内容，而是通过请求后端服务器得到内容，所以才称为 upstream（上游）。请求并取得响应内容的整个过程已经被封装到 Nginx 内部，所以 upstream 模块只需要开发若干回调函数，完成构造请求和解析响应等具体的工作。 这些回调函数如下表所示： SN 描述 create_request 生成发送到后端服务器的请求缓冲（缓冲链），在初始化 upstream 时使用。 reinit_request 在某台后端服务器出错的情况，Nginx会尝试另一台后端服务器。Nginx 选定新的服务器以后，会先调用此函数，以重新初始化 upstream 模块的工作状态，然后再次进行 upstream 连接。 process_header 处理后端服务器返回的信息头部。所谓头部是与 upstreamserver 通信的协议规定的，比如 HTTP 协议的 header 部分，或者 memcached 协议的响应状态部分。 abort_request 在客户端放弃请求时被调用。不需要在函数中实现关闭后端服务器连接的功能，系统会自动完成关闭连接的步骤，所以一般此函数不会进行任何具体工作。 finalize_request 正常完成与后端服务器的请求后调用该函数，与 abort_request 相同，一般也不会进行任何具体工作。 input_filter 处理后端服务器返回的响应正文。Nginx 默认的 input_filter 会将收到的内容封装成为缓冲区链 ngx_chain。该链由 upstream 的 out_bufs 指针域定位，所以开发人员可以在模块以外通过该指针 得到后端服务器返回的正文数据。memcached 模块实现了自己的 input_filter，在后面会具体分析这个模块。 input_filter_init 初始化 input filter 的上下文。Nginx 默认的 input_filter_init 直接返回。 memcached 模块分析memcache 是一款高性能的分布式 cache 系统，得到了非常广泛的应用。memcache 定义了一套私有通信协议，使得不能通过 HTTP 请求来访问 memcache。但协议本身简单高效，而且 memcache 使用广泛，所以大部分现代开发语言和平台都提供了 memcache 支持，方便开发者使用 memcache。 Nginx 提供了 ngx_http_memcached 模块，提供从 memcache 读取数据的功能，而不提供向 memcache 写数据的功能。作为 Web 服务器，这种设计是可以接受的。 下面，我们开始分析 ngx_http_memcached 模块，一窥 upstream 的奥秘。 Handler 模块？初看 memcached 模块，大家可能觉得并无特别之处。如果稍微细看，甚至觉得有点像 handler 模块，当大家看到这段代码以后，必定疑惑为什么会跟 handler 模块一模一样。 12clcf = ngx_http_conf_get_module_loc_conf(cf, ngx_http_core_module);clcf-&gt;handler = ngx_http_memcached_handler; 因为 upstream 模块使用的就是 handler 模块的接入方式。同时，upstream 模块的指令系统的设计也是遵循 handler 模块的基本规则：配置该模块才会执行该模块。 123456&#123; ngx_string(&quot;memcached_pass&quot;), NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1, ngx_http_memcached_pass, NGX_HTTP_LOC_CONF_OFFSET, 0, NULL &#125; 所以大家觉得眼熟是好事，说明大家对 Handler 的写法已经很熟悉了。 Upstream 模块那么，upstream 模块的特别之处究竟在哪里呢？答案是就在模块处理函数的实现中。upstream 模块的处理函数进行的操作都包含一个固定的流程。在 memcached 的例子中，可以观察 ngx_http_memcached_handler 的代码，可以发现，这个固定的操作流程是： 创建 upstream 数据结构。 123if (ngx_http_upstream_create(r) != NGX_OK) &#123; return NGX_HTTP_INTERNAL_SERVER_ERROR;&#125; 设置模块的 tag 和 schema。schema 现在只会用于日志，tag 会用于 buf_chain 管理。 1234u = r-&gt;upstream;ngx_str_set(&amp;u-&gt;schema, &quot;memcached://&quot;);u-&gt;output.tag = (ngx_buf_tag_t) &amp;ngx_http_memcached_module; 设置 upstream 的后端服务器列表数据结构。 12mlcf = ngx_http_get_module_loc_conf(r, ngx_http_memcached_module);u-&gt;conf = &amp;mlcf-&gt;upstream; 设置 upstream 回调函数。在这里列出的代码稍稍调整了代码顺序。 1234567u-&gt;create_request = ngx_http_memcached_create_request;u-&gt;reinit_request = ngx_http_memcached_reinit_request;u-&gt;process_header = ngx_http_memcached_process_header;u-&gt;abort_request = ngx_http_memcached_abort_request;u-&gt;finalize_request = ngx_http_memcached_finalize_request;u-&gt;input_filter_init = ngx_http_memcached_filter_init;u-&gt;input_filter = ngx_http_memcached_filter; 创建并设置 upstream 环境数据结构。 1234567891011ctx = ngx_palloc(r-&gt;pool, sizeof(ngx_http_memcached_ctx_t));if (ctx == NULL) &#123; return NGX_HTTP_INTERNAL_SERVER_ERROR;&#125;ctx-&gt;rest = NGX_HTTP_MEMCACHED_END;ctx-&gt;request = r;ngx_http_set_ctx(r, ctx, ngx_http_memcached_module);u-&gt;input_filter_ctx = ctx; 完成 upstream 初始化并进行收尾工作。 123r-&gt;main-&gt;count++;ngx_http_upstream_init(r);return NGX_DONE; 任何 upstream 模块，简单如 memcached，复杂如 proxy、fastcgi 都是如此。不同的 upstream 模块在这 6 步中的最大差别会出现在第 2、3、4、5 上。其中第 2、4 两步很容易理解，不同的模块设置的标志和使用的回调函数肯定不同。第 5 步也不难理解，只有第3步是最为晦涩的，不同的模块在取得后端服务器列表时，策略的差异非常大，有如 memcached 这样简单明了的，也有如 proxy 那样逻辑复杂的。这个问题先记下来，等把memcached剖析清楚了，再单独讨论。 第 6 步是一个常态。将 count 加 1，然后返回 NGX_DONE。Nginx 遇到这种情况，虽然会认为当前请求的处理已经结束，但是不会释放请求使用的内存资源，也不会关闭与客户端的连接。之所以需要这样，是因为 Nginx 建立了 upstream 请求和客户端请求之间一对一的关系，在后续使用 ngx_event_pipe 将 upstream 响应发送回客户端时，还要使用到这些保存着客户端信息的数据结构。这部分会在后面的原理篇做具体介绍，这里不再展开。 将 upstream 请求和客户端请求进行一对一绑定，这个设计有优势也有缺陷。优势就是简化模块开发，可以将精力集中在模块逻辑上，而缺陷同样明显，一对一的设计很多时候都不能满足复杂逻辑的需要。对于这一点，将会在后面的原理篇来阐述。 回调函数前面剖析了 memcached 模块的骨架，现在开始逐个解决每个回调函数。 ngx_http_memcached_create_request：很简单的按照设置的内容生成一个 key，接着生成一个“get $key”的请求，放在 r-&gt;upstream-&gt;request_bufs 里面。 ngx_http_memcached_reinit_request：无需初始化。 ngx_http_memcached_abort_request：无需额外操作。 ngx_http_memcached_finalize_request：无需额外操作。 ngx_http_memcached_process_header：模块的业务重点函数。memcache 协议的头部信息被定义为第一行文本，可以找到这段代码证明： 1234for (p = u-&gt;buffer.pos; p &lt; u-&gt;buffer.last; p++) &#123; if ( * p == LF) &#123; goto found;&#125; 如果在已读入缓冲的数据中没有发现 LF(‘\n’)字符，函数返回 NGX_AGAIN，表示头部未完全读入，需要继续读取数据。Nginx 在收到新的数据以后会再次调用该函数。 Nginx 处理后端服务器的响应头时只会使用一块缓存，所有数据都在这块缓存中，所以解析头部信息时不需要考虑头部信息跨越多块缓存的情况。而如果头部过大，不能保存在这块缓存中，Nginx 会返回错误信息给客户端，并记录 error log，提示缓存不够大。 process_header 的重要职责是将后端服务器返回的状态翻译成返回给客户端的状态。例如，在 ngx_http_memcached_process_header 中，有这样几段代码： 1234567r-&gt;headers_out.content_length_n = ngx_atoof(len, p - len - 1);u-&gt;headers_in.status_n = 200;u-&gt;state-&gt;status = 200;u-&gt;headers_in.status_n = 404;u-&gt;state-&gt;status = 404; u-&gt;state 用于计算 upstream 相关的变量。比如 u-&gt;state-&gt;status 将被用于计算变量“upstream_status”的值。u-&gt;headers_in 将被作为返回给客户端的响应返回状态码。而第一行则是设置返回给客户端的响应的长度。 在这个函数中不能忘记的一件事情是处理完头部信息以后需要将读指针 pos 后移，否则这段数据也将被复制到返回给客户端的响应的正文中，进而导致正文内容不正确。 1u-&gt;buffer.pos = p + 1; process_header 函数完成响应头的正确处理，应该返回 NGX_OK。如果返回 NGX_AGAIN，表示未读取完整数据，需要从后端服务器继续读取数据。返回 NGX_DECLINED 无意义，其他任何返回值都被认为是出错状态，Nginx 将结束 upstream 请求并返回错误信息。 ngx_http_memcached_filter_init：修正从后端服务器收到的内容长度。因为在处理 header 时没有加上这部分长度。 ngx_http_memcached_filter：memcached 模块是少有的带有处理正文的回调函数的模块。因为 memcached 模块需要过滤正文末尾 CRLF “END” CRLF，所以实现了自己的 filter 回调函数。处理正文的实际意义是将从后端服务器收到的正文有效内容封装成 ngx_chain_t，并加在 u-&gt;out_bufs 末尾。Nginx 并不进行数据拷贝，而是建立 ngx_buf_t 数据结构指向这些数据内存区，然后由 ngx_chain_t 组织这些 buf。这种实现避免了内存大量搬迁，也是 Nginx 高效的奥秘之一。 本节回顾这一节介绍了 upstream 模块的基本组成。upstream 模块是从 handler 模块发展而来，指令系统和模块生效方式与 handler 模块无异。不同之处在于，upstream 模块在 handler 函数中设置众多回调函数。实际工作都是由这些回调函数完成的。每个回调函数都是在 upstream 的某个固定阶段执行，各司其职，大部分回调函数一般不会真正用到。upstream 最重要的回调函数是 create_request、process_header 和 input_filter，他们共同实现了与后端服务器的协议的解析部分。 Nginx 负载均衡模块由 小路依依 创建， 最后一次修改 2016-08-12 负载均衡模块负载均衡模块用于从upstream指令定义的后端主机列表中选取一台主机。Nginx 先使用负载均衡模块找到一台主机，再使用 upstream 模块实现与这台主机的交互。为了方便介绍负载均衡模块，做到言之有物，以下选取 Nginx 内置的 ip hash 模块作为实际例子进行分析。 配置要了解负载均衡模块的开发方法，首先需要了解负载均衡模块的使用方法。因为负载均衡模块与之前书中提到的模块差别比较大，所以我们从配置入手比较容易理解。 在配置文件中，我们如果需要使用 ip hash 的负载均衡算法。我们需要写一个类似下面的配置： 123456upstream test &#123; ip_hash; server 192.168.0.1; server 192.168.0.2;&#125; 从配置我们可以看出负载均衡模块的使用场景： 核心指令ip_hash只能在 upstream {}中使用。这条指令用于通知 Nginx 使用 ip hash 负载均衡算法。如果没加这条指令，Nginx 会使用默认的 round robin 负载均衡模块。请各位读者对比 handler 模块的配置，是不是有共同点？ upstream {}中的指令可能出现在server指令前，可能出现在server指令后，也可能出现在两条server指令之间。各位读者可能会有疑问，有什么差别么？那么请各位读者尝试下面这个配置： 12345upstream test &#123; server 192.168.0.1 weight=5; ip_hash; server 192.168.0.2 weight=7;&#125; 神奇的事情出现了： 12nginx: [emerg] invalid parameter &quot;weight=7&quot; in nginx.conf:103configuration file nginx.conf test failed 可见 ip_hash 指令的确能影响到配置的解析。 指令配置决定指令系统，现在就来看 ip_hash 的指令定义： 1234567891011static ngx_command_t ngx_http_upstream_ip_hash_commands[] = &#123; &#123; ngx_string(&quot;ip_hash&quot;), NGX_HTTP_UPS_CONF|NGX_CONF_NOARGS, ngx_http_upstream_ip_hash, 0, 0, NULL &#125;, ngx_null_command&#125;; 没有特别的东西，除了指令属性是 NGX_HTTP_UPS_CONF。这个属性表示该指令的适用范围是 upstream{}。 钩子以从前面的章节得到的经验，大家应该知道这里就是模块的切入点了。负载均衡模块的钩子代码都是有规律的，这里通过 ip_hash 模块来分析这个规律。 12345678910111213141516static char *ngx_http_upstream_ip_hash(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)&#123; ngx_http_upstream_srv_conf_t *uscf; uscf = ngx_http_conf_get_module_srv_conf(cf, ngx_http_upstream_module); uscf-&gt;peer.init_upstream = ngx_http_upstream_init_ip_hash; uscf-&gt;flags = NGX_HTTP_UPSTREAM_CREATE |NGX_HTTP_UPSTREAM_MAX_FAILS |NGX_HTTP_UPSTREAM_FAIL_TIMEOUT |NGX_HTTP_UPSTREAM_DOWN; return NGX_CONF_OK;&#125; 这段代码中有两点值得我们注意。一个是 uscf-&gt;flags 的设置，另一个是设置 init_upstream 回调。 设置 uscf-&gt;flags NGX_HTTP_UPSTREAM_CREATE：创建标志，如果含有创建标志的话，Nginx 会检查重复创建，以及必要参数是否填写； NGX_HTTP_UPSTREAM_MAX_FAILS：可以在 server 中使用 max_fails 属性； NGX_HTTP_UPSTREAM_FAIL_TIMEOUT：可以在 server 中使用 fail_timeout 属性； NGX_HTTP_UPSTREAM_DOWN：可以在 server 中使用 down 属性； NGX_HTTP_UPSTREAM_WEIGHT：可以在 server 中使用 weight 属性； NGX_HTTP_UPSTREAM_BACKUP：可以在 server 中使用 backup 属性。 聪明的读者如果联想到刚刚遇到的那个神奇的配置错误，可以得出一个结论：在负载均衡模块的指令处理函数中可以设置并修改 upstream{} 中server指令支持的属性。这是一个很重要的性质，因为不同的负载均衡模块对各种属性的支持情况都是不一样的，那么就需要在解析配置文件的时候检测出是否使用了不支持的负载均衡属性并给出错误提示，这对于提升系统维护性是很有意义的。但是，这种机制也存在缺陷，正如前面的例子所示，没有机制能够追加检查在更新支持属性之前已经配置了不支持属性的server指令。 设置 init_upstream 回调Nginx 初始化 upstream 时，会在 ngx_http_upstream_init_main_conf 函数中调用设置的回调函数初始化负载均衡模块。这里不太好理解的是 uscf 的具体位置。通过下面的示意图，说明 upstream 负载均衡模块的配置的内存布局。 从图上可以看出，MAIN_CONF 中 ngx_upstream_module 模块的配置项中有一个指针数组 upstreams，数组中的每个元素对应就是配置文件中每一个 upstream{}的信息。更具体的将会在后面的原理篇讨论。 初始化配置init_upstream 回调函数执行时需要初始化负载均衡模块的配置，还要设置一个新钩子，这个钩子函数会在 Nginx 处理每个请求时作为初始化函数调用，关于这个新钩子函数的功能，后面会有详细的描述。这里，我们先分析 IP hash 模块初始化配置的代码： 12ngx_http_upstream_init_round_robin(cf, us);us-&gt;peer.init = ngx_http_upstream_init_ip_hash_peer; 这段代码非常简单：IP hash 模块首先调用另一个负载均衡模块 Round Robin 的初始化函数，然后再设置自己的处理请求阶段初始化钩子。实际上几个负载均衡模块可以组成一条链表，每次都是从链首的模块开始进行处理。如果模块决定不处理，可以将处理权交给链表中的下一个模块。这里，IP hash 模块指定 Round Robin 模块作为自己的后继负载均衡模块，所以在自己的初始化配置函数中也对 Round Robin 模块进行初始化。 初始化请求Nginx 收到一个请求以后，如果发现需要访问 upstream，就会执行对应的 peer.init 函数。这是在初始化配置时设置的回调函数。这个函数最重要的作用是构造一张表，当前请求可以使用的 upstream 服务器被依次添加到这张表中。之所以需要这张表，最重要的原因是如果 upstream 服务器出现异常，不能提供服务时，可以从这张表中取得其他服务器进行重试操作。此外，这张表也可以用于负载均衡的计算。之所以构造这张表的行为放在这里而不是在前面初始化配置的阶段，是因为upstream需要为每一个请求提供独立隔离的环境。 为了讨论 peer.init 的核心，我们还是看 IP hash 模块的实现： 12345r-&gt;upstream-&gt;peer.data = &amp;iphp-&gt;rrp;ngx_http_upstream_init_round_robin_peer(r, us);r-&gt;upstream-&gt;peer.get = ngx_http_upstream_get_ip_hash_peer; 第一行是设置数据指针，这个指针就是指向前面提到的那张表； 第二行是调用 Round Robin 模块的回调函数对该模块进行请求初始化。面前已经提到，一个负载均衡模块可以调用其他负载均衡模块以提供功能的补充。 第三行是设置一个新的回调函数get。该函数负责从表中取出某个服务器。除了 get 回调函数，还有另一个r-&gt;upstream-&gt;peer.free的回调函数。该函数在 upstream 请求完成后调用，负责做一些善后工作。比如我们需要维护一个 upstream 服务器访问计数器，那么可以在 get 函数中对其加 1，在 free 中对其减 1。如果是 SSL 的话，Nginx 还提供两个回调函数 peer.set_session 和 peer.save_session。一般来说，有两个切入点实现负载均衡算法，其一是在这里，其二是在 get 回调函数中。 peer.get 和 peer.free 回调函数这两个函数是负载均衡模块最底层的函数，负责实际获取一个连接和回收一个连接的预备操作。之所以说是预备操作，是因为在这两个函数中，并不实际进行建立连接或者释放连接的动作，而只是执行获取连接的地址或维护连接状态的操作。需要理解的清楚一点，在 peer.get 函数中获取连接的地址信息，并不代表这时连接一定没有被建立，相反的，通过 get 函数的返回值，Nginx 可以了解是否存在可用连接，连接是否已经建立。这些返回值总结如下： 返回值 说明 Nginx 后续动作 NGX_DONE 得到了连接地址信息，并且连接已经建立。 直接使用连接，发送数据。 NGX_OK 得到了连接地址信息，但连接并未建立。 建立连接，如连接不能立即建立，设置事件， 暂停执行本请求，执行别的请求。 NGX_BUSY 所有连接均不可用。 返回502错误至客户端。 各位读者看到上面这张表，可能会有几个问题浮现出来： Q: 什么时候连接是已经建立的？ A: 使用后端 keepalive 连接的时候，连接在使用完以后并不关闭，而是存放在一个队列中，新的请求只需要从队列中取出连接，这些连接都是已经准备好的。 Q: 什么叫所有连接均不可用？ A: 初始化请求的过程中，建立了一张表，get 函数负责每次从这张表中不重复的取出一个连接，当无法从表中取得一个新的连接时，即所有连接均不可用。 Q: 对于一个请求，peer.get 函数可能被调用多次么？ A: 正式如此。当某次 peer.get 函数得到的连接地址连接不上，或者请求对应的服务器得到异常响应，Nginx 会执行 ngx_http_upstream_next，然后可能再次调用 peer.get 函数尝试别的连接。upstream 整体流程如下： 本节回顾这一节介绍了负载均衡模块的基本组成。负载均衡模块的配置区集中在 upstream{}块中。负载均衡模块的回调函数体系是以 init_upstream 为起点，经历 init_peer，最终到达 peer.get 和 peer.free。其中 init_peer 负责建立每个请求使用的 server 列表，peer.get 负责从 server 列表中选择某个 server（一般是不重复选择），而 peer.free 负责 server 释放前的资源释放工作。最后，这一节通过一张图将 upstream 模块和负载均衡模块在请求处理过程中的相互关系展现出来。 Nginx core 模块由 小路依依 创建， 最后一次修改 2016-08-12 core 模块Nginx 的启动模块启动模块从启动 Nginx 进程开始，做了一系列的初始化工作，源代码位于src/core/nginx.c，从 main 函数开始: 时间、正则、错误日志、ssl 等初始化 读入命令行参数 OS 相关初始化 读入并解析配置 核心模块初始化 创建各种暂时文件和目录 创建共享内存 打开 listen 的端口 所有模块初始化 启动 worker 进程 Nginx event 模块由 小路依依 创建， 最后一次修改 2016-08-12 event 模块event 的类型和功能Nginx 是以 event（事件）处理模型为基础的模块。它为了支持跨平台，抽象出了 event 模块。它支持的 event 处理类型有：AIO（异步IO），/dev/poll（Solaris 和 Unix 特有），epoll（Linux 特有），eventport（Solaris 10 特有），kqueue（BSD 特有），poll，rtsig（实时信号），select 等。 event 模块的主要功能就是，监听 accept 后建立的连接，对读写事件进行添加删除。事件处理模型和 Nginx 的非阻塞 IO 模型结合在一起使用。当 IO 可读可写的时候，相应的读写事件就会被唤醒，此时就会去处理事件的回调函数。 特别对于 Linux，Nginx 大部分 event 采用 epoll EPOLLET（边沿触发）的方法来触发事件，只有 listen 端口的读事件是 EPOLLLT（水平触发）。对于边沿触发，如果出现了可读事件，必须及时处理，否则可能会出现读事件不再触发，连接饿死的情况。 1234567891011121314151617181920typedef struct &#123; /* 添加删除事件 */ ngx_int_t (*add)(ngx_event_t *ev, ngx_int_t event, ngx_uint_t flags); ngx_int_t (*del)(ngx_event_t *ev, ngx_int_t event, ngx_uint_t flags); ngx_int_t (*enable)(ngx_event_t *ev, ngx_int_t event, ngx_uint_t flags); ngx_int_t (*disable)(ngx_event_t *ev, ngx_int_t event, ngx_uint_t flags); /* 添加删除连接，会同时监听读写事件 */ ngx_int_t (*add_conn)(ngx_connection_t *c); ngx_int_t (*del_conn)(ngx_connection_t *c, ngx_uint_t flags); ngx_int_t (*process_changes)(ngx_cycle_t *cycle, ngx_uint_t nowait); /* 处理事件的函数 */ ngx_int_t (*process_events)(ngx_cycle_t *cycle, ngx_msec_t timer, ngx_uint_t flags); ngx_int_t (*init)(ngx_cycle_t *cycle, ngx_msec_t timer); void (*done)(ngx_cycle_t *cycle);&#125; ngx_event_actions_t; 上述是 event 处理抽象出来的关键结构体，可以看到，每个 event 处理模型，都需要实现部分功能。最关键的是 add 和 del 功能，就是最基本的添加和删除事件的函数。 accept 锁Nginx 是多进程程序，80 端口是各进程所共享的，多进程同时 listen 80 端口，势必会产生竞争，也产生了所谓的“惊群”效应。当内核 accept 一个连接时，会唤醒所有等待中的进程，但实际上只有一个进程能获取连接，其他的进程都是被无效唤醒的。所以 Nginx 采用了自有的一套 accept 加锁机制，避免多个进程同时调用 accept。Nginx 多进程的锁在底层默认是通过 CPU 自旋锁来实现。如果操作系统不支持自旋锁，就采用文件锁。 Nginx 事件处理的入口函数是 ngx_process_events_and_timers()，下面是部分代码，可以看到其加锁的过程： 123456789101112131415161718192021if (ngx_use_accept_mutex) &#123; if (ngx_accept_disabled &gt; 0) &#123; ngx_accept_disabled--; &#125; else &#123; if (ngx_trylock_accept_mutex(cycle) == NGX_ERROR) &#123; return; &#125; if (ngx_accept_mutex_held) &#123; flags |= NGX_POST_EVENTS; &#125; else &#123; if (timer == NGX_TIMER_INFINITE || timer &gt; ngx_accept_mutex_delay) &#123; timer = ngx_accept_mutex_delay; &#125; &#125; &#125;&#125; 在 ngx_trylock_accept_mutex()函数里面，如果拿到了锁，Nginx 会把 listen 的端口读事件加入 event 处理，该进程在有新连接进来时就可以进行 accept 了。注意 accept 操作是一个普通的读事件。下面的代码说明了这点： 123456789(void) ngx_process_events(cycle, timer, flags);if (ngx_posted_accept_events) &#123; ngx_event_process_posted(cycle, &amp;ngx_posted_accept_events);&#125;if (ngx_accept_mutex_held) &#123; ngx_shmtx_unlock(&amp;ngx_accept_mutex);&#125; ngx_process_events()函数是所有事件处理的入口，它会遍历所有的事件。抢到了 accept 锁的进程跟一般进程稍微不同的是，它被加上了 NGX_POST_EVENTS 标志，也就是说在 ngx_process_events() 函数里面只接受而不处理事件，并加入 post_events 的队列里面。直到 ngx_accept_mutex 锁去掉以后才去处理具体的事件。为什么这样？因为 ngx_accept_mutex 是全局锁，这样做可以尽量减少该进程抢到锁以后，从 accept 开始到结束的时间，以便其他进程继续接收新的连接，提高吞吐量。 ngx_posted_accept_events 和 ngx_posted_events 就分别是 accept 延迟事件队列和普通延迟事件队列。可以看到 ngx_posted_accept_events 还是放到 ngx_accept_mutex 锁里面处理的。该队列里面处理的都是 accept 事件，它会一口气把内核 backlog 里等待的连接都 accept 进来，注册到读写事件里。 而 ngx_posted_events 是普通的延迟事件队列。一般情况下，什么样的事件会放到这个普通延迟队列里面呢？我的理解是，那些 CPU 耗时比较多的都可以放进去。因为 Nginx 事件处理都是根据触发顺序在一个大循环里依次处理的，因为 Nginx 一个进程同时只能处理一个事件，所以有些耗时多的事件会把后面所有事件的处理都耽搁了。 除了加锁，Nginx 也对各进程的请求处理的均衡性作了优化，也就是说，如果在负载高的时候，进程抢到的锁过多，会导致这个进程被禁止接受请求一段时间。 比如，在 ngx_event_accept 函数中，有类似代码： 12ngx_accept_disabled = ngx_cycle-&gt;connection_n / 8 - ngx_cycle-&gt;free_connection_n; ngx_cycle-&gt;connection_n 是进程可以分配的连接总数，ngx_cycle-&gt;free_connection_n 是空闲的进程数。上述等式说明了，当前进程的空闲进程数小于 1/8 的话，就会被禁止 accept 一段时间。 定时器Nginx 在需要用到超时的时候，都会用到定时器机制。比如，建立连接以后的那些读写超时。Nginx 使用红黑树来构造定期器，红黑树是一种有序的二叉平衡树，其查找插入和删除的复杂度都为 O(logn)，所以是一种比较理想的二叉树。 定时器的机制就是，二叉树的值是其超时时间，每次查找二叉树的最小值，如果最小值已经过期，就删除该节点，然后继续查找，直到所有超时节点都被删除。]]></content>
      <tags>
        <tag>-nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx 配置文件nginx.conf中文详解]]></title>
    <url>%2Fp%2Fce6.html</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332######Nginx配置文件nginx.conf中文详解######定义Nginx运行的用户和用户组user www www;#nginx进程数，建议设置为等于CPU总核心数。worker_processes 8; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]error_log /usr/local/nginx/logs/error.log info;#进程pid文件pid /usr/local/nginx/logs/nginx.pid;#指定进程可以打开的最大描述符：数目#工作模式与连接数上限#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。#现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。#这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。worker_rlimit_nofile 65535;events&#123; #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型 #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。 #补充说明： #与apache相类，nginx针对不同的操作系统，有不同的事件模型 #A）标准事件模型 #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll #B）高效事件模型 #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。 #Epoll：使用于Linux内核2.6版本及以后的系统。 #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。 #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。 use epoll; #单个进程最大连接数（最大连接数=连接数*进程数） #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。 worker_connections 65535; #keepalive超时时间。 keepalive_timeout 60; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。 #分页大小可以用命令getconf PAGESIZE 取得。 #[root@web001 ~]# getconf PAGESIZE #4096 #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。 open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。 #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息. open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。 #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态. open_file_cache_min_uses 1; #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件时记录cache错误. open_file_cache_errors on;&#125; #设定http服务器，利用它的反向代理功能提供负载均衡支持http&#123; #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #默认编码 #charset utf-8; #服务器名字的hash表大小 #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小. server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。 client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。 large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。 sendfile on; #开启目录列表访问，合适下载服务器，默认关闭。 autoindex on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩等级 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。 gzip_vary on; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; #负载均衡配置 upstream jh.w3cschool.cn &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。 server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3; #nginx的upstream目前支持4种方式的分配 #1、轮询（默认） #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 #2、weight #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 #例如： #upstream bakend &#123; # server 192.168.0.14 weight=10; # server 192.168.0.15 weight=10; #&#125; #2、ip_hash #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 #例如： #upstream bakend &#123; # ip_hash; # server 192.168.0.14:88; # server 192.168.0.15:80; #&#125; #3、fair（第三方） #按后端服务器的响应时间来分配请求，响应时间短的优先分配。 #upstream backend &#123; # server server1; # server server2; # fair; #&#125; #4、url_hash（第三方） #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法 #upstream backend &#123; # server squid1:3128; # server squid2:3128; # hash $request_uri; # hash_method crc32; #&#125; #tips: #upstream bakend&#123;#定义负载均衡设备的Ip及设备状态&#125;&#123; # ip_hash; # server 127.0.0.1:9090 down; # server 127.0.0.1:8080 weight=2; # server 127.0.0.1:6060; # server 127.0.0.1:7070 backup; #&#125; #在需要使用负载均衡的server中增加 proxy_pass http://bakend/; #每个设备的状态设置为: #1.down表示单前的server暂时不参与负载 #2.weight为weight越大，负载的权重就越大。 #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误 #4.fail_timeout:max_fails次失败后，暂停的时间。 #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。 #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug #client_body_temp_path设置记录文件的目录 可以设置最多3层目录 #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡 &#125; #虚拟主机的配置 server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name www.w3cschool.cn w3cschool.cn; index index.html index.htm index.php; root /data/www/w3cschool; #对******进行负载均衡 location ~ .*.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址； #$remote_user：用来记录客户端用户名称； #$time_local： 用来记录访问时间与时区； #$request： 用来记录请求的url与http协议； #$status： 用来记录请求状态；成功是200， #$body_bytes_sent ：记录发送给客户端文件主体内容大小； #$http_referer：用来记录从那个页面链接访问过来的； #$http_user_agent：记录客户浏览器的相关信息； #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。 log_format access '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" $http_x_forwarded_for'; #定义本虚拟主机的访问日志 access_log /usr/local/nginx/logs/host.access.log main; access_log /usr/local/nginx/logs/host.access.404.log log404; #对 "/" 启用反向代理 location / &#123; proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数， #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。 #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答。 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候响应超时时间 #nginx跟后端服务器连接超时时间(代理连接超时) proxy_connect_timeout 90; #后端服务器数据回传时间(代理发送超时) #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时) #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小 proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; &#125; #设定查看Nginx状态的地址 location /NginxStatus &#123; stub_status on; access_log on; auth_basic "NginxStatus"; auth_basic_user_file confpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。 &#125; #本地动静分离反向代理配置 #所有jsp的页面均交由tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; #所有静态文件由nginx直接读取不经过tomcat或resin location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt| pdf|xls|mp3|wma)$ &#123; expires 15d; &#125; location ~ .*.(js|css)?$ &#123; expires 1h; &#125; &#125;&#125;######Nginx配置文件nginx.conf中文详解#####]]></content>
      <tags>
        <tag>-nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell教程]]></title>
    <url>%2Fp%2F9924.html</url>
    <content type="text"><![CDATA[Shell 脚本Shell 脚本（shell script），是一种为shell编写的脚本程序。 业界所说的shell通常都是指shell脚本，但读者朋友要知道，shell和shell script是两个不同的概念。 由于习惯的原因，简洁起见，本文出现的”shell编程”都是指shell脚本编程，不是指开发shell自身。 Shell 环境Shell 编程跟java、php编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。 Linux的Shell种类众多，常见的有： Bourne Shell（/usr/bin/sh或/bin/sh） Bourne Again Shell（/bin/bash） C Shell（/usr/bin/csh） K Shell（/usr/bin/ksh） Shell for Root（/sbin/sh） …… 本教程关注的是 Bash，也就是 Bourne Again Shell，由于易用和免费，Bash在日常工作中被广泛使用。同时，Bash也是大多数Linux系统默认的Shell。 在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 #!/bin/sh，它同样也可以改为#!/bin/bash。 #!告诉系统其后路径所指定的程序即是解释此脚本文件的Shell程序。 第一个shell脚本打开文本编辑器(可以使用vi/vim命令来创建文件)，新建一个文件test.sh，扩展名为sh（sh代表shell），扩展名并不影响脚本执行，见名知意就好，如果你用php写shell 脚本，扩展名就用php好了。 输入一些代码，第一行一般是这样： 实例12#!/bin/bashecho "Hello World !" “#!” 是一个约定的标记，它告诉系统这个脚本需要什么解释器来执行，即使用哪一种Shell。 echo命令用于向窗口输出文本。 运行Shell脚本有两种方法：1、作为可执行程序将上面的代码保存为test.sh，并cd到相应目录： 12chmod +x ./test.sh #使脚本具有执行权限./test.sh #执行脚本 注意，一定要写成./test.sh，而不是test.sh，运行其它二进制的程序也一样，直接写test.sh，linux系统会去PATH里寻找有没有叫test.sh的，而只有/bin, /sbin, /usr/bin，/usr/sbin等在PATH里，你的当前目录通常不在PATH里，所以写成test.sh是会找不到命令的，要用./test.sh告诉系统说，就在当前目录找。 2、作为解释器参数这种运行方式是，直接运行解释器，其参数就是shell脚本的文件名，如： 12/bin/sh test.sh/bin/php test.php 这种方式运行的脚本，不需要在第一行指定解释器信息，写了也没用。 Shell 变量Shell 变量定义变量时，变量名不加美元符号（$，PHP语言中变量需要），如： 1your_name="123" 注意，变量名和等号之间不能有空格，这可能和你熟悉的所有编程语言都不一样。同时，变量名的命名须遵循如下规则： 首个字符必须为字母（a-z，A-Z）。 中间不能有空格，可以使用下划线（_）。 不能使用标点符号。 不能使用bash里的关键字（可用help命令查看保留关键字）。 除了显式地直接赋值，还可以用语句给变量赋值，如： 1for file in `ls /etc` 以上语句将 /etc 下目录的文件名循环出来。 使用变量使用一个定义过的变量，只要在变量名前面加美元符号即可，如： 123your_name="qinjx"echo $your_nameecho $&#123;your_name&#125; 变量名外面的花括号是可选的，加不加都行，加花括号是为了帮助解释器识别变量的边界，比如下面这种情况： 123for skill in Ada Coffe Action Java do echo &quot;I am good at $&#123;skill&#125;Script&quot;done 如果不给skill变量加花括号，写成echo “I am good at $skillScript”，解释器就会把$skillScript当成一个变量（其值为空），代码执行结果就不是我们期望的样子了。 推荐给所有变量加上花括号，这是个好的编程习惯。 已定义的变量，可以被重新定义，如： 1234your_name="tom"echo $your_nameyour_name="alibaba"echo $your_name 这样写是合法的，但注意，第二次赋值的时候不能写$your_name=”alibaba”，使用变量的时候才加美元符（$）。 Shell 字符串字符串是shell编程中最常用最有用的数据类型（除了数字和字符串，也没啥其它类型好用了），字符串可以用单引号，也可以用双引号，也可以不用引号。单双引号的区别跟PHP类似。 单引号1str='this is a string' 单引号字符串的限制： 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的； 单引号字串中不能出现单引号（对单引号使用转义符后也不行）。 双引号12your_name='qinjx'str="Hello, I know your are \"$your_name\"! \n" 双引号的优点： 双引号里可以有变量 双引号里可以出现转义字符 拼接字符串1234your_name="qinjx"greeting="hello, "$your_name" !"greeting_1="hello, $&#123;your_name&#125; !"echo $greeting $greeting_1 获取字符串长度12string="abcd"echo $&#123;#string&#125; #输出 4 提取子字符串12string="alibaba is a great company"echo $&#123;string:1:4&#125; #输出liba 查找子字符串12string="alibaba is a great company"echo `expr index "$string" is` 注意： 以上脚本中 “`” 是反引号，而不是单引号 “‘“，不要看错了哦。 Shell 数组bash支持一维数组（不支持多维数组），并且没有限定数组的大小。 类似与C语言，数组元素的下标由0开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于0。 定义数组在Shell中，用括号来表示数组，数组元素用”空格”符号分割开。定义数组的一般形式为： 1数组名=(值1 值2 ... 值n) 例如： 1array_name=(value0 value1 value2 value3) 或者 123456array_name=(value0value1value2value3) 还可以单独定义数组的各个分量： 123array_name[0]=value0array_name[1]=value1array_name[n]=valuen 可以不使用连续的下标，而且下标的范围没有限制。 读取数组读取数组元素值的一般格式是： 1$&#123;数组名[下标]&#125; 例如： 1valuen=$&#123;array_name[n]&#125; 使用@符号可以获取数组中的所有元素，例如： 1echo $&#123;array_name[@]&#125; 获取数组的长度获取数组长度的方法与获取字符串长度的方法相同，例如： 123456# 取得数组元素的个数length=$&#123;#array_name[@]&#125;# 或者length=$&#123;#array_name[*]&#125;# 取得数组单个元素的长度lengthn=$&#123;#array_name[n]&#125; Shell 注释以”#”开头的行就是注释，会被解释器忽略。 sh里没有多行注释，只能每一行加一个#号。只能像这样： 12345678910111213#--------------------------------------------# 这是一个自动打ipa的脚本，基于webfrogs的ipa-build书写：# https://github.com/webfrogs/xcode_shell/blob/master/ipa-build# 功能：自动为etao ios app打包，产出物为14个渠道的ipa包# 特色：全自动打包，不需要输入任何参数#--------------------------------------------##### 用户配置区 开始 ######## 项目根目录，推荐将此脚本放在项目的根目录，这里就不用改了# 应用名，确保和Xcode里Product下的target_name.app名字一致###### 用户配置区 结束 ##### 如果在开发过程中，遇到大段的代码需要临时注释起来，过一会儿又取消注释，怎么办呢？ 每一行加个#符号太费力了，可以把这一段要注释的代码用一对花括号括起来，定义成一个函数，没有地方调用这个函数，这块代码就不会执行，达到了和注释一样的效果。 Shell 传递参数Shell 传递参数我们可以在执行 Shell 脚本时，向脚本传递参数，脚本内获取参数的格式为：$n。n 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推…… 实例以下实例我们向脚本传递三个参数，并分别输出，其中 $0 为执行的文件名： 123456789#!/bin/bash# author:W3Cschool教程# url:www.123echo "Shell 传递参数实例！";echo "执行的文件名：$0";echo "第一个参数为：$1";echo "第二个参数为：$2";echo "第三个参数为：$3"; 为脚本设置可执行权限，并执行脚本，输出结果如下所示： 1234567$ chmod +x test.sh $ ./test.sh 1 2 3Shell 传递参数实例！执行的文件名：test.sh第一个参数为：1第二个参数为：2第三个参数为：3 另外，还有几个特殊字符用来处理参数： 参数处理 说明 $# 传递到脚本的参数个数 $* 以一个单字符串显示所有向脚本传递的参数。 如”$*”用「”」括起来的情况、以”$1 $2 … $n”的形式输出所有参数。 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。 如”$@”用「”」括起来的情况、以”$1” “$2” … “$n” 的形式输出所有参数。 $- 显示Shell使用的当前选项，与set命令功能相同。 $? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 123456789#!/bin/bash# author:W3Cschool教程# url:www.123echo "Shell 传递参数实例！";echo "第一个参数为：$1";echo "参数个数为：$#";echo "传递的参数作为一个字符串显示：$*"; 执行脚本，输出结果如下所示： 123456$ chmod +x test.sh $ ./test.sh 1 2 3Shell 传递参数实例！第一个参数为：1参数个数为：3传递的参数作为一个字符串显示：1 2 3 $* 与 $@ 区别： 相同点：都是引用所有参数。 不同点：只有在双引号中体现出来。假设在脚本运行时写了三个参数 1、2、3，，则 “ * “ 等价于 “1 2 3”（传递了一个参数），而 “@” 等价于 “1” “2” “3”（传递了三个参数）。 12345678910111213#!/bin/bash# author:W3Cschool教程# url:www.123echo "-- \$* 演示 ---"for i in "$*"; do echo $idoneecho "-- \$@ 演示 ---"for i in "$@"; do echo $idone 执行脚本，输出结果如下所示： 12345678$ chmod +x test.sh $ ./test.sh 1 2 3-- $* 演示 ---1 2 3-- $@ 演示 ---123 Shell 数组Shell 数组数组中可以存放多个值。Bash Shell 只支持一维数组（不支持多维数组），初始化时不需要定义数组大小（与 PHP 类似）。 与大部分编程语言类似，数组元素的下标由0开始。 Shell 数组用括号来表示，元素用”空格”符号分割开，语法格式如下： 1array_name=(value1 ... valuen) 实例12345#!/bin/bash# author:W3Cschool教程# url:www.123my_array=(A B "C" D) 我们也可以使用下标来定义数组: 123array_name[0]=value0array_name[1]=value1array_name[2]=value2 读取数组读取数组元素值的一般格式是： 1$&#123;array_name[index]&#125; 实例12345678910#!/bin/bash# author:W3Cschool教程# url:www.123my_array=(A B "C" D)echo "第一个元素为: $&#123;my_array[0]&#125;"echo "第二个元素为: $&#123;my_array[1]&#125;"echo "第三个元素为: $&#123;my_array[2]&#125;"echo "第四个元素为: $&#123;my_array[3]&#125;" 执行脚本，输出结果如下所示： 123456$ chmod +x test.sh $ ./test.sh第一个元素为: A第二个元素为: B第三个元素为: C第四个元素为: D 获取数组中的所有元素使用@ 或 * 可以获取数组中的所有元素，例如： 1234567891011#!/bin/bash# author:W3Cschool教程# url:www.123my_array[0]=Amy_array[1]=Bmy_array[2]=Cmy_array[3]=Decho "数组的元素为: $&#123;my_array[*]&#125;"echo "数组的元素为: $&#123;my_array[@]&#125;" 执行脚本，输出结果如下所示： 1234$ chmod +x test.sh $ ./test.sh数组的元素为: A B C D数组的元素为: A B C D 获取数组的长度获取数组长度的方法与获取字符串长度的方法相同，例如： 1234567891011#!/bin/bash# author:W3Cschool教程# url:www.123my_array[0]=Amy_array[1]=Bmy_array[2]=Cmy_array[3]=Decho "数组元素个数为: $&#123;#my_array[*]&#125;"echo "数组元素个数为: $&#123;#my_array[@]&#125;" 执行脚本，输出结果如下所示： 1234$ chmod +x test.sh $ ./test.sh数组元素个数为: 4数组元素个数为: 4 Shell 运算符Shell 基本运算符Shell 和其他编程语言一样，支持多种运算符，包括： 算数运算符 关系运算符 布尔运算符 字符串运算符 文件测试运算符 expr 是一款表达式计算工具，使用它能完成表达式的求值操作。 例如，两个数相加(注意使用的是反引号 ` 而不是单引号 ‘)： 1234#!/bin/bashval=`expr 2 + 2`echo "两数之和为 : $val" 运行实例 » 执行脚本，输出结果如下所示： 1两数之和为 : 4 两点注意： 表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2，这与我们熟悉的大多数编程语言不一样。 完整的表达式要被 包含，注意这个字符不是常用的单引号，在 Esc 键下边。 算术运算符下表列出了常用的算术运算符，假定变量 a 为 10，变量 b 为 20： 运算符 说明 举例 + 加法 expr $a + $b 结果为 30。 - 减法 expr $a - $b 结果为 -10。 * 乘法 expr $a \* $b 结果为 200。 / 除法 expr $b / $a 结果为 2。 % 取余 expr $b % $a 结果为 0。 = 赋值 a=$b 将把变量 b 的值赋给 a。 == 相等。用于比较两个数字，相同则返回 true。 [ $a == $b ] 返回 false。 != 不相等。用于比较两个数字，不相同则返回 true。 [ $a != $b ] 返回 true。 注意：条件表达式要放在方括号之间，并且要有空格，例如: [$a==$b] 是错误的，必须写成 [ $a == $b ]。 实例算术运算符实例如下： 123456789101112131415161718192021222324252627282930#!/bin/bash# author:W3Cschool教程# url:www.123a=10b=20val=`expr $a + $b`echo "a + b : $val"val=`expr $a - $b`echo "a - b : $val"val=`expr $a \* $b`echo "a * b : $val"val=`expr $b / $a`echo "b / a : $val"val=`expr $b % $a`echo "b % a : $val"if [ $a == $b ]then echo "a 等于 b"fiif [ $a != $b ]then echo "a 不等于 b"fi 执行脚本，输出结果如下所示： 123456a + b : 30a - b : -10a * b : 200b / a : 2b % a : 0a 不等于 b 注意：乘号()前边必须加反斜杠()才能实现乘法运算；if…then…fi 是条件语句，后续将会讲解。在 MAC 中 shell 的 expr 语法是：$((表达式))，此处表达式中的 ““ 不需要转义符号 “\” 。 关系运算符关系运算符只支持数字，不支持字符串，除非字符串的值是数字。 下表列出了常用的关系运算符，假定变量 a 为 10，变量 b 为 20： 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 实例关系运算符实例如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243#!/bin/bash# author:W3Cschool教程# url:www.123a=10b=20if [ $a -eq $b ]then echo "$a -eq $b : a 等于 b"else echo "$a -eq $b: a 不等于 b"fiif [ $a -ne $b ]then echo "$a -ne $b: a 不等于 b"else echo "$a -ne $b : a 等于 b"fiif [ $a -gt $b ]then echo "$a -gt $b: a 大于 b"else echo "$a -gt $b: a 不大于 b"fiif [ $a -lt $b ]then echo "$a -lt $b: a 小于 b"else echo "$a -lt $b: a 不小于 b"fiif [ $a -ge $b ]then echo "$a -ge $b: a 大于或等于 b"else echo "$a -ge $b: a 小于 b"fiif [ $a -le $b ]then echo "$a -le $b: a 小于或等于 b"else echo "$a -le $b: a 大于 b"fi 执行脚本，输出结果如下所示： 12345610 -eq 20: a 不等于 b10 -ne 20: a 不等于 b10 -gt 20: a 不大于 b10 -lt 20: a 小于 b10 -ge 20: a 小于 b10 -le 20: a 小于或等于 b 布尔运算符下表列出了常用的布尔运算符，假定变量 a 为 10，变量 b 为 20： 运算符 说明 举例 ! 非运算，表达式为 true 则返回 false，否则返回 true。 [ ! false ] 返回 true。 -o 或运算，有一个表达式为 true 则返回 true。 [ $a -lt 20 -o $b -gt 100 ] 返回 true。 -a 与运算，两个表达式都为 true 才返回 true。 [ $a -lt 20 -a $b -gt 100 ] 返回 false。 实例布尔运算符实例如下： 12345678910111213141516171819202122232425262728293031#!/bin/bash# author:W3Cschool教程# url:www.123a=10b=20if [ $a != $b ]then echo "$a != $b : a 不等于 b"else echo "$a != $b: a 等于 b"fiif [ $a -lt 100 -a $b -gt 15 ]then echo "$a -lt 100 -a $b -gt 15 : 返回 true"else echo "$a -lt 100 -a $b -gt 15 : 返回 false"fiif [ $a -lt 100 -o $b -gt 100 ]then echo "$a -lt 100 -o $b -gt 100 : 返回 true"else echo "$a -lt 100 -o $b -gt 100 : 返回 false"fiif [ $a -lt 5 -o $b -gt 100 ]then echo "$a -lt 5 -o $b -gt 100 : 返回 true"else echo "$a -lt 5 -o $b -gt 100 : 返回 false"fi 执行脚本，输出结果如下所示： 123410 != 20 : a 不等于 b10 -lt 100 -a 20 -gt 15 : 返回 true10 -lt 100 -o 20 -gt 100 : 返回 true10 -lt 5 -o 20 -gt 100 : 返回 false 逻辑运算符以下介绍 Shell 的逻辑运算符，假定变量 a 为 10，变量 b 为 20: 运算符 说明 举例 &amp;&amp; 逻辑的 AND [[ $a -lt 100 &amp;&amp; $b -gt 100 ]] 返回 false \ \ 逻辑的 OR [[ $a -lt 100 \ \ $b -gt 100 ]] 返回 true 实例逻辑运算符实例如下： 1234567891011121314151617181920#!/bin/bash# author:W3Cschool教程# url:www.123a=10b=20if [[ $a -lt 100 &amp;&amp; $b -gt 100 ]]then echo "返回 true"else echo "返回 false"fiif [[ $a -lt 100 || $b -gt 100 ]]then echo "返回 true"else echo "返回 false"fi 执行脚本，输出结果如下所示： 12返回 false返回 true 字符串运算符下表列出了常用的字符串运算符，假定变量 a 为 “abc”，变量 b 为 “efg”： 运算符 说明 举例 = 检测两个字符串是否相等，相等返回 true。 [ $a = $b ] 返回 false。 != 检测两个字符串是否相等，不相等返回 true。 [ $a != $b ] 返回 true。 -z 检测字符串长度是否为0，为0返回 true。 [ -z $a ] 返回 false。 -n 检测字符串长度是否为0，不为0返回 true。 [ -n $a ] 返回 true。 str 检测字符串是否为空，不为空返回 true。 [ $a ] 返回 true。 实例字符串运算符实例如下： 12345678910111213141516171819202122232425262728293031323334353637#!/bin/bash# author:W3Cschool教程# url:www.123a="abc"b="efg"if [ $a = $b ]then echo "$a = $b : a 等于 b"else echo "$a = $b: a 不等于 b"fiif [ $a != $b ]then echo "$a != $b : a 不等于 b"else echo "$a != $b: a 等于 b"fiif [ -z $a ]then echo "-z $a : 字符串长度为 0"else echo "-z $a : 字符串长度不为 0"fiif [ -n $a ]then echo "-n $a : 字符串长度不为 0"else echo "-n $a : 字符串长度为 0"fiif [ $a ]then echo "$a : 字符串不为空"else echo "$a : 字符串为空"fi 执行脚本，输出结果如下所示： 12345abc = efg: a 不等于 babc != efg : a 不等于 b-z abc : 字符串长度不为 0-n abc : 字符串长度不为 0abc : 字符串不为空 文件测试运算符文件测试运算符用于检测 Unix 文件的各种属性。 属性检测描述如下： 操作符 说明 举例 -b file 检测文件是否是块设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。 -c file 检测文件是否是字符设备文件，如果是，则返回 true。 [ -c $file ] 返回 false。 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -g file 检测文件是否设置了 SGID 位，如果是，则返回 true。 [ -g $file ] 返回 false。 -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 [ -k $file ] 返回 false。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -u file 检测文件是否设置了 SUID 位，如果是，则返回 true。 [ -u $file ] 返回 false。 -r file 检测文件是否可读，如果是，则返回 true。 [ -r $file ] 返回 true。 -w file 检测文件是否可写，如果是，则返回 true。 [ -w $file ] 返回 true。 -x file 检测文件是否可执行，如果是，则返回 true。 [ -x $file ] 返回 true。 -s file 检测文件是否为空（文件大小是否大于0），不为空返回 true。 [ -s $file ] 返回 true。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 实例变量 file 表示文件”/var/www/w3cschool/test.sh”，它的大小为100字节，具有 rwx 权限。下面的代码，将检测该文件的各种属性： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/bin/bash# author:W3Cschool教程# url:www.123file="/var/www/w3cschool/test.sh"if [ -r $file ]then echo "文件可读"else echo "文件不可读"fiif [ -w $file ]then echo "文件可写"else echo "文件不可写"fiif [ -x $file ]then echo "文件可执行"else echo "文件不可执行"fiif [ -f $file ]then echo "文件为普通文件"else echo "文件为特殊文件"fiif [ -d $file ]then echo "文件是个目录"else echo "文件不是个目录"fiif [ -s $file ]then echo "文件不为空"else echo "文件为空"fiif [ -e $file ]then echo "文件存在"else echo "文件不存在"fi 执行脚本，输出结果如下所示： 1234567文件可读文件可写文件可执行文件为普通文件文件不是个目录文件不为空文件存在 Shell echo命令Shell echo命令Shell 的 echo 指令与 PHP 的 echo 指令类似，都是用于字符串的输出。命令格式： 1echo string 您可以使用echo实现更复杂的输出格式控制。 1.显示普通字符串:1echo "It is a test" 这里的双引号完全可以省略，以下命令与上面实例效果一致： 1echo It is a test 2.显示转义字符1echo "\"It is a test\"" 结果将是: 1"It is a test" 同样，双引号也可以省略 3.显示变量read 命令从标准输入中读取一行,并把输入行的每个字段的值指定给 shell 变量 123#!/bin/shread name echo "$name It is a test" 以上代码保存为 test.sh，name 接收标准输入的变量，结果将是: 123[root@www ~]# sh test.shOK #标准输入OK It is a test #输出 4.显示换行12echo -e &quot;OK!\n&quot; # -e 开启转义echo &quot;It it a test&quot; 输出结果： 123OK!It it a test 5.显示不换行123#!/bin/shecho -e "OK! \c" # -e 开启转义 \c 不换行echo "It is a test" 输出结果： 1OK! It is a test 6.显示结果定向至文件1echo "It is a test" &gt; myfile 7.原样输出字符串，不进行转义或取变量(用单引号)1echo '$name\"' 输出结果： 1$name\" 8.显示命令执行结果1echo `date` 注意：这里使用的是反引号12345结果将显示当前日期```shell Sat Dec 9 14:41:48 CST 2017 Shell printf 命令Shell printf 命令上一章节我们学习了 Shell 的 echo 命令，本章节我们来学习 Shell 的另一个输出命令 printf。 printf 命令模仿 C 程序库（library）里的 printf() 程序。 标准所定义，因此使用printf的脚本比使用echo移植性好。 printf 使用引用文本或空格分隔的参数，外面可以在printf中使用格式化字符串，还可以制定字符串的宽度、左右对齐方式等。默认printf不会像 echo 自动添加换行符，我们可以手动添加 \n。 printf 命令的语法： 1printf format-string [arguments...] 参数说明： format-string: 为格式控制字符串 arguments: 为参数列表。 实例如下： 12345$ echo &quot;Hello, Shell&quot;Hello, Shell$ printf &quot;Hello, Shell\n&quot;Hello, Shell$ 接下来,我来用一个脚本来体现printf的强大功能： 12345678#!/bin/bash# author:W3Cschool教程# url:www.123 printf &quot;%-10s %-8s %-4s\n&quot; 姓名 性别 体重kg printf &quot;%-10s %-8s %-4.2f\n&quot; 郭靖 男 66.1234 printf &quot;%-10s %-8s %-4.2f\n&quot; 杨过 男 48.6543 printf &quot;%-10s %-8s %-4.2f\n&quot; 郭芙 女 47.9876 执行脚本，输出结果如下所示： &quot;%-10s %-8s %-4.2f\n&quot; 郭芙 女 47.9876 1234姓名 性别 体重kg郭靖 男 66.12杨过 男 48.65郭芙 女 47.99 %s %c %d %f都是格式替代符 %-10s 指一个宽度为10个字符（-表示左对齐，没有则表示右对齐），任何字符都会被显示在10个字符宽的字符内，如果不足则自动以空格填充，超过也会将内容全部显示出来。 %-4.2f 指格式化为小数，其中.2指保留2位小数。 更多实例： 12345678910111213141516171819202122#!/bin/bash# author:W3Cschool教程# url:www.123 # format-string为双引号printf "%d %s\n" 1 "abc"# 单引号与双引号效果一样 printf '%d %s\n' 1 "abc" # 没有引号也可以输出printf %s abcdef# 格式只指定了一个参数，但多出的参数仍然会按照该格式输出，format-string 被重用printf %s abc defprintf "%s\n" abc defprintf "%s %s %s\n" a b c d e f g h i j# 如果没有 arguments，那么 %s 用NULL代替，%d 用 0 代替printf "%s and %d \n" 执行脚本，输出结果如下所示： 1234567891 abc1 abcabcdefabcdefabcdefa b cd e fg h ij and 0 printf的转义序列 序列 说明 \a 警告字符，通常为ASCII的BEL字符 \b 后退 \c 抑制（不显示）输出结果中任何结尾的换行字符（只在%b格式指示符控制下的参数字符串中有效），而且，任何留在参数里的字符、任何接下来的参数以及任何留在格式字符串中的字符，都被忽略 \f 换页（formfeed） \n 换行 \r 回车（Carriage return） \t 水平制表符 \v 垂直制表符 \ 一个字面上的反斜杠字符 \ddd 表示1到3位数八进制值的字符。仅在格式字符串中有效 \0ddd 表示1到3位的八进制值字符 实例123456789$ printf "a string, no processing:&lt;%s&gt;\n" "A\nB"a string, no processing:&lt;A\nB&gt;$ printf "a string, no processing:&lt;%b&gt;\n" "A\nB"a string, no processing:&lt;AB&gt;$ printf "www.123 \a"www.123 $ #不换行 Shell test命令Shell中的 test 命令用于检查某个条件是否成立，它可以进行数值、字符和文件三个方面的测试。 数值测试 参数 说明 -eq 等于则为真 -ne 不等于则为真 -gt 大于则为真 -ge 大于等于则为真 -lt 小于则为真 -le 小于等于则为真 实例演示： 12345678num1=100num2=100if test $[num1] -eq $[num2]then echo '两个数相等！'else echo '两个数不相等！'fi 输出结果： 1两个数相等！ 字符串测试 参数 说明 = 等于则为真 != 不相等则为真 -z 字符串 字符串长度为零则为真 -n 字符串 字符串长度不为零则为真 实例演示： 12345678num1="W3Cschool"num2="W3Cschool"if test num1=num2then echo '两个字符串相等!'else echo '两个字符串不相等!'fi 输出结果： 1两个字符串相等! 文件测试 参数 说明 -e 文件名 如果文件存在则为真 -r 文件名 如果文件存在且可读则为真 -w 文件名 如果文件存在且可写则为真 -x 文件名 如果文件存在且可执行则为真 -s 文件名 如果文件存在且至少有一个字符则为真 -d 文件名 如果文件存在且为目录则为真 -f 文件名 如果文件存在且为普通文件则为真 -c 文件名 如果文件存在且为字符型特殊文件则为真 -b 文件名 如果文件存在且为块特殊文件则为真 实例演示： 1234567cd /binif test -e ./bashthen echo '文件已存在!'else echo '文件不存在!'fi 输出结果： 1文件已存在! 另外，Shell还提供了与( -a )、或( -o )、非( ! )三个逻辑操作符用于将测试条件连接起来，其优先级为：”!”最高，”-a”次之，”-o”最低。例如： 1234567cd /binif test -e ./notFile -o -e ./bashthen echo '有一个文件存在!'else echo '两个文件都不存在'fi 输出结果： 1有一个文件存在! Shell 流程控制Shell 流程控制和Java、PHP等语言不一样，sh的流程控制不可为空，如(以下为PHP流程控制写法)： 123456&lt;?php if (isset($_GET["q"])) &#123; search(q); &#125; else &#123; // 不做任何事情 &#125; 在sh/bash里可不能这么写，如果else分支没有语句执行，就不要写这个else，就像这样 if elseifif 语句语法格式： 1234567if conditionthen command1 command2 ... commandN fi 写成一行（适用于终端命令提示符）： 1if [ $(ps -ef | grep -c "ssh") -gt 1 ]; then echo "true"; fi 末尾的fi就是if倒过来拼写，后面还会遇到类似的。 if elseif else 语法格式： 123456789if conditionthen command1 command2 ... commandNelse commandfi if else-if elseif else-if else 语法格式： 12345678if condition1then command1elif condition2 command2else commandNfi if else语句经常与test命令结合使用，如下所示： 12345678num1=$[2*3]num2=$[1+5]if test $[num1] -eq $[num2]then echo '两个数字相等!'else echo '两个数字不相等!'fi 输出结果： 1两个数字相等! for 循环与其他编程语言类似，Shell支持for循环。 for循环一般格式为： 1234567for var in item1 item2 ... itemNdo command1 command2 ... commandNdone 写成一行： 1for var in item1 item2 ... itemN; do command1; command2… done; 当变量值在列表里，for循环即执行一次所有命令，使用变量名获取列表中的当前取值。命令可为任何有效的shell命令和语句。in列表可以包含替换、字符串和文件名。 in列表是可选的，如果不用它，for循环使用命令行的位置参数。 例如，顺序输出当前列表中的数字： 1234for loop in 1 2 3 4 5do echo "The value is: $loop"done 输出结果： 12345The value is: 1The value is: 2The value is: 3The value is: 4The value is: 5 顺序输出字符串中的字符： 1234for str in 'This is a string'do echo $strdone 输出结果： 1This is a string while 语句while循环用于不断执行一系列命令，也用于从输入文件中读取数据；命令通常为测试条件。其格式为： 1234while conditiondo commanddone 以下是一个基本的while循环，测试条件是：如果int小于等于5，那么条件返回真。int从0开始，每次循环处理时，int加1。运行上述脚本，返回数字1到5，然后终止。 123#!/bin/shint=1while(( $int&lt;=5 )) do echo $int let &quot;int++&quot; done 运行脚本，输出： 1234512345 while循环可用于读取键盘信息。下面的例子中，输入信息被设置为变量FILM，按结束循环。 123456echo '按下 &lt;CTRL-D&gt; 退出'echo -n '输入你最喜欢的电影名: 'while read FILMdo echo "是的！$FILM 是一部好电影"done 运行脚本，输出类似下面： 123按下 &lt;CTRL-D&gt; 退出输入你最喜欢的电影名: W3Cschool在线教程是的！W3Cschool在线教程 是一部好电影 无限循环无限循环语法格式： 1234while :do commanddone 或者 1234while truedo commanddone 或者 1for (( ; ; )) until 循环until循环执行一系列命令直至条件为真时停止。 until循环与while循环在处理方式上刚好相反。 一般while循环优于until循环，但在某些时候—也只是极少数情况下，until循环更加有用。 until 语法格式: 1234until conditiondo commanddone 条件可为任意测试条件，测试发生在循环末尾，因此循环至少执行一次—请注意这一点。 caseShell case语句为多选择语句。可以用case语句匹配一个值与一个模式，如果匹配成功，执行相匹配的命令。case语句格式如下： 1234567891011121314case 值 in模式1) command1 command2 ... commandN ;;模式2） command1 command2 ... commandN ;;esac case工作方式如上所示。取值后面必须为单词in，每一模式必须以右括号结束。取值可以为变量或常数。匹配发现取值符合某一模式后，其间所有命令开始执行直至 ;;。 取值将检测匹配的每一个模式。一旦模式匹配，则执行完匹配模式相应命令后不再继续其他模式。如果无一匹配模式，使用星号 * 捕获该值，再执行后面的命令。 下面的脚本提示输入1到4，与每一种模式进行匹配： 123456789101112131415echo '输入 1 到 4 之间的数字:'echo '你输入的数字为:'read aNumcase $aNum in 1) echo '你选择了 1' ;; 2) echo '你选择了 2' ;; 3) echo '你选择了 3' ;; 4) echo '你选择了 4' ;; *) echo '你没有输入 1 到 4 之间的数字' ;;esac 输入不同的内容，会有不同的结果，例如： 1234输入 1 到 4 之间的数字:你输入的数字为:3你选择了 3 跳出循环在循环过程中，有时候需要在未达到循环结束条件时强制跳出循环，Shell使用两个命令来实现该功能：break和continue。 break命令break命令允许跳出所有循环（终止执行后面的所有循环）。 下面的例子中，脚本进入死循环直至用户输入数字大于5。要跳出这个循环，返回到shell提示符下，需要使用break命令。 12345678910111213#!/bin/bashwhile :do echo -n "输入 1 到 5 之间的数字:" read aNum case $aNum in 1|2|3|4|5) echo "你输入的数字为 $aNum!" ;; *) echo "你输入的数字不是 1 到 5 之间的! 游戏结束" break ;; esacdone 执行以上代码，输出结果为： 1234输入 1 到 5 之间的数字:3你输入的数字为 3!输入 1 到 5 之间的数字:7你输入的数字不是 1 到 5 之间的! 游戏结束 continuecontinue命令与break命令类似，只有一点差别，它不会跳出所有循环，仅仅跳出当前循环。 对上面的例子进行修改： 1234567891011121314#!/bin/bashwhile :do echo -n "输入 1 到 5 之间的数字: " read aNum case $aNum in 1|2|3|4|5) echo "你输入的数字为 $aNum!" ;; *) echo "你输入的数字不是 1 到 5 之间的!" continue echo "游戏结束" ;; esacdone 运行代码发现，当输入大于5的数字时，该例中的循环不会结束，语句 echo “Game is over!” 永远不会被执行。 esaccase的语法和C family语言差别很大，它需要一个esac（就是case反过来）作为结束标记，每个case分支用右圆括号，用两个分号表示break。 Shell 流程控制Shell 流程控制和Java、PHP等语言不一样，sh的流程控制不可为空，如(以下为PHP流程控制写法)： 123456&lt;?php if (isset($_GET["q"])) &#123; search(q); &#125; else &#123; // 不做任何事情 &#125; 在sh/bash里可不能这么写，如果else分支没有语句执行，就不要写这个else，就像这样 if elseifif 语句语法格式： 1234567if conditionthen command1 command2 ... commandN fi 写成一行（适用于终端命令提示符）： 1if [ $(ps -ef | grep -c "ssh") -gt 1 ]; then echo "true"; fi 末尾的fi就是if倒过来拼写，后面还会遇到类似的。 if elseif else 语法格式： 123456789if conditionthen command1 command2 ... commandNelse commandfi if else-if elseif else-if else 语法格式： 12345678if condition1then command1elif condition2 command2else commandNfi if else语句经常与test命令结合使用，如下所示： 12345678num1=$[2*3]num2=$[1+5]if test $[num1] -eq $[num2]then echo '两个数字相等!'else echo '两个数字不相等!'fi 输出结果： 1两个数字相等! for 循环与其他编程语言类似，Shell支持for循环。 for循环一般格式为： 1234567for var in item1 item2 ... itemNdo command1 command2 ... commandNdone 写成一行： 1for var in item1 item2 ... itemN; do command1; command2… done; 当变量值在列表里，for循环即执行一次所有命令，使用变量名获取列表中的当前取值。命令可为任何有效的shell命令和语句。in列表可以包含替换、字符串和文件名。 in列表是可选的，如果不用它，for循环使用命令行的位置参数。 例如，顺序输出当前列表中的数字： 1234for loop in 1 2 3 4 5do echo "The value is: $loop"done 输出结果： 12345The value is: 1The value is: 2The value is: 3The value is: 4The value is: 5 顺序输出字符串中的字符： 1234for str in 'This is a string'do echo $strdone 输出结果： 1This is a string while 语句while循环用于不断执行一系列命令，也用于从输入文件中读取数据；命令通常为测试条件。其格式为： 1234while conditiondo commanddone 以下是一个基本的while循环，测试条件是：如果int小于等于5，那么条件返回真。int从0开始，每次循环处理时，int加1。运行上述脚本，返回数字1到5，然后终止。 123#!/bin/shint=1while(( $int&lt;=5 )) do echo $int let "int++" done 运行脚本，输出： 1234512345 while循环可用于读取键盘信息。下面的例子中，输入信息被设置为变量FILM，按结束循环。 123456echo '按下 &lt;CTRL-D&gt; 退出'echo -n '输入你最喜欢的电影名: 'while read FILMdo echo "是的！$FILM 是一部好电影"done 运行脚本，输出类似下面： 123按下 &lt;CTRL-D&gt; 退出输入你最喜欢的电影名: W3Cschool在线教程是的！W3Cschool在线教程 是一部好电影 无限循环无限循环语法格式： 1234while :do commanddone 或者 1234while truedo commanddone 或者 1for (( ; ; )) until 循环until循环执行一系列命令直至条件为真时停止。 until循环与while循环在处理方式上刚好相反。 一般while循环优于until循环，但在某些时候—也只是极少数情况下，until循环更加有用。 until 语法格式: 1234until conditiondo commanddone 条件可为任意测试条件，测试发生在循环末尾，因此循环至少执行一次—请注意这一点。 caseShell case语句为多选择语句。可以用case语句匹配一个值与一个模式，如果匹配成功，执行相匹配的命令。case语句格式如下： 1234567891011121314case 值 in模式1) command1 command2 ... commandN ;;模式2） command1 command2 ... commandN ;;esac case工作方式如上所示。取值后面必须为单词in，每一模式必须以右括号结束。取值可以为变量或常数。匹配发现取值符合某一模式后，其间所有命令开始执行直至 ;;。 取值将检测匹配的每一个模式。一旦模式匹配，则执行完匹配模式相应命令后不再继续其他模式。如果无一匹配模式，使用星号 * 捕获该值，再执行后面的命令。 下面的脚本提示输入1到4，与每一种模式进行匹配： 123456789101112131415echo '输入 1 到 4 之间的数字:'echo '你输入的数字为:'read aNumcase $aNum in 1) echo '你选择了 1' ;; 2) echo '你选择了 2' ;; 3) echo '你选择了 3' ;; 4) echo '你选择了 4' ;; *) echo '你没有输入 1 到 4 之间的数字' ;;esac 输入不同的内容，会有不同的结果，例如： 1234输入 1 到 4 之间的数字:你输入的数字为:3你选择了 3 跳出循环在循环过程中，有时候需要在未达到循环结束条件时强制跳出循环，Shell使用两个命令来实现该功能：break和continue。 break命令break命令允许跳出所有循环（终止执行后面的所有循环）。 下面的例子中，脚本进入死循环直至用户输入数字大于5。要跳出这个循环，返回到shell提示符下，需要使用break命令。 12345678910111213#!/bin/bashwhile :do echo -n "输入 1 到 5 之间的数字:" read aNum case $aNum in 1|2|3|4|5) echo "你输入的数字为 $aNum!" ;; *) echo "你输入的数字不是 1 到 5 之间的! 游戏结束" break ;; esacdone 执行以上代码，输出结果为： 1234输入 1 到 5 之间的数字:3你输入的数字为 3!输入 1 到 5 之间的数字:7你输入的数字不是 1 到 5 之间的! 游戏结束 continuecontinue命令与break命令类似，只有一点差别，它不会跳出所有循环，仅仅跳出当前循环。 对上面的例子进行修改： 1234567891011121314#!/bin/bashwhile :do echo -n "输入 1 到 5 之间的数字: " read aNum case $aNum in 1|2|3|4|5) echo "你输入的数字为 $aNum!" ;; *) echo "你输入的数字不是 1 到 5 之间的!" continue echo "游戏结束" ;; esacdone 运行代码发现，当输入大于5的数字时，该例中的循环不会结束，语句 echo “Game is over!” 永远不会被执行。 esaccase的语法和C family语言差别很大，它需要一个esac（就是case反过来）作为结束标记，每个case分支用右圆括号，用两个分号表示break。 Shell 函数Shell 函数linux shell 可以用户定义函数，然后在shell脚本中可以随便调用。 shell中函数的定义格式如下： 123456789[ function ] funname [()]&#123; action; [return int;]&#125; 说明： 1、可以带function fun() 定义，也可以直接fun() 定义,不带任何参数。 2、参数返回，可以显示加：return 返回，如果不加，将以最后一条命令运行结果，作为返回值。 return后跟数值n(0-255 下面的例子定义了一个函数并进行调用： 1234567#!/bin/bashdemoFun()&#123; echo &quot;这是我的第一个 shell 函数!&quot;&#125;echo &quot;-----函数开始执行-----&quot;demoFunecho &quot;-----函数执行完毕-----&quot; 输出结果： 123-----函数开始执行-----这是我的第一个 shell 函数!-----函数执行完毕----- 下面定义一个带有return语句的函数： 123456789101112#!/bin/bashfunWithReturn()&#123; echo &quot;这个函数会对输入的两个数字进行相加运算...&quot; echo &quot;输入第一个数字: &quot; read aNum echo &quot;输入第二个数字: &quot; read anotherNum echo &quot;两个数字分别为 $aNum 和 $anotherNum !&quot; return $(($aNum+$anotherNum))&#125;funWithReturnecho &quot;输入的两个数字之和为 $? !&quot; 输出类似下面： 1234567这个函数会对输入的两个数字进行相加运算...输入第一个数字: 1输入第二个数字: 2两个数字分别为 1 和 2 !输入的两个数字之和为 3 ! 函数返回值在调用该函数后通过 $? 来获得。 注意：所有函数在使用前必须定义。这意味着必须将函数放在脚本开始部分，直至shell解释器首次发现它时，才可以使用。调用函数仅使用其函数名即可。 函数参数在Shell中，调用函数时可以向其传递参数。在函数体内部，通过 $n 的形式来获取参数的值，例如，$1表示第一个参数，$2表示第二个参数… 带参数的函数示例： 1234567891011#!/bin/bashfunWithParam()&#123; echo &quot;第一个参数为 $1 !&quot; echo &quot;第二个参数为 $2 !&quot; echo &quot;第十个参数为 $10 !&quot; echo &quot;第十个参数为 $&#123;10&#125; !&quot; echo &quot;第十一个参数为 $&#123;11&#125; !&quot; echo &quot;参数总数有 $# 个!&quot; echo &quot;作为一个字符串输出所有参数 $* !&quot;&#125;funWithParam 1 2 3 4 5 6 7 8 9 34 73 输出结果： 1234567第一个参数为 1 !第二个参数为 2 !第十个参数为 10 !第十个参数为 34 !第十一个参数为 73 !参数总数有 11 个!作为一个字符串输出所有参数 1 2 3 4 5 6 7 8 9 34 73 ! 注意，$10 不能获取第十个参数，获取第十个参数需要${10}。当n&gt;=10时，需要使用${n}来获取参数。 另外，还有几个特殊字符用来处理参数： 参数处理 说明 $# 传递到脚本的参数个数 $* 以一个单字符串显示所有向脚本传递的参数 $$ 脚本运行的当前进程ID号 $! 后台运行的最后一个进程的ID号 $@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。 $- 显示Shell使用的当前选项，与set命令功能相同。 $? Shell 输入/输出重定向Shell 输入/输出重定向大多数 UNIX 系统命令从你的终端接受输入并将所产生的输出发送回到您的终端。一个命令通常从一个叫标准输入的地方读取输入，默认情况下，这恰好是你的终端。同样，一个命令通常将其输出写入到标准输出，默认情况下，这也是你的终端。 重定向命令列表如下： 命令 说明 command &gt; file 将输出重定向到 file。 command &lt; file 将输入重定向到 file。 command &gt;&gt; file 将输出以追加的方式重定向到 file。 n &gt; file 将文件描述符为 n 的文件重定向到 file。 n &gt;&gt; file 将文件描述符为 n 的文件以追加的方式重定向到 file。 n &gt;&amp; m 将输出文件 m 和 n 合并。 n &lt;&amp; m 将输入文件 m 和 n 合并。 &lt;&lt; tag 将开始标记 tag 和结束标记 tag 之间的内容作为输入。 需要注意的是文件描述符 0 通常是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR）。 输出重定向重定向一般通过在命令间插入特定的符号来实现。特别的，这些符号的语法如下所示: 1command1 &gt; file1 上面这个命令执行command1然后将输出的内容存入file1。 注意任何file1内的已经存在的内容将被新内容替代。如果要将新内容添加在文件末尾，请使用&gt;&gt;操作符。 实例执行下面的 who 命令，它将命令的完整的输出重定向在用户文件中(users): 1$ who &gt; users 执行后，并没有在终端输出信息，这是因为输出已被从默认的标准输出设备（终端）重定向到指定的文件。 你可以使用 cat 命令查看文件内容： 1234$ cat users_mbsetupuser console Oct 31 17:35 laolan console Oct 31 17:35 laolan ttys000 Dec 1 11:33 输出重定向会覆盖文件内容，请看下面的例子： 1234$ echo &quot;W3Cschool教程：www.123&quot; &gt; users$ cat usersW3Cschool教程：www.123$ 如果不希望文件内容被覆盖，可以使用 &gt;&gt; 追加到文件末尾，例如： 12345$ echo &quot;W3Cschool教程：www.123&quot; &gt;&gt; users$ cat usersW3Cschool教程：www.123W3Cschool教程：www.123$ 输入重定向和输出重定向一样，Unix 命令也可以从文件获取输入，语法为： 1command1 &lt; file1 这样，本来需要从键盘获取输入的命令会转移到文件读取内容。 注意：输出重定向是大于号(&gt;)，输入重定向是小于号(&lt;)。 实例接着以上实例，我们需要统计 users 文件的行数,执行以下命令： 12$ wc -l users 2 users 也可以将输入重定向到 users 文件： 12$ wc -l &lt; users 2 注意：上面两个例子的结果不同：第一个例子，会输出文件名；第二个不会，因为它仅仅知道从标准输入读取内容。 1command1 &lt; infile &gt; outfile 同时替换输入和输出，执行command1，从文件infile读取内容，然后将输出写入到outfile中。 重定向深入讲解一般情况下，每个 Unix/Linux 命令运行时都会打开三个文件： 标准输入文件(stdin)：stdin的文件描述符为0，Unix程序默认从stdin读取数据。 标准输出文件(stdout)：stdout 的文件描述符为1，Unix程序默认向stdout输出数据。 标准错误文件(stderr)：stderr的文件描述符为2，Unix程序会向stderr流中写入错误信息。 默认情况下，command &gt; file 将 stdout 重定向到 file，command &lt; file 将stdin 重定向到 file。 如果希望 stderr 重定向到 file，可以这样写： 1$ command 2 &gt; file 如果希望 stderr 追加到 file 文件末尾，可以这样写： 1$ command 2 &gt;&gt; file 2 表示标准错误文件(stderr)。 如果希望将 stdout 和 stderr 合并后重定向到 file，可以这样写： 12345$ command &gt; file 2&gt;&amp;1或者$ command &gt;&gt; file 2&gt;&amp;1 如果希望对 stdin 和 stdout 都重定向，可以这样写： 1$ command &lt; file1 &gt;file2 command 命令将 stdin 重定向到 file1，将 stdout 重定向到 file2。 Here DocumentHere Document 是 Shell 中的一种特殊的重定向方式，用来将输入重定向到一个交互式 Shell 脚本或程序。 它的基本的形式如下： 123command &lt;&lt; delimiter documentdelimiter 它的作用是将两个 delimiter 之间的内容(document) 作为输入传递给 command。 注意： 结尾的delimiter 一定要顶格写，前面不能有任何字符，后面也不能有任何字符，包括空格和 tab 缩进。 开始的delimiter前后的空格会被忽略掉。 实例在命令行中通过 wc -l 命令计算 Here Document 的行数： 1234567$ wc -l &lt;&lt; EOF 欢迎来到 W3Cschool教程 www.123EOF3 # 输出结果为 3 行$ 我们也可以将 Here Document 用在脚本中，例如： 123456789#!/bin/bash# author:W3Cschool教程# url:www.123cat &lt;&lt; EOF欢迎来到W3Cschool教程www.123EOF 执行以上脚本，输出结果： 123欢迎来到W3Cschool教程www.123 /dev/null 文件如果希望执行某个命令，但又不希望在屏幕上显示输出结果，那么可以将输出重定向到 /dev/null： 1$ command &gt; /dev/null /dev/null 是一个特殊的文件，写入到它的内容都会被丢弃；如果尝试从该文件读取内容，那么什么也读不到。但是 /dev/null 文件非常有用，将命令的输出重定向到它，会起到”禁止输出”的效果。 如果希望屏蔽 stdout 和 stderr，可以这样写： 1$ command &gt; /dev/null 2&gt;&amp;1 注意：0 是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR）。 Shell 文件包含Shell 文件包含和其他语言一样，Shell 也可以包含外部脚本。这样可以很方便的封装一些公用的代码作为一个独立的文件。 Shell 文件包含的语法格式如下： 12345. filename # 注意点号(.)和文件名中间有一空格或source filename 实例创建两个 shell 脚本文件。 test1.sh 代码如下： 12345#!/bin/bash# author:W3Cschool教程# url:www.123url=&quot;http://www.123&quot; test2.sh 代码如下： 1234567891011#!/bin/bash# author:W3Cschool教程# url:www.123#使用 . 号来引用test1.sh 文件. ./test1.sh# 或者使用以下包含文件代码# source ./test1.shecho &quot;W3Cschool教程官网地址：$url&quot; 接下来，我们为 test2.sh 添加可执行权限并执行： 123$ chmod +x test2.sh $ ./test2.sh W3Cschool教程官网地址：http://www.123]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux教程]]></title>
    <url>%2Fp%2Ffaca.html</url>
    <content type="text"><![CDATA[Linux 安装本章节我们将为大家介绍Linux的安装。 本章节以 centos6.4 为例。 centos6.4 下载地址： 网易镜像：http://mirrors.163.com/centos/6/isos/ 搜狐镜像：http://mirrors.sohu.com/centos/6/isos/ 注：建议安装64位Linux系统。 接下来你需要将下载的Linux系统刻录成光盘或U盘。 注：你也可以在Window上安装VMware虚拟机来安装Linux系统。 Linux 安装步骤1、首先，使用光驱或U盘或你下载的Linux ISO文件进行安装。 界面说明： Install or upgrade an existing system 安装或升级现有的系统 install system with basic video driver 安装过程中采用基本的显卡驱动 Rescue installed system 进入系统修复模式 Boot from local drive 退出安装从硬盘启动 Memory test 内存检测 注：用联想E49安装时选择第一项安装时会出现屏幕显示异常的问题，后改用第二项安装时就没有出现问题 2、介质直接”skip”就可以了 3、出现引导界面，点击”next” 4、选中”English（English）”否则会有部分乱码问题 5、键盘布局选择”U.S.English” 6、选择”Basic Storage Devies”点击”Next” 7、询问是否忽略所有数据，新电脑安装系统选择”Yes,discard any data” 8、Hostname填写格式”英文名.姓” 9、网络设置安装图示顺序点击就可以了 10、时区可以在地图上点击，选择”shanghai”并取消System clock uses UTC前面的对勾 11、设置root的密码 12、硬盘分区，一定要按照图示点选 13、调整分区，必须要有/home这个分区，如果没有这个分区，安装部分软件会出现不能安装的问题 14、询问是否格式化分区 15、将更改写入到硬盘 16、引导程序安装位置 17、最重要的一步，也是本教程最关键的一步，也是其他教程没有提及的一步，按图示顺序点击 18、取消以下内容的所有选项 Applications Base System Servers 并对Desktops进行如下设置 即取消如下选项： Desktop Debugging and Performance Tools Desktop Platform Remote Desktop Clients Input Methods中仅保留ibus-pinyin-1.3.8-1.el6.x86_64,其他的全部取消 19、选中Languages，并选中右侧的Chinese Support然后点击红色区域 20、调整完成后如下图所示 21、至此，一个最精简的桌面环境就设置完成了， 22、安装完成，重启 23、重启之后，的License Information 24、Create User Username：填写您的英文名（不带.姓） Full Name：填写您的英文名.姓（首字母大写） 25、”Date and Time” 选中 “Synchronize data and time over the network” Finsh之后系统将重启 26、第一次登录，登录前不要做任何更改，这个很重要！！！登录之后紧接着退出 第二次登录，选择语言，在红色区域选择下拉小三角，选other，选中”汉语（中国）” 27、登录之后，请一定按照如下顺序点击！ 至此，CentOS安装完成，如有其他问题，请随时与我联系！！ Linux 系统启动过程Linux 系统启动过程linux启动时我们会看到许多启动信息。 Linux系统的启动过程并不是大家想象中的那么复杂，其过程可以分为5个阶段： 内核的引导。 运行init。 系统初始化。 建立终端 。 用户登录系统。 内核引导当计算机打开电源后，首先是BIOS开机自检，按照BIOS中设置的启动设备（通常是硬盘）来启动。 操作系统接管硬件以后，首先读入 /boot 目录下的内核文件。 运行initinit 进程是系统所有进程的起点，你可以把它比拟成系统所有进程的老祖宗，没有这个进程，系统中任何进程都不会启动。 init 程序首先是需要读取配置文件 /etc/inittab。 运行级别许多程序需要开机启动。它们在Windows叫做”服务”（service），在Linux就叫做”守护进程”（daemon）。 init进程的一大任务，就是去运行这些开机启动的程序。 但是，不同的场合需要启动不同的程序，比如用作服务器时，需要启动Apache，用作桌面就不需要。 Linux允许为不同的场合，分配不同的开机启动程序，这就叫做”运行级别”（runlevel）。也就是说，启动时根据”运行级别”，确定要运行哪些程序。 Linux系统有7个运行级别(runlevel)： 运行级别0：系统停机状态，系统默认运行级别不能设为0，否则不能正常启动 运行级别1：单用户工作状态，root权限，用于系统维护，禁止远程登陆 运行级别2：多用户状态(没有NFS) 运行级别3：完全的多用户状态(有NFS)，登陆后进入控制台命令行模式 运行级别4：系统未使用，保留 运行级别5：X11控制台，登陆后进入图形GUI模式 运行级别6：系统正常关闭并重启，默认运行级别不能设为6，否则不能正常启动 系统初始化在init的配置文件中有这么一行： si::sysinit:/etc/rc.d/rc.sysinit 它调用执行了/etc/rc.d/rc.sysinit，而rc.sysinit是一个bash shell的脚本，它主要是完成一些系统初始化的工作，rc.sysinit是每一个运行级别都要首先运行的重要脚本。 它主要完成的工作有：激活交换分区，检查磁盘，加载硬件模块以及其它一些需要优先执行任务。 1l5:5:wait:/etc/rc.d/rc 5 这一行表示以5为参数运行/etc/rc.d/rc，/etc/rc.d/rc是一个Shell脚本，它接受5作为参数，去执行/etc/rc.d/rc5.d/目录下的所有的rc启动脚本，/etc/rc.d/rc5.d/目录中的这些启动脚本实际上都是一些连接文件，而不是真正的rc启动脚本，真正的rc启动脚本实际上都是放在/etc/rc.d/init.d/目录下。 而这些rc启动脚本有着类似的用法，它们一般能接受start、stop、restart、status等参数。 /etc/rc.d/rc5.d/中的rc启动脚本通常是K或S开头的连接文件，对于以以S开头的启动脚本，将以start参数来运行。 而如果发现存在相应的脚本也存在K打头的连接，而且已经处于运行态了(以/var/lock/subsys/下的文件作为标志)，则将首先以stop为参数停止这些已经启动了的守护进程，然后再重新运行。 这样做是为了保证是当init改变运行级别时，所有相关的守护进程都将重启。 至于在每个运行级中将运行哪些守护进程，用户可以通过chkconfig或setup中的”System Services”来自行设定。 建立终端rc执行完毕后，返回init。这时基本系统环境已经设置好了，各种守护进程也已经启动了。 init接下来会打开6个终端，以便用户登录系统。在inittab中的以下6行就是定义了6个终端： 1234561:2345:respawn:/sbin/mingetty tty12:2345:respawn:/sbin/mingetty tty23:2345:respawn:/sbin/mingetty tty34:2345:respawn:/sbin/mingetty tty45:2345:respawn:/sbin/mingetty tty56:2345:respawn:/sbin/mingetty tty6 从上面可以看出在2、3、4、5的运行级别中都将以respawn方式运行mingetty程序，mingetty程序能打开终端、设置模式。 同时它会显示一个文本登录界面，这个界面就是我们经常看到的登录界面，在这个登录界面中会提示用户输入用户名，而用户输入的用户将作为参数传给login程序来验证用户的身份。 用户登录系统一般来说，用户的登录方式有三种： （1）命令行登录 （2）ssh登录 （3）图形界面登录 对于运行级别为5的图形方式用户来说，他们的登录是通过一个图形化的登录界面。登录成功后可以直接进入KDE、Gnome等窗口管理器。 而本文主要讲的还是文本方式登录的情况：当我们看到mingetty的登录界面时，我们就可以输入用户名和密码来登录系统了。 Linux的账号验证程序是login，login会接收mingetty传来的用户名作为用户名参数。 然后login会对用户名进行分析：如果用户名不是root，且存在/etc/nologin文件，login将输出nologin文件的内容，然后退出。 这通常用来系统维护时防止非root用户登录。只有/etc/securetty中登记了的终端才允许root用户登录，如果不存在这个文件，则root可以在任何终端上登录。 /etc/usertty文件用于对用户作出附加访问限制，如果不存在这个文件，则没有其他限制。 &lt;p在分析完用户名后，login将搜索/etc/passwd以及/etc/shadow来验证密码以及设置账户的其它信息，比如：主目录是什么、使用何种shell。如果没有指定主目录，将默认为根目录；如果没有指定shell，将默认为/bin/bash。 图形模式与文字模式的切换方式Linux预设提供了六个命令窗口终端机让我们来登录。 默认我们登录的就是第一个窗口，也就是tty1，这个六个窗口分别为tty1,tty2 … tty6，你可以按下Ctrl + Alt + F1 ~ F6 来切换它们。 如果你安装了图形界面，默认情况下是进入图形界面的，此时你就可以按Ctrl + Alt + F1 ~ F6来进入其中一个命令窗口界面。 当你进入命令窗口界面后再返回图形界面只要按下Ctrl + Alt + F7 就回来了。 如果你用的vmware 虚拟机，命令窗口切换的快捷键为 Alt + Space + F1~F6. 如果你在图形界面下请按Alt + Shift + Ctrl + F1~F6 切换至命令窗口。 Linux 关机在linux领域内大多用在服务器上，很少遇到关机的操作。毕竟服务器上跑一个服务是永无止境的，除非特殊情况下，不得已才会关机。 正确的关机流程为：sync &gt; shutdown &gt; reboot &gt; halt 关机指令为：shutdown ，你可以man shutdown 来看一下帮助文档。 例如你可以运行如下命令关机： 12345678910111213141516171819sync 将数据由内存同步到硬盘中。shutdown 关机指令，你可以man shutdown 来看一下帮助文档。例如你可以运行如下命令关机：shutdown –h 10 ‘This server will shutdown after 10 mins’ 这个命令告诉大家，计算机将在10分钟后关机，并且会显示在登陆用户的当前屏幕中。Shutdown –h now 立马关机Shutdown –h 20:25 系统会在今天20:25关机Shutdown –h +10 十分钟后关机Shutdown –r now 系统立马重启Shutdown –r +10 系统十分钟后重启reboot 就是重启，等同于 shutdown –r nowhalt 关闭系统，等同于shutdown –h now 和 poweroff 最后总结一下，不管是重启系统还是关闭系统，首先要运行sync命令，把内存中的数据写到磁盘中。 关机的命令有 shutdown –h now halt poweroff 和 init 0 , 重启系统的命令有 shutdown –r now ， reboot 和 init Linux 系统目录结构Linux 系统目录结构登录系统后，在当前命令窗口下输入命令： 1ls / 你会看到如下图所示: 树状目录结构： 以下是对这些目录的解释： /bin：bin是Binary的缩写, 这个目录存放着最经常使用的命令。 /boot：这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件。 /dev ：dev是Device(设备)的缩写, 该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的。 /etc：这个目录用来存放所有的系统管理所需要的配置文件和子目录。 /home：用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。 /lib：这个目录里存放着系统最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。 /lost+found：这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。 /media linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。 /mnt：系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。 /opt： 这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。 /proc：这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件，比如可以通过下面的命令来屏蔽主机的ping命令，使别人无法ping你的机器： 1echo 1 &gt; /proc/sys/net/ipv4/icmp_echo_ignore_all /root：该目录为系统管理员，也称作超级权限者的用户主目录。 /sbin：s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。 /selinux： 这个目录是Redhat/CentOS所特有的目录，Selinux是一个安全机制，类似于windows的防火墙，但是这套机制比较复杂，这个目录就是存放selinux相关的文件的。 /srv： 该目录存放一些服务启动之后需要提取的数据。 /sys： 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。 sysfs文件系统集成了下面3种文件系统的信息：针对进程信息的proc文件系统、针对设备的devfs文件系统以及针对伪终端的devpts文件系统。 该文件系统是内核设备树的一个直观反映。 当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中被创建。 /tmp：这个目录是用来存放一些临时文件的。 /usr： 这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似与windows下的program files目录。 /usr/bin：系统用户使用的应用程序。 /usr/sbin：超级用户使用的比较高级的管理程序和系统守护程序。 /usr/src：内核源代码默认的放置目录。 /var：这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。 在linux系统中，有几个目录是比较重要的，平时需要注意不要误删除或者随意更改内部文件。 /etc： 上边也提到了，这个是系统中的配置文件，如果你更改了该目录下的某个文件可能会导致系统不能启动。 /bin, /sbin, /usr/bin, /usr/sbin: 这是系统预设的执行文件的放置目录，比如 ls 就是在/bin/ls 目录下的。 值得提出的是，/bin, /usr/bin 是给系统用户使用的指令（除root外的通用户），而/sbin, /usr/sbin 则是给root使用的指令。 /var： 这是一个非常重要的目录，系统上跑了很多程序，那么每个程序都会有相应的日志产生，而这些日志就被记录到这个目录下，具体在/var/log 目录下，另外mail的预设放置也是在这里。 Linux 忘记密码解决方法Linux 忘记密码解决方法很多朋友经常会忘记Linux系统的root密码，linux系统忘记root密码的情况该怎么办呢？重新安装系统吗？当然不用！进入单用户模式更改一下root密码即可。 步骤如下： 重启linux系统 3 秒之内要按一下回车，出现如下界面 然后输入e 在 第二行最后边输入 single，有一个空格。具体方法为按向下尖头移动到第二行，按”e”进入编辑模式 在后边加上single 回车 最后按”b”启动，启动后就进入了单用户模式了 此时已经进入到单用户模式了，你可以更改root密码了。更密码的命令为 passwd 【使用系统安装光盘的救援模式】 救援模式即rescue ，这个模式主要是应用于，系统无法进入的情况。如，grub损坏或者某一个配置文件修改出错。如何使用rescue模式呢？ 光盘启动，按F5 进入rescue模式 输入linux rescue 回车 选择语言，笔者建议你选择英语 选择us 键盘 这里问你是否启动网络，有时候可能会联网调试。我们选no 这里告诉我们，接下来会把系统挂载在/mnt/sysimage 中。 其中有三个选项: Continue 就是挂载后继续下一步。 Read-Only 挂载成只读，这样更安全，有时文件系统损坏时，只读模式会防止文件系统近一步损坏。 Skip就是不挂载，进入一个命令窗口模式。 这里我们选择Continue。 至此，系统已经挂载到了/mnt/sysimage中。接下来回车，输入chroot /mnt/sysimage 进入管理员环境。 提示： 其实也可以到rescue模式下更改root的密码的。这个rescue模式和windows PE系统很相近。 当运行了chroot /mnt/sysimage/ 后，再ls 看到目录结构和原来系统中的目录结构是一样的。 没错！现在的环境和原来系统的环境是一模一样的。你可以输入exit 或者按Ctrl + D退出这个环境。然后你再ls 看一下 这个目录其实就是rescue模式下的目录结构，而我们的系统文件全部在 /mnt/sysimage目录下。 Linux 远程登录Linux一般作为服务器使用，而服务器一般放在机房，你不可能在机房操作你的Linux服务器。这时我们就需要远程登录到Linux服务器来管理维护系统。 CentOS系统默认安装了openssh 如果没有安装可以使用命令进行安装： yum install openssh-server -y Linux系统中是通过ssh服务实现的远程登录功能，默认ssh服务端口号为 22。 Window系统上 Linux 远程登录客户端有SecureCRT, Putty, SSH Secure Shell，Xshell等，本文以Putty为例来登录远程服务器。 putty下载地址：http://www.putty.org/ 如果你下载了putty，请双击putty.exe 然后弹出如下的窗口。 在Host Name( or IP address) 下面的框中输入你要登录的远程服务器IP(可以通过ifconfig命令查看服务器ip)，然后回车。 此时，提示我们输入要登录的用户名。 输入root 然后回车，再输入密码，就能登录到远程的linux系统了。 使用密钥认证机制远程登录linuxSSH 为 Secure Shell 的缩写，由 IETF 的网络工作小组（Network Working Group）所制定。 SSH 为建立在应用层和传输层基础上的安全协议。 首先使用工具 PUTTYGEN.EXE 生成密钥对。打开工具PUTTYGEN.EXE后如下图所示： 该工具可以生成三种格式的key ：SSH-1(RSA) SSH-2(RSA) SSH-2(DSA) ，我们采用默认的格式即SSH-2(RSA)。Number of bits in a generated key 这个是指生成的key的大小，这个数值越大，生成的key就越复杂，安全性就越高。这里我们写2048. 然后单击Generate 开始生成密钥对： 注意的是，在这个过程中鼠标要来回的动，否则这个进度条是不会动的。 到这里，密钥对已经生成了。你可以给你的密钥输入一个密码，（在Key Passphrase那里）也可以留空。然后点 Save public key 保存公钥，点 Save private Key 保存私钥。笔者建议你放到一个比较安全的地方，一来防止别人偷窥，二来防止误删除。接下来就该到远程linux主机上设置了。 1）创建目录 /root/.ssh 并设置权限 [root@localhost ~]# mkdir /root/.ssh mkdir 命令用来创建目录，以后会详细介绍，暂时只了解即可。 [root@localhost ~]# chmod 700 /root/.ssh chmod 命令是用来修改文件属性权限的，以后会详细介绍。 2）创建文件 / root/.ssh/authorized_keys [root@localhost ~]# vim /root/.ssh/authorized_keys vim 命令是编辑一个文本文件的命令，同样在后续章节详细介绍。 3）打开刚才生成的public key 文件，建议使用写字板打开，这样看着舒服一些，复制从AAAA开头至 “—- END SSH2 PUBLIC KEY —-“ 该行上的所有内容，粘贴到/root/.ssh/authorized_keys 文件中，要保证所有字符在一行。（可以先把复制的内容拷贝至记事本，然后编辑成一行载粘贴到该文件中）。 在这里要简单介绍一下，如何粘贴，用vim打开那个文件后，该文件不存在，所以vim会自动创建。按一下字母”i”然后同时按shift + Insert 进行粘贴（或者单击鼠标右键即可），前提是已经复制到剪切板中了。粘贴好后，然后把光标移动到该行最前面输入ssh-rsa ，然后按空格。再按ESC，然后输入冒号wq 即 :wq 就保存了。格式如下图： 4）再设置putty选项，点窗口左侧的SSh –&gt; Auth ，单击窗口右侧的Browse… 选择刚刚生成的私钥， 再点Open ，此时输入root，就不用输入密码就能登录了。 如果在前面你设置了Key Passphrase ，那么此时就会提示你输入密码的。为了更加安全建议大家要设置一个Key Passphrase。 Linux 文件基本属性Linux 文件基本属性Linux系统是一种典型的多用户系统，不同的用户处于不同的地位，拥有不同的权限。为了保护系统的安全性，Linux系统对不同的用户访问同一文件（包括目录文件）的权限做了不同的规定。 在Linux中我们可以使用 ll 或者 ls –l 命令来显示一个文件的属性以及文件所属的用户和组，如： 12345[root@www /]# ls -ltotal 64dr-xr-xr-x 2 root root 4096 Dec 14 2012 bindr-xr-xr-x 4 root root 4096 Apr 19 2012 boot…… 实例中，bin文件的第一个属性用”d”表示。”d”在Linux中代表该文件是一个目录文件。 在Linux中第一个字符代表这个文件是目录、文件或链接文件等等。 当为[ d ]则是目录 当为[ - ]则是文件； 若是[ l ]则表示为链接文档(link file)； 若是[ b ]则表示为装置文件里面的可供储存的接口设备(可随机存取装置)； 若是[ c ]则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)。 接下来的字符中，以三个为一组，且均为『rwx』 的三个参数的组合。其中，[ r ]代表可读(read)、[ w ]代表可写(write)、[ x ]代表可执行(execute)。 要注意的是，这三个权限的位置不会改变，如果没有权限，就会出现减号[ - ]而已。 每个文件的属性由左边第一部分的10个字符来确定（如下图）。 从左至右用0-9这些数字来表示。 第0位确定文件类型，第1-3位确定属主（该文件的所有者）拥有该文件的权限。 第4-6位确定属组（所有者的同组用户）拥有该文件的权限，第7-9位确定其他用户拥有该文件的权限。 其中，第1、4、7位表示读权限，如果用”r”字符表示，则有读权限，如果用”-“字符表示，则没有读权限； 第2、5、8位表示写权限，如果用”w”字符表示，则有写权限，如果用”-“字符表示没有写权限；第3、6、9位表示可执行权限，如果用”x”字符表示，则有执行权限，如果用”-“字符表示，则没有执行权限。 Linux文件属主和属组12345[root@www /]# ls -ltotal 64dr-xr-xr-x 2 root root 4096 Dec 14 2012 bindr-xr-xr-x 4 root root 4096 Apr 19 2012 boot…… 对于文件来说，它都有一个特定的所有者，也就是对该文件具有所有权的用户。 同时，在Linux系统中，用户是按组分类的，一个用户属于一个或多个组。 文件所有者以外的用户又可以分为文件所有者的同组用户和其他用户。 因此，Linux系统按文件所有者、文件所有者同组用户和其他用户来规定了不同的文件访问权限。 在以上实例中，bin文件是一个目录文件，属主和属组都为root，属主有可读、可写、可执行的权限；与属主同组的其他用户有可读和可执行的权限；其他用户也有可读和可执行的权限。 更改文件属性1、chgrp：更改文件属组语法： 1chgrp [-R] 属组名文件名 参数选项 -R：递归更改文件属组，就是在更改某个目录文件的属组时，如果加上-R的参数，那么该目录下的所有文件的属组都会更改。 2、chown：更改文件属主，也可以同时更改文件属组语法： 12chown [–R] 属主名 文件名chown [-R] 属主名：属组名 文件名 进入 /root 目录（~）将install.log的拥有者改为bin这个账号： 1234[root@www ~] cd ~[root@www ~]# chown bin install.log[root@www ~]# ls -l-rw-r--r-- 1 bin users 68495 Jun 25 08:53 install.log 将install.log的拥有者与群组改回为root： 123[root@www ~]# chown root:root install.log[root@www ~]# ls -l-rw-r--r-- 1 root root 68495 Jun 25 08:53 install.log 3、chmod：更改文件9个属性Linux文件属性有两种设置方法，一种是数字，一种是符号。 Linux文件的基本权限就有九个，分别是owner/group/others三种身份各有自己的read/write/execute权限。 先复习一下刚刚上面提到的数据：文件的权限字符为：『-rwxrwxrwx』， 这九个权限是三个三个一组的！其中，我们可以使用数字来代表各个权限，各权限的分数对照表如下： r:4 w:2 x:1 每种身份(owner/group/others)各自的三个权限(r/w/x)分数是需要累加的，例如当权限为： [-rwxrwx—] 分数则是： owner = rwx = 4+2+1 = 7 group = rwx = 4+2+1 = 7 others= — = 0+0+0 = 0 所以等一下我们设定权限的变更时，该文件的权限数字就是770啦！变更权限的指令chmod的语法是这样的： 1chmod [-R] xyz 文件或目录 选项与参数： xyz : 就是刚刚提到的数字类型的权限属性，为 rwx 属性数值的相加。 -R : 进行递归(recursive)的持续变更，亦即连同此目录下的所有文件都会变更 举例来说，如果要将.bashrc这个文件所有的权限都设定启用，那么命令如下： 12345[root@www ~]# ls -al .bashrc-rw-r--r-- 1 root root 395 Jul 4 11:45 .bashrc[root@www ~]# chmod 777 .bashrc[root@www ~]# ls -al .bashrc-rwxrwxrwx 1 root root 395 Jul 4 11:45 .bashrc 那如果要将权限变成 -rwxr-xr– 呢？那么权限的分数就成为 [4+2+1][4+0+1][4+0+0]=754。 符号类型改变文件权限还有一个改变权限的方法呦！从之前的介绍中我们可以发现，基本上就九个权限分别是(1)user (2)group (3)others三种身份啦！ 那么我们就可以藉由u, g, o来代表三种身份的权限！ 此外， a 则代表 all 亦即全部的身份！那么读写的权限就可以写成r, w, x！也就是可以使用底下的方式来看： chmod u g o a +(加入) -(除去) =(设定) r w x 文件或目录 如果我们需要将文件权限设置为 -rwxr-xr– ，可以使用 chmod u=rwx,g=rx,o=r 文件名 来设定: 12345[root@www ~]# ls -al .bashrc-rwxr-xr-x 1 root root 395 Jul 4 11:45 .bashrc[root@www ~]# chmod a+w .bashrc[root@www ~]# ls -al .bashrc-rwxrwxrwx 1 root root 395 Jul 4 11:45 .bashrc 而如果是要将权限去掉而不改变其他已存在的权限呢？例如要拿掉全部人的可执行权限，则： 123[root@www ~]# chmod a-x .bashrc[root@www ~]# ls -al .bashrc-rw-rw-rw- 1 root root 395 Jul 4 11:45 .bashrc Linux 文件与目录管理Linux 文件与目录管理我们知道Linux的目录结构为树状结构，最顶级的目录为根目录 /。 其他目录通过挂载可以将它们添加到树中，通过解除挂载可以移除它们。 在开始本教程前我们需要先知道什么是绝对路径与相对路径。 绝对路径：路径的写法，由根目录 / 写起，例如： /usr/share/doc 这个目录。 相对路径：路径的写法，不是由 / 写起，例如由 /usr/share/doc 要到 /usr/share/man 底下时，可以写成： cd ../man 这就是相对路径的写法啦！ 处理目录的常用命令接下来我们就来看几个常见的处理目录的命令吧： ls: 列出目录 cd：切换目录 pwd：显示目前的目录 mkdir：创建一个新的目录 rmdir：删除一个空的目录 cp: 复制文件或目录 rm: 移除文件或目录 mv: 移动文件与目录、文件重命名 你可以使用 man [命令] 来查看各个命令的使用文档，如 ：man cp。 ls (列出目录)在Linux系统当中， ls 命令可能是最常被运行的。 语法： 123[root@www ~]# ls [-aAdfFhilnrRSt] 目录名称[root@www ~]# ls [--color=&#123;never,auto,always&#125;] 目录名称[root@www ~]# ls [--full-time] 目录名称 选项与参数： -a ：全部的文件，连同隐藏档( 开头为 . 的文件) 一起列出来(常用) -d ：仅列出目录本身，而不是列出目录内的文件数据(常用) -l ：长数据串列出，包含文件的属性与权限等等数据；(常用) 将家目录下的所有文件列出来(含属性与隐藏档) 1[root@www ~]# ls -al ~ cd (切换目录)cd是Change Directory的缩写，这是用来变换工作目录的命令。 语法： 123456789101112131415 cd [相对路径或绝对路径]#使用 mkdir 命令创建w3cschool.cn目录[root@www ~]# mkdir w3cschool.cn#使用绝对路径切换到w3cschool.cn目录[root@www ~]# cd /root/w3cschool.cn/#使用相对路径切换到w3cschool.cn目录[root@www ~]# cd ./w3cschool.cn/# 表示回到自己的家目录，亦即是 /root 这个目录[root@www w3cschool.cn]# cd ~# 表示去到目前的上一级目录，亦即是 /root 的上一级目录的意思；[root@www ~]# cd .. 接下来大家多操作几次应该就可以很好的理解 cd 命令的。 pwd (显示目前所在的目录)pwd是Print Working Directory的缩写，也就是显示目前所在目录的命令。 123456789101112131415161718[root@www ~]# pwd [-P]选项与参数：-P ：显示出确实的路径，而非使用连结 (link) 路径。范例：单纯显示出目前的工作目录：[root@www ~]# pwd/root &lt;== 显示出目录啦～ 范例：显示出实际的工作目录，而非连结档本身的目录名而已 [root@www ~]# cd /var/mail &lt;==注意，/var/mail是一个连结档 [root@www mail]# pwd /var/mail &lt;==列出目前的工作目录 [root@www mail]# pwd -P /var/spool/mail &lt;==怎么回事？有没有加 -P 差很多～ [root@www mail]# ls -ld /var/mail lrwxrwxrwx 1 root root 10 Sep 4 17:54 /var/mail -&gt; spool/mail# 看到这里应该知道为啥了吧？因为 /var/mail 是连结档，连结到 /var/spool/mail # 所以，加上 pwd -P 的选项后，会不以连结档的数据显示，而是显示正确的完整路径啊！ mkdir (创建新目录)如果想要创建新的目录的话，那么就使用mkdir (make directory)吧。 语法： 1mkdir [-mp] 目录名称 选项与参数： -m ：配置文件的权限喔！直接配置，不需要看默认权限 (umask) 的脸色～ -p ：帮助你直接将所需要的目录(包含上一级目录)递回创建起来！ 范例：请到/tmp底下尝试创建数个新目录看看： 123456[root@www ~]# cd /tmp[root@www tmp]# mkdir test &lt;==创建一名为 test 的新目录 [root@www tmp]# mkdir test1/test2/test3/test4 mkdir: cannot create directory `test1/test2/test3/test4&apos;: No such file or directory &lt;== 没办法直接创建此目录啊！ [root@www tmp]# mkdir -p test1/test2/test3/test4 加了这个 -p 的选项，可以自行帮你创建多层目录！ 范例：创建权限为rwx–x–x的目录 12345[root@www tmp]# mkdir -m 711 test2[root@www tmp]# ls -ldrwxr-xr-x 3 root root 4096 Jul 18 12:50 testdrwxr-xr-x 3 root root 4096 Jul 18 12:53 test1drwx--x--x 2 root root 4096 Jul 18 12:54 test2 上面的权限部分，如果没有加上 -m 来强制配置属性，系统会使用默认属性。 如果我们使用 -m ，如上例我们给予 -m 711 来给予新的目录 drwx–x–x 的权限。 rmdir (删除空的目录)语法： 1rmdir [-p] 目录名称 选项与参数： -p ：连同上一级『空的』目录也一起删除 删除 w3cschool.cn 目录 1[root@www tmp]# rmdir w3cschool.cn/ 范例：将於mkdir范例中创建的目录(/tmp底下)删除掉！ 12345678910[root@www tmp]# ls -l &lt;==看看有多少目录存在？ drwxr-xr-x 3 root root 4096 Jul 18 12:50 test drwxr-xr-x 3 root root 4096 Jul 18 12:53 test1 drwx--x--x 2 root root 4096 Jul 18 12:54 test2 [root@www tmp]# rmdir test &lt;==可直接删除掉，没问题 [root@www tmp]# rmdir test1 &lt;==因为尚有内容，所以无法删除！ rmdir: `test1&apos;: Directory not empty [root@www tmp]# rmdir -p test1/test2/test3/test4 [root@www tmp]# ls -l &lt;==您看看，底下的输出中test与test1不见了！ drwx--x--x 2 root root 4096 Jul 18 12:54 test2 利用 -p 这个选项，立刻就可以将 test1/test2/test3/test4 一次删除。 不过要注意的是，这个 rmdir 仅能删除空的目录，你可以使用 rm 命令来删除非空目录。 cp (复制文件或目录)cp 即拷贝文件和目录。 语法: 12[root@www ~]# cp [-adfilprsu] 来源档(source) 目标档(destination)[root@www ~]# cp [options] source1 source2 source3 .... directory 选项与参数： -a ：相当於 -pdr 的意思，至於 pdr 请参考下列说明；(常用) -d ：若来源档为连结档的属性(link file)，则复制连结档属性而非文件本身； -f ：为强制(force)的意思，若目标文件已经存在且无法开启，则移除后再尝试一次； -i ：若目标档(destination)已经存在时，在覆盖时会先询问动作的进行(常用) -l ：进行硬式连结(hard link)的连结档创建，而非复制文件本身； -p ：连同文件的属性一起复制过去，而非使用默认属性(备份常用)； -r ：递回持续复制，用於目录的复制行为；(常用) -s ：复制成为符号连结档 (symbolic link)，亦即『捷径』文件； -u ：若 destination 比 source 旧才升级 destination ！ 用root身份，将家目录下的 .bashrc 复制到 /tmp 下，并更名为 bashr 123[root@www ~]# cp ~/.bashrc /tmp/bashrc[root@www ~]# cp -i ~/.bashrc /tmp/bashrccp: overwrite `/tmp/bashrc&apos;? n &lt;==n不覆盖，y为覆盖 rm (移除文件或目录)语法： 1rm [-fir] 文件或目录 选项与参数： -f ：就是 force 的意思，忽略不存在的文件，不会出现警告信息； -i ：互动模式，在删除前会询问使用者是否动作 -r ：递回删除啊！最常用在目录的删除了！这是非常危险的选项！！！ 将刚刚在 cp 的范例中创建的 bashrc 删除掉！ 12[root@www tmp]# rm -i bashrcrm: remove regular file `bashrc&apos;? y 如果加上 -i 的选项就会主动询问喔，避免你删除到错误的档名！ mv (移动文件与目录，或修改名称)语法： 12[root@www ~]# mv [-fiu] source destination[root@www ~]# mv [options] source1 source2 source3 .... directory 选项与参数： -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖； -i ：若目标文件 (destination) 已经存在时，就会询问是否覆盖！ -u ：若目标文件已经存在，且 source 比较新，才会升级 (update) 复制一文件，创建一目录，将文件移动到目录中 1234[root@www ~]# cd /tmp[root@www tmp]# cp ~/.bashrc bashrc[root@www tmp]# mkdir mvtest[root@www tmp]# mv bashrc mvtest 将某个文件移动到某个目录去，就是这样做！ 将刚刚的目录名称更名为 mvtest2 1[root@www tmp]# mv mvtest mvtest2 Linux 文件内容查看Linux系统中使用以下命令来查看文件的内容： cat 由第一行开始显示文件内容 tac 从最后一行开始显示，可以看出 tac 是 cat 的倒着写！ nl 显示的时候，顺道输出行号！ more 一页一页的显示文件内容 less 与 more 类似，但是比 more 更好的是，他可以往前翻页！ head 只看头几行 tail 只看尾巴几行 你可以使用 man [命令]来查看各个命令的使用文档，如 ：man cp。 cat由第一行开始显示文件内容 语法： 1cat [-AbEnTv] 选项与参数： -A ：相当於 -vET 的整合选项，可列出一些特殊字符而不是空白而已； -b ：列出行号，仅针对非空白行做行号显示，空白行不标行号！ -E ：将结尾的断行字节 $ 显示出来； -n ：列印出行号，连同空白行也会有行号，与 -b 的选项不同； -T ：将 [tab] 按键以 ^I 显示出来； -v ：列出一些看不出来的特殊字符 检看 /etc/issue 这个文件的内容： 123[root@www ~]# cat /etc/issueCentOS release 6.4 (Final)Kernel \r on an \m tactac与cat命令刚好相反，文件内容从最后一行开始显示，可以看出 tac 是 cat 的倒着写！如： 1234[root@www ~]# tac /etc/issueKernel \r on an \mCentOS release 6.4 (Final) nl显示行号 语法： 1nl [-bnw] 文件 选项与参数： -b ：指定行号指定的方式，主要有两种：-b a ：表示不论是否为空行，也同样列出行号(类似 cat -n)；-b t ：如果有空行，空的那一行不要列出行号(默认值)； -n ：列出行号表示的方法，主要有三种：-n ln ：行号在萤幕的最左方显示；-n rn ：行号在自己栏位的最右方显示，且不加 0 ；-n rz ：行号在自己栏位的最右方显示，且加 0 ； -w ：行号栏位的占用的位数。 范例一：用 nl 列出 /etc/issue 的内容 123[root@www ~]# nl /etc/issue 1 CentOS release 6.4 (Final) 2 Kernel \r on an \m more一页一页翻动 12345678[root@www ~]# more /etc/man.config## Generated automatically from man.conf.in by the# configure script.## man.conf from man-1.6d....(中间省略)....--More--(28%) &lt;== 重点在这一行喔！你的光标也会在这里等待你的命令 在 more 这个程序的运行过程中，你有几个按键可以按的： 空白键 (space)：代表向下翻一页； Enter ：代表向下翻『一行』； /字串 ：代表在这个显示的内容当中，向下搜寻『字串』这个关键字； :f ：立刻显示出档名以及目前显示的行数； q ：代表立刻离开 more ，不再显示该文件内容。 b 或 [ctrl]-b ：代表往回翻页，不过这动作只对文件有用，对管线无用。 less一页一页翻动，以下实例输出/etc/man.config文件的内容： 12345678[root@www ~]# less /etc/man.config## Generated automatically from man.conf.in by the# configure script.## man.conf from man-1.6d....(中间省略)....: &lt;== 这里可以等待你输入命令！ less运行时可以输入的命令有： 空白键 ：向下翻动一页； [pagedown]：向下翻动一页； [pageup] ：向上翻动一页； /字串 ：向下搜寻『字串』的功能； ?字串 ：向上搜寻『字串』的功能； n ：重复前一个搜寻 (与 / 或 ? 有关！) N ：反向的重复前一个搜寻 (与 / 或 ? 有关！) q ：离开 less 这个程序； head取出文件前面几行 语法： 1head [-n number] 文件 选项与参数： -n ：后面接数字，代表显示几行的意思 1[root@www ~]# head /etc/man.config 默认的情况中，显示前面 10 行！若要显示前 20 行，就得要这样： 1[root@www ~]# head -n 20 /etc/man.config tail取出文件后面几行 语法： 1tail [-n number] 文件 选项与参数： -n ：后面接数字，代表显示几行的意思 -f ：表示持续侦测后面所接的档名，要等到按下[ctrl]-c才会结束tail的侦测 123[root@www ~]# tail /etc/man.config# 默认的情况中，显示最后的十行！若要显示最后的 20 行，就得要这样：[root@www ~]# tail -n 20 /etc/man.config Linux 用户和用户组管理Linux 用户和用户组管理Linux系统是一个多用户多任务的分时操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。 用户的账号一方面可以帮助系统管理员对使用系统的用户进行跟踪，并控制他们对系统资源的访问；另一方面也可以帮助用户组织文件，并为用户提供安全性保护。 每个用户账号都拥有一个惟一的用户名和各自的口令。 用户在登录时键入正确的用户名和口令后，就能够进入系统和自己的主目录。 实现用户账号的管理，要完成的工作主要有如下几个方面： 用户账号的添加、删除与修改。 用户口令的管理。 用户组的管理。 一、Linux系统用户账号的管理用户账号的管理工作主要涉及到用户账号的添加、修改和删除。 添加用户账号就是在系统中创建一个新账号，然后为新账号分配用户号、用户组、主目录和登录Shell等资源。刚添加的账号是被锁定的，无法使用。 1、添加新的用户账号使用useradd命令，其语法如下：1useradd 选项 用户名 参数说明： 选项: -c comment 指定一段注释性描述。 -d 目录 指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录。 -g 用户组 指定用户所属的用户组。 -G 用户组，用户组 指定用户所属的附加组。 -s Shell文件 指定用户的登录Shell。 -u 用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号。 用户名: 指定新账号的登录名。 实例11# useradd –d /usr/sam -m sam 此命令创建了一个用户sam，其中-d和-m选项用来为登录名sam产生一个主目录/usr/sam（/usr为默认的用户主目录所在的父目录）。 实例21# useradd -s /bin/sh -g group –G adm,root gem 此命令新建了一个用户gem，该用户的登录Shell是 /bin/sh，它属于group用户组，同时又属于adm和root用户组，其中group用户组是其主组。 这里可能新建组：#groupadd group及groupadd adm 增加用户账号就是在/etc/passwd文件中为新用户增加一条记录，同时更新其他系统文件如/etc/shadow, /etc/group等。 Linux提供了集成的系统管理工具userconf，它可以用来对用户账号进行统一管理。 3、删除帐号如果一个用户的账号不再使用，可以从系统中删除。删除用户账号就是要将/etc/passwd等系统文件中的该用户记录删除，必要时还删除用户的主目录。 删除一个已有的用户账号使用userdel命令，其格式如下： 1userdel 选项 用户名 常用的选项是-r，它的作用是把用户的主目录一起删除。 例如： 1# userdel sam 此命令删除用户sam在系统文件中（主要是/etc/passwd, /etc/shadow, /etc/group等）的记录，同时删除用户的主目录。 4、修改帐号修改用户账号就是根据实际情况更改用户的有关属性，如用户号、主目录、用户组、登录Shell等。 修改已有用户的信息使用usermod命令，其格式如下： 1usermod 选项 用户名 常用的选项包括-c, -d, -m, -g, -G, -s, -u以及-o等，这些选项的意义与useradd命令中的选项一样，可以为用户指定新的资源值。 另外，有些系统可以使用选项：-l 新用户名 这个选项指定一个新的账号，即将原来的用户名改为新的用户名。 例如： 1# usermod -s /bin/ksh -d /home/z –g developer sam 此命令将用户sam的登录Shell修改为ksh，主目录改为/home/z，用户组改为developer。 5、用户口令的管理用户管理的一项重要内容是用户口令的管理。用户账号刚创建时没有口令，但是被系统锁定，无法使用，必须为其指定口令后才可以使用，即使是指定空口令。 指定和修改用户口令的Shell命令是passwd。超级用户可以为自己和其他用户指定口令，普通用户只能用它修改自己的口令。命令的格式为： 1passwd 选项 用户名 可使用的选项： -l 锁定口令，即禁用账号。 -u 口令解锁。 -d 使账号无口令。 -f 强迫用户下次登录时修改口令。 如果默认用户名，则修改当前用户的口令。 例如，假设当前用户是sam，则下面的命令修改该用户自己的口令： 1234$ passwd Old password:****** New password:******* Re-enter new password:******* 如果是超级用户，可以用下列形式指定任何用户的口令： 123# passwd sam New password:******* Re-enter new password:******* 普通用户修改自己的口令时，passwd命令会先询问原口令，验证后再要求用户输入两遍新口令，如果两次输入的口令一致，则将这个口令指定给用户；而超级用户为用户指定口令时，就不需要知道原口令。 为了系统安全起见，用户应该选择比较复杂的口令，例如最好使用8位长的口令，口令中包含有大写、小写字母和数字，并且应该与姓名、生日等不相同。 为用户指定空口令时，执行下列形式的命令： 1# passwd -d sam 此命令将用户sam的口令删除，这样用户sam下一次登录时，系统就不再询问口令。 passwd命令还可以用-l(lock)选项锁定某一用户，使其不能登录，例如： 1# passwd -l sam 二、Linux系统用户组的管理每个用户都有一个用户组，系统可以对一个用户组中的所有用户进行集中管理。不同Linux 系统对用户组的规定有所不同，如Linux下的用户属于与它同名的用户组，这个用户组在创建用户时同时创建。 用户组的管理涉及用户组的添加、删除和修改。组的增加、删除和修改实际上就是对/etc/group文件的更新。 1、增加一个新的用户组使用groupadd命令。其格式如下：1groupadd 选项 用户组 可以使用的选项有： -g GID 指定新用户组的组标识号（GID）。 -o 一般与-g选项同时使用，表示新用户组的GID可以与系统已有用户组的GID相同。 实例1：1# groupadd group1 此命令向系统中增加了一个新组group1，新组的组标识号是在当前已有的最大组标识号的基础上加1。 实例2：1# groupadd -g 101 group2 此命令向系统中增加了一个新组group2，同时指定新组的组标识号是101。 2、如果要删除一个已有的用户组，使用groupdel命令，其格式如下：1groupdel 用户组 例如：1# groupdel group1 此命令从系统中删除组group1。 3、修改用户组的属性使用groupmod命令。其语法如下：1groupmod 选项 用户组 常用的选项有： -g GID 为用户组指定新的组标识号。 -o 与-g选项同时使用，用户组的新GID可以与系统已有用户组的GID相同。 -n新用户组 将用户组的名字改为新名字 实例1：1# groupmod -g 102 group2 此命令将组group2的组标识号修改为102。 实例2：1# groupmod –g 10000 -n group3 group2 此命令将组group2的标识号改为10000，组名修改为group3。 4、如果一个用户同时属于多个用户组，那么用户可以在用户组之间切换，以便具有其他用户组的权限。用户可以在登录后，使用命令newgrp切换到其他用户组，这个命令的参数就是目的用户组。例如： 1$ newgrp root 这条命令将当前用户切换到root用户组，前提条件是root用户组确实是该用户的主组或附加组。类似于用户账号的管理，用户组的管理也可以通过集成的系统管理工具来完成。 三、与用户账号有关的系统文件完成用户管理的工作有许多种方法，但是每一种方法实际上都是对有关的系统文件进行修改。 与用户和用户组相关的信息都存放在一些系统文件中，这些文件包括/etc/passwd, /etc/shadow, /etc/group等。 下面分别介绍这些文件的内容。 1、/etc/passwd文件是用户管理工作涉及的最重要的一个文件。Linux系统中的每个用户都在/etc/passwd文件中有一个对应的记录行，它记录了这个用户的一些基本属性。 这个文件对所有用户都是可读的。它的内容类似下面的例子： 12345678910111213＃ cat /etc/passwdroot:x:0:0:Superuser:/:daemon:x:1:1:System daemons:/etc:bin:x:2:2:Owner of system commands:/bin:sys:x:3:3:Owner of system files:/usr/sys:adm:x:4:4:System accounting:/usr/adm:uucp:x:5:5:UUCP administrator:/usr/lib/uucp:auth:x:7:21:Authentication administrator:/tcb/files/auth:cron:x:9:16:Cron daemon:/usr/spool/cron:listen:x:37:4:Network daemon:/usr/net/nls:lp:x:71:18:Printer administrator:/usr/spool/lp:sam:x:200:50:Sam san:/usr/sam:/bin/sh 从上面的例子我们可以看到，/etc/passwd中一行记录对应着一个用户，每行记录又被冒号(:)分隔为7个字段，其格式和具体含义如下： 1用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录Shell 1）”用户名”是代表用户账号的字符串。通常长度不超过8个字符，并且由大小写字母和/或数字组成。登录名中不能有冒号(:)，因为冒号在这里是分隔符。 为了兼容起见，登录名中最好不要包含点字符(.)，并且不使用连字符(-)和加号(+)打头。 2）“口令”一些系统中，存放着加密后的用户口令字。虽然这个字段存放的只是用户口令的加密串，不是明文，但是由于/etc/passwd文件对所有用户都可读，所以这仍是一个安全隐患。因此，现在许多Linux 系统（如SVR4）都使用了shadow技术，把真正的加密后的用户口令字存放到/etc/shadow文件中，而在/etc/passwd文件的口令字段中只存放一个特殊的字符，例如“x”或者“*”。 3）“用户标识号”是一个整数，系统内部用它来标识用户。一般情况下它与用户名是一一对应的。如果几个用户名对应的用户标识号是一样的，系统内部将把它们视为同一个用户，但是它们可以有不同的口令、不同的主目录以及不同的登录Shell等。 通常用户标识号的取值范围是0～65 535。0是超级用户root的标识号，1～99由系统保留，作为管理账号，普通用户的标识号从100开始。在Linux系统中，这个界限是500。 4）“组标识号”字段记录的是用户所属的用户组。它对应着/etc/group文件中的一条记录。 5)“注释性描述”字段记录着用户的一些个人情况。例如用户的真实姓名、电话、地址等，这个字段并没有什么实际的用途。在不同的Linux 系统中，这个字段的格式并没有统一。在许多Linux系统中，这个字段存放的是一段任意的注释性描述文字，用做finger命令的输出。 6)“主目录”，也就是用户的起始工作目录。它是用户在登录到系统之后所处的目录。在大多数系统中，各用户的主目录都被组织在同一个特定的目录下，而用户主目录的名称就是该用户的登录名。各用户对自己的主目录有读、写、执行（搜索）权限，其他用户对此目录的访问权限则根据具体情况设置。 7)用户登录后，要启动一个进程，负责将用户的操作传给内核，这个进程是用户登录到系统后运行的命令解释器或某个特定的程序，即Shell。Shell是用户与Linux系统之间的接口。Linux的Shell有许多种，每种都有不同的特点。常用的有sh(Bourne Shell), csh(C Shell), ksh(Korn Shell), tcsh(TENEX/TOPS-20 type C Shell), bash(Bourne Again Shell)等。 系统管理员可以根据系统情况和用户习惯为用户指定某个Shell。如果不指定Shell，那么系统使用sh为默认的登录Shell，即这个字段的值为/bin/sh。 用户的登录Shell也可以指定为某个特定的程序（此程序不是一个命令解释器）。 利用这一特点，我们可以限制用户只能运行指定的应用程序，在该应用程序运行结束后，用户就自动退出了系统。有些Linux 系统要求只有那些在系统中登记了的程序才能出现在这个字段中。 8)系统中有一类用户称为伪用户（psuedo users）。这些用户在/etc/passwd文件中也占有一条记录，但是不能登录，因为它们的登录Shell为空。它们的存在主要是方便系统管理，满足相应的系统进程对文件属主的要求。 常见的伪用户如下所示： 1234567伪 用 户 含 义 bin 拥有可执行的用户命令文件 sys 拥有系统文件 adm 拥有帐户文件 uucp UUCP使用 lp lp或lpd子系统使用 nobody NFS使用 拥有帐户文件1、除了上面列出的伪用户外，还有许多标准的伪用户，例如：audit, cron, mail, usenet等，它们也都各自为相关的进程和文件所需要。由于/etc/passwd文件是所有用户都可读的，如果用户的密码太简单或规律比较明显的话，一台普通的计算机就能够很容易地将它破解，因此对安全性要求较高的Linux系统都把加密后的口令字分离出来，单独存放在一个文件中，这个文件是/etc/shadow文件。 有超级用户才拥有该文件读权限，这就保证了用户密码的安全性。 2、/etc/shadow中的记录行与/etc/passwd中的一一对应，它由pwconv命令根据/etc/passwd中的数据自动产生它的文件格式与/etc/passwd类似，由若干个字段组成，字段之间用”:”隔开。这些字段是： 1登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志 “登录名”是与/etc/passwd文件中的登录名相一致的用户账号 “口令”字段存放的是加密后的用户口令字，长度为13个字符。如果为空，则对应用户没有口令，登录时不需要口令；如果含有不属于集合 { ./0-9A-Za-z }中的字符，则对应的用户不能登录。 “最后一次修改时间”表示的是从某个时刻起，到用户最后一次修改口令时的天数。时间起点对不同的系统可能不一样。例如在SCO Linux 中，这个时间起点是1970年1月1日。 “最小时间间隔”指的是两次修改口令之间所需的最小天数。 “最大时间间隔”指的是口令保持有效的最大天数。 “警告时间”字段表示的是从系统开始警告用户到用户密码正式失效之间的天数。 “不活动时间”表示的是用户没有登录活动但账号仍能保持有效的最大天数。 “失效时间”字段给出的是一个绝对的天数，如果使用了这个字段，那么就给出相应账号的生存期。期满后，该账号就不再是一个合法的账号，也就不能再用来登录了。 下面是/etc/shadow的一个例子： 1234567891011121314＃ cat /etc/shadowroot:Dnakfw28zf38w:8764:0:168:7:::daemon:*::0:0::::bin:*::0:0::::sys:*::0:0::::adm:*::0:0::::uucp:*::0:0::::nuucp:*::0:0::::auth:*::0:0::::cron:*::0:0::::listen:*::0:0::::lp:*::0:0::::sam:EkdiSECLWPdSa:9740:0:0:::: 3、用户组的所有信息都存放在/etc/group文件中。将用户分组是Linux 系统中对用户进行管理及控制访问权限的一种手段。 每个用户都属于某个用户组；一个组中可以有多个用户，一个用户也可以属于不同的组。 当一个用户同时是多个组中的成员时，在/etc/passwd文件中记录的是用户所属的主组，也就是登录时所属的默认组，而其他组称为附加组。 用户要访问属于附加组的文件时，必须首先使用newgrp命令使自己成为所要访问的组中的成员。 用户组的所有信息都存放在/etc/group文件中。此文件的格式也类似于/etc/passwd文件，由冒号(:)隔开若干个字段，这些字段有： 1组名:口令:组标识号:组内用户列表 “组名”是用户组的名称，由字母或数字构成。与/etc/passwd中的登录名一样，组名不应重复。 “口令”字段存放的是用户组加密后的口令字。一般Linux 系统的用户组都没有口令，即这个字段一般为空，或者是*。 “组标识号”与用户标识号类似，也是一个整数，被系统内部用来标识组。 “组内用户列表”是属于这个组的所有用户的列表/b]，不同用户之间用逗号(,)分隔。这个用户组可能是用户的主组，也可能是附加组。 /etc/group文件的一个例子如下： 1234567root::0:rootbin::2:root,binsys::3:root,uucpadm::4:root,admdaemon::5:root,daemonlp::7:root,lpusers::20:root,sam 四、批量添加用户添加和删除用户对每位Linux系统管理员都是轻而易举的事，比较棘手的是如果要添加几十个、上百个甚至上千个用户时，我们不太可能还使用useradd一个一个地添加，必然要找一种简便的创建大量用户的方法。Linux系统提供了创建大量用户的工具，可以让您立即创建大量用户，方法如下： （1）先编辑一个文本用户文件。每一列按照/etc/passwd密码文件的格式书写，要注意每个用户的用户名、UID、宿主目录都不可以相同，其中密码栏可以留做空白或输入x号。一个范例文件user.txt内容如下： 123456user001::600:100:user:/home/user001:/bin/bashuser002::601:100:user:/home/user002:/bin/bashuser003::602:100:user:/home/user003:/bin/bashuser004::603:100:user:/home/user004:/bin/bashuser005::604:100:user:/home/user005:/bin/bashuser006::605:100:user:/home/user006:/bin/bash （2）以root身份执行命令 /usr/sbin/newusers，从刚创建的用户文件user.txt中导入数据，创建用户：1# newusers &lt; user.txt 然后可以执行命令 vipw 或 vi /etc/passwd 检查 /etc/passwd 文件是否已经出现这些用户的数据，并且用户的宿主目录是否已经创建。 （3）执行命令/usr/sbin/pwunconv。将 /etc/shadow 产生的 shadow 密码解码，然后回写到 /etc/passwd 中，并将/etc/shadow的shadow密码栏删掉。这是为了方便下一步的密码转换工作，即先取消 shadow password 功能。 1# pwunconv （4）编辑每个用户的密码对照文件。范例文件 passwd.txt 内容如下： 123456user001:密码user002:密码user003:密码user004:密码user005:密码user006:密码 （5）以root身份执行命令 /usr/sbin/chpasswd。创建用户密码，chpasswd 会将经过 /usr/bin/passwd 命令编码过的密码写入 /etc/passwd 的密码栏。 1# chpasswd &lt; passwd.txt （6）确定密码经编码写入/etc/passwd的密码栏后。执行命令 /usr/sbin/pwconv 将密码编码为 shadow password，并将结果写入 /etc/shadow。 1# pwconv 这样就完成了大量用户的创建了，之后您可以到/home下检查这些用户宿主目录的权限设置是否都正确，并登录验证用户密码是否正确。 Linux vi/vim所有的 Unix Like 系统都会内建 vi 文书编辑器，其他的文书编辑器则不一定会存在。但是目前我们使用比较多的是 vim 编辑器。 vim 具有程序编辑的能力，可以主动的以字体颜色辨别语法的正确性，方便程序设计。 什么是 vim？Vim是从 vi 发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。 简单的来说， vi 是老式的字处理器，不过功能已经很齐全了，但是还是有可以进步的地方。 vim 则可以说是程序开发者的一项很好用的工具。 连 vim 的官方网站 (http://www.vim.org) 自己也说 vim 是一个程序开发工具而不是文字处理软件。 vim 键盘图： vi/vim 的使用基本上 vi/vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。 这三种模式的作用分别是： 命令模式： 用户刚刚启动 vi/vim，便进入了命令模式。 此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。 以下是常用的几个命令： i 切换到输入模式，以输入字符。 x 删除当前光标所在处的字符。 : 切换到底线命令模式，以在最底一行输入命令。 若想要编辑文本：启动Vim，进入了命令模式，按下i，切换到输入模式。 命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。 输入模式 在命令模式下按下i就进入了输入模式。 在输入模式中，可以使用以下按键： 字符按键以及Shift组合，输入字符 ENTER，回车键，换行 BACK SPACE，退格键，删除光标前一个字符 DEL，删除键，删除光标后一个字符 方向键，在文本中移动光标 HOME/END，移动光标到行首/行尾 Page Up/Page Down，上/下翻页 Insert，切换光标为输入/替换模式，光标将变成竖线/下划线 ESC，退出输入模式，切换到命令模式 底线命令模式 在命令模式下按下:（英文冒号）就进入了底线命令模式。 底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。 在底线命令模式中，基本的命令有（已经省略了冒号）： q 退出程序 w 保存文件 按ESC键可随时退出底线命令模式。 简单的说，我们可以将这三个模式想成底下的图标来表示： vi/vim 使用实例使用 vi/vim 进入命令模式如果你想要使用 vi 来建立一个名为 test.txt 的文件时，你可以这样做： 1[root@www ~]# vi test.txt 直接输入 vi 文件名 就能够进入 vi 的命令模式了。请注意，记得 vi 后面一定要加文件名，不管该文件存在与否！ 按下 i 进入输入模式，开始编辑文字在命令模式之中，只要按下 i, o, a 等字符就可以进入输入模式了！ 在输入模式当中，你可以发现在左下角状态栏中会出现 –INSERT- 的字样，那就是可以输入任意字符的提示。 这个时候，键盘上除了 [Esc] 这个按键之外，其他的按键都可以视作为一般的输入按钮了，所以你可以进行任何的编辑。 按下 [ESC] 按钮回到命令模式好了，假设我已经按照上面的样式给他编辑完毕了，那么应该要如何退出呢？是的！没错！就是给他按下 [Esc] 这个按钮即可！马上你就会发现画面左下角的 – INSERT – 不见了！ 在命令模式中按下 :wq 储存后离开 viOK，我们要存档了，存盘并离开的指令很简单，输入『:wq』即可保存离开！ OK! 这样我们就成功创建了一个 test.txt 的文件。是不是很简单。 vi/vim 按键说明除了上面简易范例的 i, [Esc], :wq 之外，其实 vim 还有非常多的按键可以使用。 第一部份：命令模式可用的按钮说明，光标移动、复制贴上、搜寻取代等 移动光标的方法 h 或 向左箭头键(←) 光标向左移动一个字符 j 或 向下箭头键(↓) 光标向下移动一个字符 k 或 向上箭头键(↑) 光标向上移动一个字符 l 或 向右箭头键(→) 光标向右移动一个字符 如果你将右手放在键盘上的话，你会发现 hjkl 是排列在一起的，因此可以使用这四个按钮来移动光标。 如果想要进行多次移动的话，例如向下移动 30 行，可以使用 “30j” 或 “30↓” 的组合按键， 亦即加上想要进行的次数(数字)后，按下动作即可！ [Ctrl] + [f] 屏幕『向下』移动一页，相当于 [Page Down]按键 (常用) [Ctrl] + [b] 屏幕『向上』移动一页，相当于 [Page Up] 按键 (常用) [Ctrl] + [d] 屏幕『向下』移动半页 [Ctrl] + [u] 屏幕『向上』移动半页 + 光标移动到非空格符的下一列 - 光标移动到非空格符的上一列 n 那个 n 表示『数字』，例如 20 。按下数字后再按空格键，光标会向右移动这一行的 n 个字符。例如 20 则光标会向后面移动 20 个字符距离。 0 或功能键[Home] 这是数字『 0 』：移动到这一行的最前面字符处 (常用) $ 或功能键[End] 移动到这一行的最后面字符处(常用) H 光标移动到这个屏幕的最上方那一行的第一个字符 M 光标移动到这个屏幕的中央那一行的第一个字符 L 光标移动到这个屏幕的最下方那一行的第一个字符 G 移动到这个档案的最后一行(常用) nG n 为数字。移动到这个档案的第 n 行。例如 20G 则会移动到这个档案的第 20 行(可配合 :set nu) gg 移动到这个档案的第一行，相当于 1G 啊！ (常用) n n 为数字。光标向下移动 n 行(常用) 搜寻与取代 /word 向光标之下寻找一个名称为 word 的字符串。例如要在档案内搜寻 vbird 这个字符串，就输入 /vbird 即可！ (常用) ?word 向光标之上寻找一个字符串名称为 word 的字符串。 n 这个 n 是英文按键。代表重复前一个搜寻的动作。举例来说， 如果刚刚我们执行 /vbird 去向下搜寻 vbird 这个字符串，则按下 n 后，会向下继续搜寻下一个名称为 vbird 的字符串。如果是执行 ?vbird 的话，那么按下 n 则会向上继续搜寻名称为 vbird 的字符串！ N 这个 N 是英文按键。与 n 刚好相反，为『反向』进行前一个搜寻动作。 例如 /vbird 后，按下 N 则表示『向上』搜寻 vbird 。 使用 /word 配合 n 及 N 是非常有帮助的！可以让你重复的找到一些你搜寻的关键词！ :n1,n2s/word1/word2/g n1 与 n2 为数字。在第 n1 与 n2 行之间寻找 word1 这个字符串，并将该字符串取代为 word2 ！举例来说，在 100 到 200 行之间搜寻 vbird 并取代为 VBIRD 则： 『:100,200s/vbird/VBIRD/g』。(常用) :1,$s/word1/word2/g 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！(常用) :1,$s/word1/word2/gc 从第一行到最后一行寻找 word1 字符串，并将该字符串取代为 word2 ！且在取代前显示提示字符给用户确认 (confirm) 是否需要取代！(常用) 删除、复制与贴上 x, X 在一行字当中，x 为向后删除一个字符 (相当于 [del] 按键)， X 为向前删除一个字符(相当于 [backspace] 亦即是退格键) (常用) nx n 为数字，连续向后删除 n 个字符。举例来说，我要连续删除 10 个字符， 『10x』。 dd 删除游标所在的那一整行(常用) ndd n 为数字。删除光标所在的向下 n 行，例如 20dd 则是删除 20 行 (常用) d1G 删除光标所在到第一行的所有数据 dG 删除光标所在到最后一行的所有数据 d$ 删除游标所在处，到该行的最后一个字符 d0 那个是数字的 0 ，删除游标所在处，到该行的最前面一个字符 yy 复制游标所在的那一行(常用) nyy n 为数字。复制光标所在的向下 n 列，例如 20yy 则是复制 20 列(常用) y1G 复制游标所在列到第一列的所有数据 yG 复制游标所在列到最后一列的所有数据 y0 复制光标所在的那个字符到该行行首的所有数据 y$ 复制光标所在的那个字符到该行行尾的所有数据 p, P p 为将已复制的数据在光标下一行贴上，P 则为贴在游标上一行！ 举例来说，我目前光标在第 20 行，且已经复制了 10 行数据。则按下 p 后， 那 10 行数据会贴在原本的 20 行之后，亦即由 21 行开始贴。但如果是按下 P 呢？ 那么原本的第 20 行会被推到变成 30 行。 (常用) J 将光标所在列与下一列的数据结合成同一列 c 重复删除多个数据，例如向下删除 10 行，[ 10cj ] u 复原前一个动作。(常用) [Ctrl]+r 重做上一个动作。(常用) 这个 u 与 [Ctrl]+r 是很常用的指令！一个是复原，另一个则是重做一次～ 利用这两个功能按键，你的编辑，嘿嘿！很快乐的啦！ . 不要怀疑！这就是小数点！意思是重复前一个动作的意思。 如果你想要重复删除、重复贴上等等动作，按下小数点『.』就好了！ (常用) 第二部份：命令模式切换到输入模式的可用的按钮说明 进入输入或取代的编辑模式 i, I 进入输入模式(Insert mode)： i 为『从目前光标所在处输入』， I 为『在目前所在行的第一个非空格符处开始输入』。 (常用) a, A 进入输入模式(Insert mode)： a 为『从目前光标所在的下一个字符处开始输入』， A 为『从光标所在行的最后一个字符处开始输入』。(常用) o, O 进入输入模式(Insert mode)： 这是英文字母 o 的大小写。o 为『在目前光标所在的下一行处输入新的一行』； O 为在目前光标所在处的上一行输入新的一行！(常用) r, R 进入取代模式(Replace mode)： r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字，直到按下 ESC 为止；(常用) 上面这些按键中，在 vi 画面的左下角处会出现『–INSERT–』或『–REPLACE–』的字样。 由名称就知道该动作了吧！！特别注意的是，我们上面也提过了，你想要在档案里面输入字符时， 一定要在左下角处看到 INSERT 或 REPLACE 才能输入喔！ [Esc] 退出编辑模式，回到命令模式中(常用) 第三部份：命令模式切换到底线命令模式的可用的按钮说明 底线命令模式的储存、离开等指令 :w 将编辑的数据写入硬盘档案中(常用) :w! 若文件属性为『只读』时，强制写入该档案。不过，到底能不能写入， 还是跟你对该档案的档案权限有关啊！ :q 离开 vi (常用) :q! 若曾修改过档案，又不想储存，使用 ! 为强制离开不储存档案。 注意一下啊，那个惊叹号 (!) 在 vi 当中，常常具有『强制』的意思～ :wq 储存后离开，若为 :wq! 则为强制储存后离开 (常用) ZZ 这是大写的 Z 喔！若档案没有更动，则不储存离开，若档案已经被更动过，则储存后离开！ :w [filename] 将编辑的数据储存成另一个档案（类似另存新档） :r [filename] 在编辑的数据中，读入另一个档案的数据。亦即将 『filename』 这个档案内容加到游标所在行后面 :n1,n2 w [filename] 将 n1 到 n2 的内容储存成 filename 这个档案。 :! command 暂时离开 vi 到指令列模式下执行 command 的显示结果！例如 『:! ls /home』即可在 vi 当中察看 /home 底下以 ls 输出的档案信息！ vim 环境的变更 :set nu 显示行号，设定之后，会在每一行的前缀显示该行的行号 :set nonu 与 set nu 相反，为取消行号！ 特别注意，在 vi/vim 中，数字是很有意义的！数字通常代表重复做几次的意思！ 也有可能是代表去到第几个什么什么的意思。 举例来说，要删除 50 行，则是用 『50dd』 对吧！ 数字加在动作之前，如我要向下移动 20 行呢？那就是『20j』或者是『20↓』即可。 linux yum 命令linux yum 命令yum（ Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。 基於RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。 yum提供了查找、安装、删除某一个、一组甚至全部软件包的命令，而且命令简洁而又好记。 yum 语法1yum [options] [command] [package ...] options：可选，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。 command：要进行的操作。 package操作的对象。 yum常用命令 1.列出所有可更新的软件清单命令：yum check-update 2.更新所有软件命令：yum update 3.仅安装指定的软件命令：yum install &lt;package_name&gt; 4.仅更新指定的软件命令：yum update &lt;package_name&gt; 5.列出所有可安裝的软件清单命令：yum list 6.删除软件包命令：yum remove &lt;package_name&gt; 7.查找软件包 命令：yum search 8.清除缓存命令: yum clean packages: 清除缓存目录下的软件包 yum clean headers: 清除缓存目录下的 headers yum clean oldheaders: 清除缓存目录下旧的 headers yum clean, yum clean all (= yum clean packages; yum clean oldheaders) :清除缓存目录下的软件包及旧的headers 实例 1安装 pam-devel 123456789101112[root@www ~]# yum install pam-develSetting up Install ProcessParsing package install argumentsResolving Dependencies &lt;==先检查软件的属性相依问题 --&gt; Running transaction check---&gt; Package pam-devel.i386 0:0.99.6.2-4.el5 set to be updated--&gt; Processing Dependency: pam = 0.99.6.2-4.el5 for package: pam-devel--&gt; Running transaction check---&gt; Package pam.i386 0:0.99.6.2-4.el5 set to be updatedfilelists.xml.gz 100% |=========================| 1.6 MB 00:05filelists.xml.gz 100% |=========================| 138 kB 00:00-&gt; Finished Dependency Resolution……(省略) 实例 2移除 pam-devel 12345678910111213141516171819[root@www ~]# yum remove pam-develSetting up Remove ProcessResolving Dependencies &lt;==同样的，先解决属性相依的问题 --&gt; Running transaction check---&gt; Package pam-devel.i386 0:0.99.6.2-4.el5 set to be erased--&gt; Finished Dependency ResolutionDependencies Resolved============================================================================= Package Arch Version Repository Size=============================================================================Removing: pam-devel i386 0.99.6.2-4.el5 installed 495 kTransaction Summary=============================================================================Install 0 Package(s)Update 0 Package(s)Remove 1 Package(s) &lt;==还好，并没有属性相依的问题，单纯移除一个软件 Is this ok [y/N]: y Downloading Packages: Running rpm_check_debug Running Transaction Test Finished Transaction Test Transaction Test Succeeded Running Transaction Erasing : pam-devel ######################### [1/1] Removed: pam-devel.i386 0:0.99.6.2-4.el5 Complete! 实例 3利用 yum 的功能，找出以 pam 为开头的软件名称有哪些？ 123456789[root@www ~]# yum list pam*Installed Packagespam.i386 0.99.6.2-3.27.el5 installedpam_ccreds.i386 3-5 installedpam_krb5.i386 2.2.14-1 installedpam_passwdqc.i386 1.0.2-1.2.2 installedpam_pkcs11.i386 0.5.3-23 installedpam_smb.i386 1.1.7-7.2.1 installedAvailable Packages &lt;==底下则是『可升级』的或『未安装』的 pam.i386 0.99.6.2-4.el5 base pam-devel.i386 0.99.6.2-4.el5 base pam_krb5.i386 2.2.14-10 base 国内 yum 源网易（163）yum源是国内最好的yum源之一 ，无论是速度还是软件版本，都非常的不错。 将yum源设置为163 yum，可以提升软件包安装和更新的速度，同时避免一些常见软件版本无法找到。 安装步骤首先备份/etc/yum.repos.d/CentOS-Base.repo 1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup 下载对应版本repo文件, 放入/etc/yum.repos.d/(操作前请做好相应备份) CentOS5 ：http://mirrors.163.com/.help/CentOS5-Base-163.repo CentOS6 ：http://mirrors.163.com/.help/CentOS6-Base-163.repo 运行以下命令生成缓存 12yum clean allyum makecache 除了网易之外，国内还有其他不错的yum源，比如中科大和搜狐。 中科大的yum源，安装方法查看：https://lug.ustc.edu.cn/wiki/mirrors/help/centos sohu的yum源安装方法查看: http://mirrors.sohu.com/help/centos.html]]></content>
      <tags>
        <tag>-linux</tag>
      </tags>
  </entry>
</search>
